{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cables:  Fuses:  Poles:  Switches:  Transformers:  UGStructures:\n",
      "0     3865     736   18961        537           3618          16883\n",
      "1       39      46      31         52             57             40\n",
      "   Cables:  Fuses:  Poles:  Switches:  Transformers:  UGStructures:\n",
      "0     3865     736   18961        537           3618          16883\n",
      "1       22      29      14         35             40             23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import re\n",
    "#import xlrd\n",
    "\n",
    "# fileName - iterate through entire folder :)\n",
    "fileName = 'Original_FiveAssetClasses.xlsx'\n",
    "#fileNameOtherDevices = 'Other Device Numbers.xls'\n",
    "#fileNamePolesClassHeight = 'Poles_class_height.xlsx' # Poles_class_height table\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(fileName) as xlsx:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfTransformersV1 = pd.read_excel(xlsx, 'Transformers') # 280 rows\n",
    "    dfSwitchesV1 = pd.read_excel(xlsx, 'Switches') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "    dfPolesV1 = pd.read_excel(xlsx, 'Poles') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "    dfCablesV1 = pd.read_excel(xlsx, 'UGPrimaryCables')\n",
    "    dfFusesV1 = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "    dfUGStructuresV1 = pd.read_excel(xlsx,'UGStructures')\n",
    "\n",
    "\n",
    "Summary = {'Transformers:': dfTransformersV1.shape, 'Switches:': dfSwitchesV1.shape,'Poles:': dfPolesV1.shape, \n",
    "           'Cables:': dfCablesV1.shape, 'Fuses:':dfFusesV1.shape, 'UGStructures:':dfUGStructuresV1.shape}\n",
    "dfSummary = pd.DataFrame(Summary)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformersV2 = dfTransformersV1\n",
    "dfSwitchesV2 = dfSwitchesV1\n",
    "dfPolesV2 = dfPolesV1\n",
    "dfCablesV2 = dfCablesV1\n",
    "dfFusesV2 = dfFusesV1\n",
    "dfUGStructuresV2 = dfUGStructuresV1\n",
    "\n",
    "# 17 columns dropped\n",
    "dropCommonColumns = ['OBJECTID','WORKORDERID','FIELDVERIFY','COMMENTS','CREATIONUSER','DATECREATED','LASTUSER',\n",
    "                     'DATEMODIFIED','WORKREQUESTID','DESIGNID','WORKLOCATIONID','WMSID','WORKFLOWSTATUS',\n",
    "                     'WORKFUNCTION','GISONUMBER','GISOTYPENBR','OWNERSHIP']\n",
    "\n",
    "#*************************#\n",
    "#****DEFINITIONS**********#\n",
    "#*************************#\n",
    "def drop_columns(dfAssetClass, dropColumns):\n",
    "    dfAssetClass = dfAssetClass.drop(dropColumns, axis=1)\n",
    "    return dfAssetClass\n",
    "\n",
    "def new_columns(dfAssetClass, numAssetRows, columnID):\n",
    "    dfAssetClass[columnID] = pd.DataFrame(np.empty([numAssetRows,1]).cumsum(axis=1))\n",
    "    dfAssetClass.loc[:,columnID] = np.nan\n",
    "    return dfAssetClass[columnID]\n",
    "\n",
    "#*************************#\n",
    "#****DEFINITIONS**********#\n",
    "#*************************#\n",
    "\n",
    "#Drop all common columns \n",
    "dfSwitchesV2 = drop_columns(dfSwitchesV2, dropCommonColumns)\n",
    "dfTransformersV2 = drop_columns(dfTransformersV2, dropCommonColumns)\n",
    "dfFusesV2 = drop_columns(dfFusesV2,dropCommonColumns)\n",
    "dfCablesV2 = drop_columns(dfCablesV2, dropCommonColumns)\n",
    "dfUGStructuresV2 = drop_columns(dfUGStructuresV2, dropCommonColumns)\n",
    "dfPolesV2 = drop_columns(dfPolesV2, dropCommonColumns)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "SummaryV2 = {'Transformers:': dfTransformers.shape, 'Switches:': dfSwitches.shape,'Poles:': dfPoles.shape, \n",
    "           'Cables:': dfCables.shape, 'Fuses:':dfFuses.shape, 'UGStructures:':dfUGStructures.shape}\n",
    "dfSummaryV2 = pd.DataFrame(SummaryV2)\n",
    "print(dfSummary)\n",
    "print(dfSummaryV2)\n",
    "# print(dfSummary-dfSummaryV2) # shows 17 cols dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642 1974\n"
     ]
    }
   ],
   "source": [
    "# Save future wait times while running\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "#print(dfPoles.columns)\n",
    "\n",
    "dropTxCols = ['ANCILLARYROLE', 'ENABLED', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'SYMBOLROTATION', \n",
    "              'GPSDATE', 'LABELTEXT', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'GROUNDREACTANCE', 'GROUNDRESISTANCE', \n",
    "              'MAGNETIZINGREACTANCE', 'MAGNETIZINGRESISTANCE', 'HIGHSIDEGROUNDREACTANCE','HIGHSIDEGROUNDRESISTANCE', \n",
    "              'HIGHSIDEPROTECTION', 'LOCATIONTYPE','COOLINGTYPE', 'FEATURE_STATUS','KVA', 'DEMAND_KVA',\n",
    "              'DEMAND_DATE_MM_DD_YYYY', 'STREET_LIGHT_FACILITY', 'HIGHSIDECONFIGURATION', 'LOWSIDECONFIGURATION',\n",
    "              'LOWSIDEGROUNDRESISTANCE', 'LOWSIDEVOLTAGE', 'LATITUDE', 'LONGITUDE']\n",
    "\n",
    "# drop columns not related to Tx\n",
    "dfTransformers = drop_columns(dfTransformers,dropTxCols)\n",
    "# df.query('line_race != 0')\n",
    "# df = df[df.line_race != 0]\n",
    "\n",
    "# Add additional columns and fill with NaNs\n",
    "#dfPoles[''] = new_columns(dfPoles, numPolesRows,'')\n",
    "numTxRows = len(dfTransformers['DEVICENUMBER'])\n",
    "#dfTransformers[''] = new_columns(dfTransformers,numTxRows, '')\n",
    "\n",
    "# Don't drop so they still exist :S\n",
    "# dfTransformers['UNITS'] = new_columns(dfTransformers,numTxRows, 'UNITS')\n",
    "# dfTransformers['FAULTINDICATOR'] = new_columns(dfTransformers,numTxRows, 'FAULTINDICATOR')\n",
    "# dfTransformers['COMPATIBLEUNITID'] = new_columns(dfTransformers,numTxRows, 'COMPATIBLEUNITID')\n",
    "\n",
    "dfTransformers['Asset Class'] = new_columns(dfTransformers, numTxRows,'Asset Class')\n",
    "dfTransformers['HI'] = new_columns(dfTransformers, numTxRows,'HI')\n",
    "dfTransformers['PRID'] = new_columns(dfTransformers, numTxRows,'PRID')\n",
    "dfTransformers['IN_VALLEY'] = new_columns(dfTransformers, numTxRows,'IN_VALLEY')\n",
    "dfTransformers['TX_RESIDENTIAL'] = new_columns(dfTransformers, numTxRows,'TX_RESIDENTIAL')\n",
    "dfTransformers['TX_COMMERCIAL'] = new_columns(dfTransformers, numTxRows,'TX_COMMERCIAL')\n",
    "dfTransformers['TX_INDUSTRIAL'] = new_columns(dfTransformers, numTxRows,'TX_INDUSTRIAL')\n",
    "dfTransformers['DEVICE_RESIDENTIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_RESIDENTIAL')\n",
    "dfTransformers['DEVICE_COMMERCIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_COMMERCIAL')\n",
    "dfTransformers['DEVICE_INDUSTRIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_INDUSTRIAL')\n",
    "dfTransformers['UPSTREAM_DEVICE'] = new_columns(dfTransformers, numTxRows,'UPSTREAM_DEVICE')\n",
    "dfTransformers['PCB'] = new_columns(dfTransformers, numTxRows,'PCB')\n",
    "\n",
    "# Rename Pole columns\n",
    "dfTransformers = dfTransformers.rename(columns={'DEVICENUMBER':'ID',\n",
    "                                                'PHASEDESIGNATION':'Type',\n",
    "                                                'INSTALLATIONDATE':'INSTALL_YEAR',\n",
    "                                                'FEEDERID':'CIRCUIT',\n",
    "                                                'RATEDKVA':'KVA'})\n",
    "# Separate year\n",
    "dfTransformers['INSTALL_YEAR'] = dfTransformers['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "# UG Tx: 2/3/5/7 - 1Ph/Ntwk/Sub/Pad 3Ph [1436,27,4,507: 1642 counts]\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "dfUGTransformers = pd.DataFrame(dfTransformers[(dfTransformers.SUBTYPECD == 2) | \n",
    "                                  (dfTransformers.SUBTYPECD == 3) | \n",
    "                                  (dfTransformers.SUBTYPECD == 5) | \n",
    "                                  (dfTransformers.SUBTYPECD == 7) ])\n",
    "\n",
    "# OH Tx: 1/9/10 - 1Ph/3Ph/2Ph [1125/510/7: 1347 counts]\n",
    "dfOHTransformers = pd.DataFrame(dfTransformers[(dfTransformers.SUBTYPECD == 1) | \n",
    "                                  (dfTransformers.SUBTYPECD == 9) | \n",
    "                                  (dfTransformers.SUBTYPECD == 10)])\n",
    "\n",
    "# Replace Asset class and 'SUBTYPECD' with actual tx types\n",
    "dictOHTxSubclass = {'1':'Standard 1Ph','9':'Standard 3Ph','10':'Standard 2Ph'}\n",
    "dictUGTxSubclass = {'2':'Padmount 1Ph','3':'Network Submersible','5':'Submersible', '7':'Padmount 3Ph'}\n",
    "\n",
    "numOHTxRows = len(dfOHTransformers['ID'])\n",
    "numUGTxRows = len(dfUGTransformers['ID'])\n",
    "\n",
    "#dfOHTransformers['SUBTYPECD_LOOKUP'] = new_columns(dfOHTransformers, numOHTxRows,'SUBTYPECD_LOOKUP')\n",
    "# pd.DataFrame(np.empty([numOHTxRows,1]).cumsum(axis=1))\n",
    "#print(dfOHTransformers.head())\n",
    "\n",
    "dfOHTransformers['SUBTYPECD'] = dfOHTransformers['SUBTYPECD'].astype(str)\n",
    "dfUGTransformers['SUBTYPECD'] = dfUGTransformers['SUBTYPECD'].astype(str)\n",
    "\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "dfOHTransformers.loc[:,'SUBTYPECD'] = dfOHTransformers['SUBTYPECD'].apply(lambda x: dictOHTxSubclass[x])\n",
    "dfUGTransformers.loc[:,'SUBTYPECD'] = dfUGTransformers['SUBTYPECD'].apply(lambda x: dictUGTxSubclass[x])\n",
    "\n",
    "# Fill in Asset and asset subclass columns\n",
    "dfOHTransformers['Asset Class'] = 'Overhead Transformer'\n",
    "dfUGTransformers['Asset Class'] = 'Underground Transformer'\n",
    "dfOHTransformers = dfOHTransformers.rename(columns={'SUBTYPECD':'Asset Subclass'})\n",
    "dfUGTransformers = dfUGTransformers.rename(columns={'SUBTYPECD':'Asset Subclass'})\n",
    "\n",
    "# Remaining OH Tx and UG Tx specific columns\n",
    "dfOHTransformers['BANKING'] = new_columns(dfOHTransformers, numOHTxRows,'BANKING')\n",
    "dfUGTransformers['PEDESTAL'] = new_columns(dfUGTransformers, numUGTxRows,'PEDESTAL')\n",
    "dfUGTransformers['SWITCHABLE'] = new_columns(dfUGTransformers, numUGTxRows,'SWITCHABLE')\n",
    "dfUGTransformers['SWITCH_TYPE'] = new_columns(dfUGTransformers, numUGTxRows,'SWITCH_TYPE')\n",
    "print(numOHTxRows, numUGTxRows)\n",
    "\n",
    "# print(dfOHTransformers.dtypes)\n",
    "# print(dfUGTransformers.dtypes)\n",
    "\n",
    "# Tx Domain code tables\n",
    "fileNameDomainCodes_Tx = 'DomainCodes_Tx.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameDomainCodes_Tx) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfUGTxDomainCodes = pd.read_excel(xls, 'UGTransformers')\n",
    "    dfOHTxDomainCodes = pd.read_excel(xls, 'OHTransformers')\n",
    "\n",
    "# Convert to string for merge purposes\n",
    "dfOHTransformers['COMPATIBLEUNITID'] = dfOHTransformers['COMPATIBLEUNITID'].astype(str)\n",
    "dfUGTransformers['COMPATIBLEUNITID'] = dfUGTransformers['COMPATIBLEUNITID'].astype(str)\n",
    "dfOHTxDomainCodes['COMPATIBLEUNITID'] = dfOHTxDomainCodes['COMPATIBLEUNITID'].astype(str)\n",
    "dfUGTxDomainCodes['COMPATIBLEUNITID'] = dfUGTxDomainCodes['COMPATIBLEUNITID'].astype(str)\n",
    "#print(dfUGTxDomainCodes.head())\n",
    "\n",
    "#df=pd.merge(df, df, how='left', left_on='ID', right_on='Loc_No')\n",
    "#df.merge(df1, on='sku', how='left')\n",
    "#dfOHTransformers=pd.merge(dfOHTransformers, dfOHTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#dfUGTransformers=pd.merge(dfUGTransformers, dfUGTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "dfOHTransformers=dfOHTransformers.merge(dfOHTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "dfUGTransformers=dfUGTransformers.merge(dfUGTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#print(dfUGTransformers.head(2))\n",
    "\n",
    "dropTxCols2 = ['COMPATIBLEUNITID','Description']\n",
    "\n",
    "# drop columns and drop rows that are not UG Switch\n",
    "dfOHTransformers = drop_columns(dfOHTransformers,dropTxCols2)\n",
    "\n",
    "MasterFile = pd.ExcelWriter('V2_GIS_Tx.xlsx')\n",
    "dfOHTransformers.to_excel(MasterFile, 'OHTransformer')\n",
    "dfUGTransformers.to_excel(MasterFile, 'UGTransformer')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pole attached assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type Loc_No                  Subclass\n",
      "0  PME-11  149-S  Air-Insulated Live Front\n",
      "1  PME-11  165-S  Air-Insulated Live Front\n",
      "2  PME-11  205-S  Air-Insulated Live Front\n",
      "3  PME-11  269-F  Air-Insulated Live Front\n"
     ]
    }
   ],
   "source": [
    "# Switches\n",
    "fileNameOtherDevices = 'Other Device Numbers.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameOtherDevices) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfSwitchGears = pd.read_excel(xls, 'SWITCHGEARS') # 280 rows\n",
    "\n",
    "dropSGcols = ['Switch Gear', 'Adrs #','Location','City','Notes','To Type','Inst. Date','Mftr.','Catalog#','Serial#',\n",
    "             'DOM','Comments']\n",
    "\n",
    "dfSwitchGears = drop_columns(dfSwitchGears, dropSGcols)\n",
    "#dfSwitchGears = dfSwitchGears.dropna() # drop all rows with NaN values\n",
    "\n",
    "dictSGassetSubclass = {'PMH-3':'Air-Insulated Live Front','PMH-5':'Air-Insulated Live Front',\n",
    "                       'PMH-9':'Air-Insulated Live Front','PMH-11':'Air-Insulated Live Front',\n",
    "                       'PME-9':'Air-Insulated Dead Front','PME-10':'Air-Insulated Dead Front',\n",
    "                       'PME-11':'Air-Insulated Live Front','VISTA-321':'SF6-Insulated Switch',\n",
    "                       'VISTA-422':'SF6-Insulated Switch','VISTA-431':'SF6-Insulated Switch',\n",
    "                       '422':'S&C Elec','431':'S&C Elec','321':'S&C Elec','G&W':'G&W',\n",
    "                       'NET':'Carte Elec Ltd'}\n",
    "# 'Type' -> 'PMH'\n",
    "# 'Loc_No' -> '149-S'\n",
    "dfSwitchGears['Type'] = dfSwitchGears['Type'].fillna(method='ffill')\n",
    "numSGrows = len(dfSwitchGears['Loc_No'])\n",
    "dfSwitchGears['Subclass'] = new_columns(dfSwitchGears, numSGrows, 'Subclass')\n",
    "dfSwitchGears =dfSwitchGears.astype(str)\n",
    "dfSwitchGears['Subclass'] = dfSwitchGears['Type'].apply(lambda x: dictSGassetSubclass[x])\n",
    "\n",
    "print(dfSwitchGears.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 11)\n",
      "dfSG Shape: (451, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace 'Asset Subclass' col with actual names\n",
    "dfSwitches['ID'] = dfSwitches['ID'].astype(str)\n",
    "dfSwitches=pd.merge(dfSwitches, dfSwitchGears, how='left', left_on='ID', right_on='Loc_No')\n",
    "#dfSwitches['ID'] = dfSwitchGears['Loc_No'].apply(lambda x: )\n",
    "#df.merge(df1, on='sku', how='left')\n",
    "# print(len(pd.unique(dfSwitchGears['Loc_No'].values.ravel()))) # 111\n",
    "\n",
    "switchesDropMoreCols = ['Asset Subclass', 'Loc_No']\n",
    "dfSwitches = dfSwitches.drop(switchesDropMoreCols, axis=1)\n",
    "dfSwitches = dfSwitches.rename(columns={'Subclass':'Asset Subclass'})\n",
    "#Rearrange columns\n",
    "dfSwitches=dfSwitches[['Asset Class', 'Asset Subclass', 'ID','CIRCUIT','INSTALL_YEAR','TIE_FEEDER','PHASING','IN_VALLEY','HI','TX_PHASE','PRID','Type']]\n",
    "\n",
    "MasterFile = pd.ExcelWriter('V2_GIS_Poles.xlsx')\n",
    "dfSwitches.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dfSwitches['ID'] = dfSwitchGears['Loc_No'].apply(lambda x: dfSwitchGears['Loc_No'] )\n",
    "#df.merge(df1, on='sku', how='left')\n",
    "#print(dfSwitches[40:47])\n",
    "# print(len(pd.unique(dfSwitchGears['Loc_No'].values.ravel()))) # 111\n",
    "\n",
    "MasterFile = pd.ExcelWriter('V2_GIS_Switches.xlsx')\n",
    "dfSwitches.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dfSwitches.shape)\n",
    "print('dfSG Shape:', dfSwitchGears.shape)\n",
    "print(dfSwitchGears.uniquevalues())\n",
    "# print(dfSwitches.head(5))\n",
    "# print(dfSwitchGears.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# colNames = {'Transformers:': list(dfTransformers.columns), 'Switches:': list(dfSwitches.columns),\n",
    "#            'Poles:': list(dfPoles.columns), 'Cables:': list(dfCables.columns), 'Fuses:':list(dfFuses.columns),\n",
    "#            'UGStructures:':list(dfUGStructures.columns)}\n",
    "# dfColNames = pd.Series(colNames)\n",
    "# print(dfColNames['Transformers:'])\n",
    "\n",
    "# Cables\n",
    "dropCablesCols = ['ENABLED', 'INSTALLATIONDATE', 'FEEDERID', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', \n",
    "                 'LENGTHSOURCE', 'MEASUREDLENGTH', 'LENGTHUOMCODE', 'WIRECOUNT', 'SUBTYPECD', 'LABELTEXT', \n",
    "                 'COMPATIBLEUNITID', 'PHASEDESIGNATION', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'ISFEEDERTRUNK', \n",
    "                 'NEUTRALUSECD', 'FEATURE_STATUS', 'CONDUCTOR_REJUVENATION', 'SHAPE_Length']\n",
    "\n",
    "\n",
    "\n",
    "#print(dfSwitches.head(5))\n",
    "\n",
    "\n",
    "# Rename OH Tx columns\n",
    "\n",
    "# Rename UG Tx columns\n",
    "\n",
    "# Rename Distribution Poles columns\n",
    "\n",
    "# Rename UG Cable columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transformer\n",
    "\n",
    "# separate into UG and OH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fuses\n",
    "\n",
    "dropFusesCols = ['ANCILLARYROLE', 'ENABLED', 'INSTALLATIONDATE', 'FEEDERID', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'GPSDATE', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLEUNITID', 'PHASEDESIGNATION', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXCONTINUOUSCURRENT', 'MAXINTERRUPTINGCURRENT', 'MAXOPERATINGVOLTAGE', 'PRESENTPOSITION_R', 'PRESENTPOSITION_Y', 'PRESENTPOSITION_B', 'NORMALPOSITION_R', 'NORMALPOSITION_Y', 'NORMALPOSITION_B', 'DEVICENUMBER', 'FUSELINKSIZE', 'FEATURE_STATUS', 'SYMBOLROTATION', 'INSULATOR_MATERIAL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SwitchGrouped = dfNodesCopy.groupby('SwitchRegion')\n",
    "#print(SwitchGrouped.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #  Ctrl + A\n",
    "# # Ctrl + / to uncomment\n",
    "\n",
    "# # ****************************\n",
    "# # A. NODES sheet\n",
    "# # ****************************\n",
    "# # 1. Split 'Node Id' to 'NodeID_1' and 'NodeID_2'\n",
    "# dfNodes['NodeID_1'], dfNodes['NodeID_2'] = zip(*dfNodes['Node Id'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfNodesCopy = pd.DataFrame(dfNodes)\n",
    "# # 3. Rename all column headers to 'Nodes_' + x\n",
    "# dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "# #print(dfNodes_Copy.count())\n",
    "\n",
    "# # ****************************\n",
    "# # B. MASTER SPREADSHEET\n",
    "# # ****************************\n",
    "# # Copy dfNodesCopy into dfMaster\n",
    "# dfMaster = pd.DataFrame(dfNodesCopy)\n",
    "# # print(dfMaster.count())\n",
    "# # Nodes_NodeID_1 and Nodes_NodeID_2 are keys\n",
    "\n",
    "# # ****************************\n",
    "# # C. Topology sheet\n",
    "# # ****************************\n",
    "# # 1. No renaming here,so freate a 'copy' dataframe\n",
    "# dfTopologyCopy = pd.DataFrame(dfTopology)\n",
    "# # 2. Rename all column headers to 'Topology_' + x\n",
    "# dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "# #print(dfTopologyCopy.count())\n",
    "\n",
    "# # 3. Combine topology sheet\n",
    "# # pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')\n",
    "# # dfFinal = \n",
    "# # Topology - more match with 'Topology_Coord. Y' over 'Topology_Coord. X'\n",
    "# dfMaster = pd.merge(dfMaster, dfTopologyCopy, how='outer', left_on='Nodes_NodeID_2', right_on ='Topology_Coord. Y')\n",
    "# #print(dfMaster.count())\n",
    "\n",
    "\n",
    "# # ****************************\n",
    "# # D. Fuses sheet \n",
    "# # ****************************\n",
    "# # 1. Split 'From Node' to 'FromNode_xCoord' and 'FromNode_yCoord'\n",
    "# dfFuses['FromNode_xCoord'], dfFuses['FromNode_yCoord'] = zip(*dfFuses['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Split 'To Node' to 'ToNode_FuseID' and 'ToNode_FdrID'\n",
    "# dfFuses['ToNode_FuseID'], dfFuses['ToNode_FdrID'] = zip(*dfFuses['To Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 3. Create a 'Copy' dataframe\n",
    "# dfFusesCopy = pd.DataFrame(dfFuses)\n",
    "# # 4. Rename all column headers to 'Fuses_' + x\n",
    "# dfFusesCopy.rename(columns=lambda x:'Fuses_'+x, inplace=True)\n",
    "# # 5. Combine Fuses sheet with Master\n",
    "# dfMaster = pd.merge(dfMaster, dfFusesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Fuses_FromNode_xCoord')\n",
    "# #print(dfMaster.count())\n",
    "\n",
    "# # ****************************\n",
    "# # D1. Output excel file - For VERIFICATION purposes\n",
    "# # ****************************\n",
    "# # Verify the excel file \n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# # http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# # MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# # dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# # MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ctrl + / to uncomment\n",
    "\n",
    "# # ****************************\n",
    "# # E. Switch sheet \n",
    "# # ****************************\n",
    "# # 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "# dfSwitches['FromNode_1'], dfSwitches['FromNode_2'] = zip(*dfSwitches['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfSwitchesCopy = pd.DataFrame(dfSwitches)\n",
    "# # 3. Rename all column headers to 'Switches_' + x\n",
    "# dfSwitchesCopy.rename(columns=lambda x:'Switches_'+x, inplace=True)\n",
    "# # 4. Combine Switches sheet with Master: \n",
    "# # 4.1 First with 'Switches_FromNode_1' - NodeID_1 also has '109-D'/'7-S' switch id :)\n",
    "# dfMaster = pd.merge(dfMaster, dfSwitchesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Switches_FromNode_1')\n",
    "# # 4.2 Second with 'Section Id' of FusesCopy - maybe not necessary\n",
    "\n",
    "# # ****************************\n",
    "# # F. Transformer aka \"Loads\" in CYME\n",
    "# # ****************************\n",
    "# # \n",
    "# # 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "# dfLoads['FromNode_1'], dfLoads['FromNode_2'] = zip(*dfLoads['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfLoadsCopy = pd.DataFrame(dfLoads)\n",
    "# # 3. Rename all column headers to Loads_' + x\n",
    "# dfLoadsCopy.rename(columns=lambda x:'Loads_'+x, inplace=True)\n",
    "# # 4. Combine all Loads with 'FromNode_1'  with dfMaster\n",
    "# dfMaster = pd.merge(dfMaster, dfLoadsCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Loads_FromNode_1')\n",
    "# # 4.2 May need to combine dfLoadsCopy with dfSpotLoads if tx nameplate rating not same\n",
    "\n",
    "\n",
    "# #Plot\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# pd.options.display.mpl_style = 'default'\n",
    "# #dfSwitches.boxplot()\n",
    "# #dfFusesCopy.boxplot(column=\"Fuses_Rating(A)\")\n",
    "# #mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)\n",
    "# dfFusesCopy['Fuses_FromNode_xCoord'] = dfFusesCopy['Fuses_FromNode_xCord'].convert_objects(convert_numeric=True)\n",
    "# dfFusesCopy['Fuses_FromNode_yCoord'] = dfFusesCopy['Fuses_FromNode_yCord'].convert_objects(convert_numeric=True)\n",
    "# #dfFusesCopy.plot(kind='scatter', x='Fuses_FromNode_xCoord', y='Fuses_FromNode_yCoord')\n",
    "\n",
    "\n",
    "# # ****************************\n",
    "# # D1. Output excel file\n",
    "# # ****************************\n",
    "# # Verify the excel file \n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# # http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# #MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# #dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# #MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************************\n",
    "# G. PRID to each region\n",
    "# ****************************\n",
    "# combine PRID to Tx?\n",
    "\n",
    "# ****************************\n",
    "# H. Cable \n",
    "# ****************************\n",
    "# combine cable and conductors\n",
    "\n",
    "# ****************************\n",
    "# I. Conductors  \n",
    "# ****************************\n",
    "# combine poles\n",
    "\n",
    "# ****************************\n",
    "# J. Poles \n",
    "# ****************************\n",
    "# Output excel file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
