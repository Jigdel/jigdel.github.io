{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Feeders:  36\n",
      "(12096, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# fileName - iterate through entire folder :)\n",
    "#fileName = '3S3-1_Crestwood_Feeder_Details.xlsx'\n",
    "\n",
    "#input directory\n",
    "inputDirectory = 'Metsco_Feeder_Reports'\n",
    "\n",
    "# define filepath and sort the file list\n",
    "filesList = glob(os.path.join(inputDirectory, '*.xlsx'))\n",
    "numFiles = len(filesList)\n",
    "print('Number of Feeders: ', numFiles)\n",
    "sortedFileList = sorted(filesList)\n",
    "\n",
    "# variables\n",
    "dictFeeders = {}\n",
    "allNodes_list = pd.DataFrame()\n",
    "\n",
    "# read text files in tweet_input directory\n",
    "for f in sortedFileList:\n",
    "\n",
    "    fileName = os.path.basename(f).split('_')\n",
    "    FeederKey = fileName[0]\n",
    "    #print(FeederKey)\n",
    "    \n",
    "    if ('$' not in FeederKey):\n",
    "        # Read CYME Feeder xlsx file into dataframes\n",
    "        with pd.ExcelFile(f) as xlsx:\n",
    "            #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "            dfTopology = pd.read_excel(xlsx, 'Topology') # 280 rows\n",
    "            dfSpotLoads = pd.read_excel(xlsx, 'Spot Loads') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "            dfLoads = pd.read_excel(xlsx, 'Loads') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "            dfCables = pd.read_excel(xlsx, 'Cables')\n",
    "            dfSwitches = pd.read_excel(xlsx, 'Switches') # 41 items\n",
    "            dfNodes = pd.read_excel(xlsx, 'Nodes') # 249 items\n",
    "            dfOHlines = pd.read_excel(xlsx, 'OverheadLinesByPhase') #Neutral - 94, Section Id - 381\n",
    "            dfFuses = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "\n",
    "            # # Strip '\\n' from column headers\n",
    "            dfTopology.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSpotLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfCables.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSwitches.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfNodes.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfOHlines.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfFuses.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            #print(dfNodes.columns)\n",
    "            allNodes_list = allNodes_list.append(dfNodes)\n",
    "\n",
    "            # Split 'Nodes_Node Id' to 'NodeID_1' and 'NodeID_2' for 'SwitchRegion'\n",
    "            #dfSwitches['NodeID_1'], dfNodesCopy['NodeID_2'] = zip(*dfNodesCopy['Nodes_Node Id'].\n",
    "            #apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "            \n",
    "#             cableLength = sum(dfCables['Length(m)'])/1000\n",
    "#             txCounts = len(dfLoads['Spot Number'])\n",
    "#             fuseCounts = len(dfFuses['Equipment Id'])\n",
    "#             switchCounts = len(dfSwitches['Equipment Id'])\n",
    "            \n",
    "            \n",
    "            #print(FeederKey,':',cableLength,'kms')\n",
    "            #dictFeeders.update({FeederKey:[cableLength, txCounts, switchCounts,fuseCounts]})\n",
    "        \n",
    "# Write to excel file\n",
    "# dfFdrs = pd.DataFrame(dictFeeders)\n",
    "# dfFdrs = dfFdrs.transpose()\n",
    "# dfFdrs.columns =['Cables','Transformer', 'Switches','Fuses']\n",
    "#print(dfFdrs)\n",
    "# print(ugSwitches)\n",
    "# MasterFile = pd.ExcelWriter('AllFeeders.xlsx')\n",
    "# dfFdrs.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "MasterFile = pd.ExcelWriter('AllNodes.xlsx')\n",
    "allNodes_list.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "print(allNodes_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fileName - iterate through entire folder :)\n",
    "fileName = 'Original_FiveAssetClasses_Copy.xlsx'\n",
    "#fileNameOtherDevices = 'Other Device Numbers.xls'\n",
    "#fileNamePolesClassHeight = 'Poles_class_height.xlsx' # Poles_class_height table\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(fileName) as xlsx:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfTransformersV1 = pd.read_excel(xlsx, 'Transformers') # 280 rows\n",
    "    dfSwitchesV1 = pd.read_excel(xlsx, 'Switches') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "    dfPolesV1 = pd.read_excel(xlsx, 'Poles') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "    dfCablesV1 = pd.read_excel(xlsx, 'UGPrimaryCables')\n",
    "    dfFusesV1 = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "    dfUGStructuresV1 = pd.read_excel(xlsx,'UGStructures')\n",
    "\n",
    "    \n",
    "# df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Remove ' ' in 1R 1-S but some FEEDERID values are float. Will do it manually\n",
    "# dfTransformersV1['FEEDERID'] = dfTransformers['FEEDERID'].apply(lambda x: x.replace(' ', '') if ' ' in x else x)\n",
    "# dfSwitchesV1['FEEDERID'] = dfSwitchesV1['FEEDERID'].apply(lambda x: x.replace(' ', '') if ' ' in x else x)\n",
    "# dfCablesV1['FEEDERID'] = dfCablesV1['FEEDERID'].apply(lambda x: x.replace(' ', '') if ' ' in x else x)\n",
    "# dfFusesV1['FEEDERID'] = dfFusesV1['FEEDERID'].apply(lambda x: x.replace(' ', '') if ' ' in x else x)\n",
    "\n",
    "Summary = {'Transformers:': dfTransformersV1.shape, 'Switches:': dfSwitchesV1.shape,'Poles:': dfPolesV1.shape, \n",
    "           'Cables:': dfCablesV1.shape, 'Fuses:':dfFusesV1.shape, 'UGStructures:':dfUGStructuresV1.shape}\n",
    "dfSummary = pd.DataFrame(Summary)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformersV2 = dfTransformersV1\n",
    "dfSwitchesV2 = dfSwitchesV1\n",
    "dfPolesV2 = dfPolesV1\n",
    "dfCablesV2 = dfCablesV1\n",
    "dfFusesV2 = dfFusesV1\n",
    "dfUGStructuresV2 = dfUGStructuresV1\n",
    "\n",
    "# 17 columns dropped\n",
    "dropCommonColumns = ['OBJECTID','WORKORDERID','FIELDVERIFY','COMMENTS','CREATIONUSER','DATECREATED','LASTUSER',\n",
    "                     'DATEMODIFIED','WORKREQUESTID','DESIGNID','WORKLOCATIONID','WMSID','WORKFLOWSTATUS',\n",
    "                     'WORKFUNCTION','GISONUMBER','GISOTYPENBR','OWNERSHIP']\n",
    "\n",
    "#*************************#\n",
    "#****DEFINITIONS**********#\n",
    "#*************************#\n",
    "def drop_columns(dfAssetClass, dropColumns):\n",
    "    dfAssetClass = dfAssetClass.drop(dropColumns, axis=1)\n",
    "    return dfAssetClass\n",
    "\n",
    "def new_columns(dfAssetClass, numAssetRows, columnID):\n",
    "    dfAssetClass[columnID] = pd.DataFrame(np.empty([numAssetRows,1]).cumsum(axis=1))\n",
    "    dfAssetClass.loc[:,columnID] = np.nan\n",
    "    return dfAssetClass[columnID]\n",
    "\n",
    "#*************************#\n",
    "#****DEFINITIONS**********#\n",
    "#*************************#\n",
    "\n",
    "#Drop all common columns \n",
    "dfSwitchesV2 = drop_columns(dfSwitchesV2, dropCommonColumns)\n",
    "dfTransformersV2 = drop_columns(dfTransformersV2, dropCommonColumns)\n",
    "dfFusesV2 = drop_columns(dfFusesV2,dropCommonColumns)\n",
    "dfCablesV2 = drop_columns(dfCablesV2, dropCommonColumns)\n",
    "dfUGStructuresV2 = drop_columns(dfUGStructuresV2, dropCommonColumns)\n",
    "dfPolesV2 = drop_columns(dfPolesV2, dropCommonColumns)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "# SummaryV2 = {'Transformers:': dfTransformers.shape, 'Switches:': dfSwitches.shape,'Poles:': dfPoles.shape, \n",
    "#            'Cables:': dfCables.shape, 'Fuses:':dfFuses.shape, 'UGStructures:':dfUGStructures.shape}\n",
    "# dfSummaryV2 = pd.DataFrame(SummaryV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numTxRows = len(dfTransformers['DEVICENUMBER'])\n",
    "# numPolesRows = len(dfPoles['DEVICENUMBER'])\n",
    "# numSwitchRows = len(dfSwitches['DEVICENUMBER'])\n",
    "# numFusesRows = len(dfFuses['DEVICENUMBER'])\n",
    "\n",
    "# df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "dfGroupedTxFdrs = pd.DataFrame(dfTransformers.groupby(by=['FEEDERID'])['DEVICENUMBER'].count())\n",
    "dfGroupedSwitchFdrs = pd.DataFrame(dfSwitches.groupby(by=['FEEDERID'])['DEVICENUMBER'].count())\n",
    "dfGroupedFusesFdrs = pd.DataFrame(dfFuses.groupby(by=['FEEDERID'])['DEVICENUMBER'].count())\n",
    "dfGroupedCableFdrs = pd.DataFrame(dfCables.groupby(by=['FEEDERID'])['MEASUREDLENGTH'].sum())\n",
    "\n",
    "# dfGroupedTxFdrs['FdrID']= dfGroupedTxFdrs.index\n",
    "# dfGroupedSwitchFdrs['FdrID']= dfGroupedSwitchFdrs.index\n",
    "# dfGroupedFusesFdrs['FdrID']= dfGroupedFusesFdrs.index\n",
    "# dfGroupedCableFdrs['FdrID']= dfGroupedCableFdrs.index\n",
    "\n",
    "# cols = ['FdrID', 'DEVICENUMBER']\n",
    "# cols2 = ['FdrID', 'MEASUREDLENGTH']\n",
    "# dfGroupedTxFdrs = dfGroupedTxFdrs[cols]\n",
    "# dfGroupedSwitchFdrs = dfGroupedSwitchFdrs[cols]\n",
    "# dfGroupedFusesFdrs = dfGroupedFusesFdrs[cols]\n",
    "# dfGroupedCableFdrs = dfGroupedCableFdrs[cols2]\n",
    "\n",
    "# frames = [dfGroupedCableFdrs, dfGroupedTxFdrs, dfGroupedSwitchFdrs, dfGroupedFusesFdrs]\n",
    "# dfGroupedAll = pd.concat(frames, ignore_index=True, keys='FdrID')\n",
    "# print(dfGroupedAll.head(2))\n",
    "\n",
    "#print(dfGroupedTxFdrs.head(3))\n",
    "#print(dfGroupedSwitchFdrs.head(3))\n",
    "# print(dfGroupedFusesFdrs.head(3))\n",
    "#print(len(dfGroupedTxFdrs))\n",
    "# print(len(dfGroupedSwitchFdrs))\n",
    "# print(len(dfGroupedFusesFdrs))\n",
    "\n",
    "\n",
    "frames = [dfGroupedCableFdrs, dfGroupedTxFdrs, dfGroupedSwitchFdrs, dfGroupedFusesFdrs]\n",
    "# dfGroupedAll = dfGroupedCableFdrs.append(dfGroupedTxFdrs)\n",
    "\n",
    "# print(dfGroupedAll.head(2))\n",
    "#dfGroupedAll = pd.DataFrame(dfGroupedTxFdrs.merge(dfGroupedSwitchFdrs, how='inner', on='FdrID'))\n",
    "\n",
    "#pd.concat([s3, s4, s5], axis=1, keys=['red','blue','yellow'])\n",
    "#dfGroupedAll = pd.concat(frames, ignore_index=True, keys=['FdrID', 'Cables', 'Tx', 'Switches'])\n",
    "dfGroupedAll = dfGroupedCableFdrs.append([dfGroupedTxFdrs, dfGroupedSwitchFdrs, dfGroupedFusesFdrs])\n",
    "# print(dfGroupedAll.head(2))\n",
    "#dfGroupedAll = dfGroupedAll.merge(dfGroupedFusesFdrs, how='left', on='FdrID')\n",
    "#print(dfGroupedAll.head(2))\n",
    "MasterFile = pd.ExcelWriter('AllFeedersGIS.xlsx')\n",
    "dfGroupedAll.to_excel(MasterFile, 'GIS')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#seriesFdrs = pd.DataFrame(dictFeeders, index=['Cable (kms)', 'Tx Counts', 'Switch Counts', 'Fuse Counts'])\n",
    "#print(seriesFdrs)\n",
    "#dfFdrs = pd.DataFrame(dictFeeders.items(), columns=['Feeder', 'Cable (kms)', 'Tx Counts', 'Switch Counts', 'Fuse Counts'])\n",
    "#dfFdrs = pd.DataFrame.to_dict(dictFeeders, orient='index')\n",
    "dfFdrs = pd.DataFrame(dictFeeders)\n",
    "dfFdrs = dfFdrs.transpose()\n",
    "dfFdrs.columns =['Cables','Transformer', 'Switches','Fuses']\n",
    "# print(dfFdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:       24.1101\n",
      "total:     24.1101\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Quick and fast peek into sheet names\n",
    "#xls = xlrd.open_workbook(r'<path_to_your_excel_file>', on_demand=True)\n",
    "# Fdr1 = xlrd.open_workbook(r'3S3-1_Crestwood_Feeder_Details.xlsx', on_demand=True)\n",
    "# print(Fdr1.sheet_names()) # <- remember: xlrd sheet_names is a function, not a property\n",
    "\n",
    "#import timeit\n",
    "#timeit.timeit('pd.read_excel(fileName, \"Topology\")', number=10000)\n",
    "#%timeit(pd.read_excel(fileName, 'Topology')) # 561 ms per loop (best out of 3)\n",
    "#%timeit(pd.ExcelFile(fileName).parse('Topology')) # 539 ms per loop (best out of 3)\n",
    "\n",
    "\n",
    "# Sources:\n",
    "# http://www.swegler.com/becky/blog/2014/08/06/useful-pandas-snippets/\n",
    "# http://stackoverflow.com/questions/12250024/how-to-obtain-sheet-names-from-xls-files-without-loading-the-whole-file-in-pytho\n",
    "# Read excel sheets: http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel-reader\n",
    "\n",
    "#print(dfCables.count())\n",
    "#Feeder = pd.read_excel('3S3-1_Crestwood_Feeder_Details.xlsx', 0, index_col=None, na_values=['NA'])\n",
    "#print(Feeder)\n",
    "\n",
    "#timeit.timeit('\"-\".join(str(n) for n in range(100))', number=10000)\n",
    "\n",
    "#import timeit\n",
    "#timeit.timeit('pd.read_excel(fileName, \"Topology\")', number=10000)\n",
    "#%timeit(pd.read_excel(fileName, 'Topology')) # 561 ms per loop (best out of 3)\n",
    "#%timeit(pd.ExcelFile(fileName).parse('Topology')) # 539 ms per loop (best out of 3)\n",
    "\n",
    "#print('Sum of cable length:', sum(dfCables['Length(m)'])/1000, 'kms')\n",
    "cableLength = sum(dfCables['Length(m)'])/1000\n",
    "dictMaster = {'Sum:' : cableLength, 'total: ':cableLength}\n",
    "dfMaster = pd.Series(dictMaster, )\n",
    "print(dfMaster)\n",
    "#pd.DataFrame(d.items(), columns=['Date', 'DateValue'])\n",
    "# MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ****************************\n",
    "# A. NODES sheet\n",
    "# ****************************\n",
    "# 1. Split 'Node Id' to 'NodeID_1' and 'NodeID_2'\n",
    "dfNodes['NodeID_1'], dfNodes['NodeID_2'] = zip(*dfNodes['Node Id'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# 2. Create a 'Copy' dataframe\n",
    "dfNodesCopy = pd.DataFrame(dfNodes)\n",
    "# 3. Rename al column headers to 'Nodes_' + x\n",
    "dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "#print(dfNodes_Copy.count())\n",
    "\n",
    "# ****************************\n",
    "# B. MASTER SPREADSHEET\n",
    "# ****************************\n",
    "# Copy dfNodesCopy into dfMaster\n",
    "dfMaster = pd.DataFrame(dfNodesCopy)\n",
    "# print(dfMaster.count())\n",
    "# Nodes_NodeID_1 and Nodes_NodeID_2 are keys\n",
    "\n",
    "# ****************************\n",
    "# C. Topology sheet\n",
    "# ****************************\n",
    "# 1. No renaming here,so freate a 'copy' dataframe\n",
    "dfTopologyCopy = pd.DataFrame(dfTopology)\n",
    "# 2. Rename all column headers to 'Topology_' + x\n",
    "dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "#print(dfTopologyCopy.count())\n",
    "\n",
    "# 3. Combine topology sheet\n",
    "# pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')\n",
    "# dfFinal = \n",
    "# Topology - more match with 'Topology_Coord. Y' over 'Topology_Coord. X'\n",
    "dfMaster = pd.merge(dfMaster, dfTopologyCopy, how='outer', left_on='Nodes_NodeID_2', right_on ='Topology_Coord. Y')\n",
    "#print(dfMaster.count())\n",
    "\n",
    "\n",
    "# ****************************\n",
    "# D. Fuses sheet \n",
    "# ****************************\n",
    "# 1. Split 'From Node' to 'FromNode_xCoord' and 'FromNode_yCoord'\n",
    "dfFuses['FromNode_xCoord'], dfFuses['FromNode_yCoord'] = zip(*dfFuses['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# 2. Split 'To Node' to 'ToNode_FuseID' and 'ToNode_FdrID'\n",
    "dfFuses['ToNode_FuseID'], dfFuses['ToNode_FdrID'] = zip(*dfFuses['To Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# 3. Create a 'Copy' dataframe\n",
    "dfFusesCopy = pd.DataFrame(dfFuses)\n",
    "# 4. Rename all column headers to 'Fuses_' + x\n",
    "dfFusesCopy.rename(columns=lambda x:'Fuses_'+x, inplace=True)\n",
    "# 5. Combine Fuses sheet with Master\n",
    "dfMaster = pd.merge(dfMaster, dfFusesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Fuses_FromNode_xCoord')\n",
    "#print(dfMaster.count())\n",
    "\n",
    "# ****************************\n",
    "# D1. Output excel file - For VERIFICATION purposes\n",
    "# ****************************\n",
    "# Verify the excel file \n",
    "# http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ****************************\n",
    "# E. Switch sheet \n",
    "# ****************************\n",
    "# 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "dfSwitches['FromNode_1'], dfSwitches['FromNode_2'] = zip(*dfSwitches['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# 2. Create a 'Copy' dataframe\n",
    "dfSwitchesCopy = pd.DataFrame(dfSwitches)\n",
    "# 3. Rename all column headers to 'Switches_' + x\n",
    "dfSwitchesCopy.rename(columns=lambda x:'Switches_'+x, inplace=True)\n",
    "# 4. Combine Switches sheet with Master: \n",
    "# 4.1 First with 'Switches_FromNode_1' - NodeID_1 also has '109-D'/'7-S' switch id :)\n",
    "dfMaster = pd.merge(dfMaster, dfSwitchesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Switches_FromNode_1')\n",
    "# 4.2 Second with 'Section Id' of FusesCopy - maybe not necessary\n",
    "\n",
    "# ****************************\n",
    "# F. Transformer aka \"Loads\" in CYME\n",
    "# ****************************\n",
    "# \n",
    "# 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "dfLoads['FromNode_1'], dfLoads['FromNode_2'] = zip(*dfLoads['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# 2. Create a 'Copy' dataframe\n",
    "dfLoadsCopy = pd.DataFrame(dfLoads)\n",
    "# 3. Rename all column headers to Loads_' + x\n",
    "dfLoadsCopy.rename(columns=lambda x:'Loads_'+x, inplace=True)\n",
    "# 4. Combine all Loads with 'FromNode_1'  with dfMaster\n",
    "dfMaster = pd.merge(dfMaster, dfLoadsCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Loads_FromNode_1')\n",
    "# 4.2 May need to combine dfLoadsCopy with dfSpotLoads if tx nameplate rating not same\n",
    "\n",
    "# ****************************\n",
    "# D1. Output excel file\n",
    "# ****************************\n",
    "# Verify the excel file \n",
    "# http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "# ****************************\n",
    "# G. PRID to each region\n",
    "# ****************************\n",
    "# combine PRID to Tx?\n",
    "\n",
    "# ****************************\n",
    "# H. Cable \n",
    "# ****************************\n",
    "# combine cable and conductors\n",
    "\n",
    "# ****************************\n",
    "# I. Conductors  \n",
    "# ****************************\n",
    "# combine poles\n",
    "\n",
    "# ****************************\n",
    "# J. Poles \n",
    "# ****************************\n",
    "# Output excel file\n",
    "\n",
    "# Delete dataframes or drop columns\n",
    "#dfNodes_Copy = dfNodes_Copy.drop('Nodes_Network Id\\n',1)\n",
    "# del dfNodes_Copy\n",
    "\n",
    "#print(dfMaster)\n",
    "\n",
    "#dfFuses['FromNode_xCoord'], dfFuses['FromNode_yCoord'] = zip(*dfFuses['From Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "#dfFuses['ToNode_FuseID'], dfFuses['ToNode_FdrID'] = zip(*dfFuses['To Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "\n",
    "#dfMaster['FromNode_xCoord'], dfMaster['FromNode_yCoord'] = zip(*dfFuses['From Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "#dfMaster['ToNode_FuseID'], dfMaster['ToNode_FdrID'] = zip(*dfFuses['To Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "#print(dfMaster['FromNode_xCoord'].count()) # 44 values :)\n",
    "#print(dfMaster['FromNode_xCoord'])\n",
    "\n",
    "# ['Cmd' + '/' to uncomment]\n",
    "# *****Rename all columns for each sheets \n",
    "# Rename the _copy versions\n",
    "# dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "# dfSpotLoadsCopy.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
    "# dfLoadsCopy.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
    "# dfCablesCopy.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
    "# dfSwitchesCopy.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
    "# dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "# dfOHlinesCopy.rename(columns=lambda x: 'OHlinesByPhase_'+x, inplace=True)\n",
    "# dfFusesCopy.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n",
    "# ******rename the original version****\n",
    "# dfTopology.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "# dfSpotLoads.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
    "# dfLoads.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
    "# dfCables.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
    "# dfSwitches.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
    "# dfNodes.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "# dfOHlines.rename(columns=lambda x: 'OHlinesByPhase_'+x, inplace=True)\n",
    "# dfFuses.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
