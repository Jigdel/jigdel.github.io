{
 "metadata": {
  "name": "",
  "signature": "sha256:f7956b01a71a27b66c712a81fd9ab03e76f6548044bb265a1c03fe4454201bb4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import xlrd\n",
      "\n",
      "# fileName - iterate through entire folder :)\n",
      "fileName = '3S3-1_Crestwood_Feeder_Details.xlsx'\n",
      "\n",
      "# Quick and fast peek into sheet names\n",
      "#xls = xlrd.open_workbook(r'<path_to_your_excel_file>', on_demand=True)\n",
      "# Fdr1 = xlrd.open_workbook(r'3S3-1_Crestwood_Feeder_Details.xlsx', on_demand=True)\n",
      "# print(Fdr1.sheet_names()) # <- remember: xlrd sheet_names is a function, not a property\n",
      "\n",
      "# Read CYME Feeder xlsx file into dataframes\n",
      "with pd.ExcelFile(fileName) as xlsx:\n",
      "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
      "    dfTopology = pd.read_excel(xlsx, 'Topology') # 280 rows\n",
      "    dfSpotLoads = pd.read_excel(xlsx, 'Spot Loads') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
      "    dfLoads = pd.read_excel(xlsx, 'Loads') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
      "    dfCables = pd.read_excel(xlsx, 'Cables')\n",
      "    dfSwitches = pd.read_excel(xlsx, 'Switches') # 41 items\n",
      "    dfNodes = pd.read_excel(xlsx, 'Nodes') # 249 items\n",
      "    dfOHlines = pd.read_excel(xlsx, 'OverheadLinesByPhase') #Neutral - 94, Section Id - 381\n",
      "    dfFuses = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
      "\n",
      "# Sources:\n",
      "# http://www.swegler.com/becky/blog/2014/08/06/useful-pandas-snippets/\n",
      "# http://stackoverflow.com/questions/12250024/how-to-obtain-sheet-names-from-xls-files-without-loading-the-whole-file-in-pytho\n",
      "\n",
      "#print(dfCables.count())\n",
      "#Feeder = pd.read_excel('3S3-1_Crestwood_Feeder_Details.xlsx', 0, index_col=None, na_values=['NA'])\n",
      "#print(Feeder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "# ****************************\n",
      "# A. NODES sheet\n",
      "# ****************************\n",
      "# 1. Split 'Node Id' to 'NodeID_1' and 'NodeID_2'\n",
      "dfNodes['NodeID_1'], dfNodes['NodeID_2'] = zip(*dfNodes['Node Id\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
      "# 2. Create a 'Copy' dataframe\n",
      "dfNodesCopy = pd.DataFrame(dfNodes)\n",
      "# 3. Rename al column headers to 'Nodes_' + x\n",
      "dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
      "#print(dfNodes_Copy.count())\n",
      "\n",
      "# ****************************\n",
      "# B. MASTER SPREADSHEET\n",
      "# ****************************\n",
      "# Copy dfNodesCopy into dfMaster\n",
      "dfMaster = pd.DataFrame(dfNodesCopy)\n",
      "\n",
      "# ****************************\n",
      "# C. Topology sheet\n",
      "# ****************************\n",
      "# 1. No renaming here,so freate a 'copy' dataframe\n",
      "dfTopologyCopy = pd.DataFrame(dfTopology)\n",
      "# 2. Rename all column headers to 'Topology_' + x\n",
      "dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
      "\n",
      "# C. Combine topology sheet\n",
      "#pd.merge(dfFinal, dfTopology, on=['key1', 'key2'])\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# combine fuses sheet\n",
      "#*** FUSES sheet ***\n",
      "# 1. Split 'From Node' to 'FromNode_xCoord' and 'FromNode_yCoord'\n",
      "# 2. Split 'To Node' to 'ToNode_FuseID' and 'ToNode_FdrID'\n",
      "# 3. Create a 'Copy' dataframe\n",
      "# 4. Rename all column headers to 'Fuses_' + x\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# combine switch sheet\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# combine transformer\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# combine PRID to Tx?\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# combine cable and conductors\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# combine poles\n",
      "\n",
      "# ****************************\n",
      "# . \n",
      "# ****************************\n",
      "# Output excel file\n",
      "\n",
      "# Delete dataframes or drop columns\n",
      "#dfNodes_Copy = dfNodes_Copy.drop('Nodes_Network Id\\n',1)\n",
      "# del dfNodes_Copy\n",
      "\n",
      "#print(dfMaster)\n",
      "\n",
      "#dfFuses['FromNode_xCoord'], dfFuses['FromNode_yCoord'] = zip(*dfFuses['From Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
      "#dfFuses['ToNode_FuseID'], dfFuses['ToNode_FdrID'] = zip(*dfFuses['To Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
      "\n",
      "#dfMaster['FromNode_xCoord'], dfMaster['FromNode_yCoord'] = zip(*dfFuses['From Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
      "#dfMaster['ToNode_FuseID'], dfMaster['ToNode_FdrID'] = zip(*dfFuses['To Node\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
      "#print(dfMaster['FromNode_xCoord'].count()) # 44 values :)\n",
      "#print(dfMaster['FromNode_xCoord'])\n",
      "\n",
      "# ['Cmd' + '/' to uncomment]\n",
      "# *****Rename all columns for each sheets \n",
      "# Rename the _copy versions\n",
      "# dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
      "# dfSpotLoadsCopy.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
      "# dfLoadsCopy.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
      "# dfCablesCopy.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
      "# dfSwitchesCopy.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
      "# dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
      "# dfOHlinesCopy.rename(columns=lambda x: 'OHlinesByPhase_'+x, inplace=True)\n",
      "# dfFusesCopy.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n",
      "# ******rename the original version****\n",
      "# dfTopology.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
      "# dfSpotLoads.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
      "# dfLoads.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
      "# dfCables.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
      "# dfSwitches.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
      "# dfNodes.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
      "# dfOHlines.rename(columns=lambda x: 'OHlinesByPhase_'+x, inplace=True)\n",
      "# dfFuses.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read excel sheets\n",
      "# Source: http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel-reader\n",
      "\n",
      "# using the ExcelFile class\n",
      "data = {}\n",
      "with pd.ExcelFile('3S3-1_Crestwood_Feeder_Details.xlsx') as FdrFile:\n",
      "    data['Fuses'] = pd.read_excel(FdrFile, 'Fuses', index_col=None, na_values=['NA'])\n",
      "    data['Nodes'] = pd.read_excel(FdrFile, 'Nodes', index_col=None, na_values=['NA'])\n",
      "\n",
      "# equivalent using the read_excel function\n",
      "#data = read_excel('path_to_file.xls', ['Sheet1', 'Sheet2'], index_col=None, na_values=['NA'])\n",
      "\n",
      "# print(data['Fuses'].count())\n",
      "# print(data['Nodes'].count()) # each column count\n",
      "\n",
      "# print(data['Fuses'].keys()) # prints all the keys i.e. column headers\n",
      "# print(data['Fuses'].keys()[0]) # prints first key of the 'Fuses' dict i.e. \"Network Id\"\n",
      "# print(data['Fuses']['Network Id\\n']) # prints all key column values; note the '\\n' in the key\n",
      "\n",
      "# Parsing specific columns\n",
      "# read_excel('path_to_file.xls', 'Sheet1', parse_cols=2)\n",
      "\n",
      "#print(data['Fuses'].keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import numpy as np\n",
      "\n",
      "#print(data['Fuses']['To Node\\n'])\n",
      "\n",
      "# Separate 'To Node' column values\n",
      "# Split delimited values in a DataFrame column into two new columns\n",
      "#df['new_col1'], df['new_col2'] = zip(*df['original_col'].apply(lambda x: x.split(': ', 1)))\n",
      "\n",
      "# ** Fuses sheet **\n",
      "# del data['Fuses']['NodeIDsecond'] # delete column\n",
      "# print(data['Fuses']['To Node\\n']) # prints '548-F_3S3-1'\n",
      "# data['Fuses']['ToNodeFirst'], data['Fuses']['ToNodeSecond'] = zip(*data['Fuses']['To Node\\n'].apply(lambda x: x.split('_', 1)))\n",
      "# print(data['Fuses']['ToNodeFirst'].count()) #44\n",
      "# print(data['Fuses']['ToNodeFirst']) # prints all fuses\n",
      "\n",
      "# **Nodes sheet **\n",
      "# print(data['Nodes'].keys()) # Index(['Network Id\\n', 'Node Id\\n', 'Phase\\n'], dtype='object')\n",
      "# print(data['Nodes']['Node Id\\n'].unique()) # print unique list of values\n",
      "# print(data['Nodes']['Node Id\\n']) # prints '22-D_3S3-1','24045.721_5540100.592','280-S_3S3-1'\n",
      "data['Nodes']['NodeIDfirst'], data['Nodes']['NodeIDsecond'] = zip(*data['Nodes']['Node Id\\n'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
      "print(data['Nodes']['Node Id\\n'].count())\n",
      "print(data['Nodes']['NodeIDfirst'].count())\n",
      "print(data['Nodes']['NodeIDsecond'].count())\n",
      "\n",
      "# (lambda x: re.split('(\\W+)', x))\n",
      "#lambda x: x.split('_',1)\n",
      "#line.strip().find(' ') != -1 # not finding the ' ' character in the string\n",
      "#(df.new_col1.apply(lambda x: x.str.split('|')[1] if len(x.str.split()) == 2 else None))\n",
      "\n",
      "print(data['Nodes'].keys())\n",
      "\n",
      "#df.groupby(\"date\").agg({\"duration\": np.sum, \"user_id\": pd.Series.nunique})\n",
      "# table.groupby('YEARMONTH').CLIENTCODE.nunique()\n",
      "# print unique value counts\n",
      "print(data.groupby(['Nodes'])['NodeIDfirst'].nunique())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "649\n",
        "649\n",
        "647\n",
        "Index(['Network Id\\n', 'Node Id\\n', 'Phase\\n', 'NodeIDfirst', 'NodeIDsecond'], dtype='object')\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'dict' object has no attribute 'groupby'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-83-528a4bf67df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# table.groupby('YEARMONTH').CLIENTCODE.nunique()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# print unique value counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NodeIDfirst'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'groupby'"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}