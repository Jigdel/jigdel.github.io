{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cables:  Fuses:  Poles:  Switches:  Transformers:  UGStructures:\n",
      "0     3865     736   18961        537           3618          16883\n",
      "1       39      46      31         52             57             40\n",
      "   Cables:  Fuses:  Poles:  Switches:  Transformers:  UGStructures:\n",
      "0     3865     736   18961        537           3618          16883\n",
      "1       22      29      14         35             40             23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import re\n",
    "#import xlrd\n",
    "\n",
    "# fileName - iterate through entire folder :)\n",
    "fileName = 'Original_FiveAssetClasses.xlsx'\n",
    "#fileNameOtherDevices = 'Other Device Numbers.xls'\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(fileName) as xlsx:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfTransformersV1 = pd.read_excel(xlsx, 'Transformers') # 280 rows\n",
    "    dfSwitchesV1 = pd.read_excel(xlsx, 'Switches') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "    dfPolesV1 = pd.read_excel(xlsx, 'Poles') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "    dfCablesV1 = pd.read_excel(xlsx, 'UGPrimaryCables')\n",
    "    dfFusesV1 = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "    dfUGStructuresV1 = pd.read_excel(xlsx,'UGStructures')\n",
    "\n",
    "\n",
    "Summary = {'Transformers:': dfTransformersV1.shape, 'Switches:': dfSwitchesV1.shape,'Poles:': dfPolesV1.shape, \n",
    "           'Cables:': dfCablesV1.shape, 'Fuses:':dfFusesV1.shape, 'UGStructures:':dfUGStructuresV1.shape}\n",
    "dfSummary = pd.DataFrame(Summary)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformersV2 = dfTransformersV1\n",
    "dfSwitchesV2 = dfSwitchesV1\n",
    "dfPolesV2 = dfPolesV1\n",
    "dfCablesV2 = dfCablesV1\n",
    "dfFusesV2 = dfFusesV1\n",
    "dfUGStructuresV2 = dfUGStructuresV1\n",
    "\n",
    "# 17 columns dropped\n",
    "dropCommonColumns = ['OBJECTID','WORKORDERID','FIELDVERIFY','COMMENTS','CREATIONUSER','DATECREATED','LASTUSER',\n",
    "                     'DATEMODIFIED','WORKREQUESTID','DESIGNID','WORKLOCATIONID','WMSID','WORKFLOWSTATUS',\n",
    "                     'WORKFUNCTION','GISONUMBER','GISOTYPENBR','OWNERSHIP']\n",
    "\n",
    "def drop_columns(dfAssetClass, dropColumns):\n",
    "    dfAssetClass = dfAssetClass.drop(dropColumns, axis=1)\n",
    "    return dfAssetClass\n",
    "\n",
    "#Drop all common columns \n",
    "dfSwitchesV2 = drop_columns(dfSwitchesV2, dropCommonColumns)\n",
    "dfTransformersV2 = drop_columns(dfTransformersV2, dropCommonColumns)\n",
    "dfFusesV2 = drop_columns(dfFusesV2,dropCommonColumns)\n",
    "dfCablesV2 = drop_columns(dfCablesV2, dropCommonColumns)\n",
    "dfUGStructuresV2 = drop_columns(dfUGStructuresV2, dropCommonColumns)\n",
    "dfPolesV2 = drop_columns(dfPolesV2, dropCommonColumns)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "SummaryV2 = {'Transformers:': dfTransformers.shape, 'Switches:': dfSwitches.shape,'Poles:': dfPoles.shape, \n",
    "           'Cables:': dfCables.shape, 'Fuses:':dfFuses.shape, 'UGStructures:':dfUGStructures.shape}\n",
    "dfSummaryV2 = pd.DataFrame(SummaryV2)\n",
    "print(dfSummary)\n",
    "print(dfSummaryV2)\n",
    "# print(dfSummary-dfSummaryV2) # shows 17 cols dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save future wait times while running\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "# Switches\n",
    "fileNameOtherDevices = 'Other Device Numbers.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameOtherDevices) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfSwitchGears = pd.read_excel(xls, 'SWITCHGEARS') # 280 rows\n",
    "\n",
    "dropSGcols = ['Switch Gear', 'Adrs #','Location','City','Notes','To Type','Inst. Date','Mftr.','Catalog#','Serial#',\n",
    "             'DOM','Comments']\n",
    "\n",
    "dfSwitchGears = drop_columns(dfSwitchGears, dropSGcols)\n",
    "#dfSwitchGears = dfSwitchGears.dropna() # drop all rows with NaN values\n",
    "\n",
    "def new_columns(dfAssetClass, numAssetRows, columnID):\n",
    "    dfAssetClass[columnID] = pd.DataFrame(np.empty([numAssetRows,1]).cumsum(axis=1))\n",
    "    dfAssetClass.loc[:,columnID] = np.nan\n",
    "    return dfAssetClass[columnID]\n",
    "\n",
    "dictSGassetSubclass = {'PMH-3':'Air-Insulated Live Front','PMH-5':'Air-Insulated Live Front',\n",
    "                       'PMH-9':'Air-Insulated Live Front','PMH-11':'Air-Insulated Live Front',\n",
    "                       'PME-9':'Air-Insulated Dead Front','PME-10':'Air-Insulated Dead Front',\n",
    "                       'PME-11':'Air-Insulated Live Front','VISTA-321':'SF6-Insulated Switch',\n",
    "                       'VISTA-422':'SF6-Insulated Switch','VISTA-431':'SF6-Insulated Switch',\n",
    "                       '422':'S&C Elec','431':'S&C Elec','321':'S&C Elec','G&W':'G&W',\n",
    "                       'NET':'Carte Elec Ltd'}\n",
    "# 'Type' -> 'PMH'\n",
    "# 'Loc_No' -> '149-S'\n",
    "dfSwitchGears['Type'] = dfSwitchGears['Type'].fillna(method='ffill')\n",
    "numSGrows = len(dfSwitchGears['Loc_No'])\n",
    "dfSwitchGears['Subclass'] = new_columns(dfSwitchGears, numSGrows, 'Subclass')\n",
    "dfSwitchGears =dfSwitchGears.astype(str)\n",
    "#dfSwitchGears['Loc_No'] = dfSwitchGears.iloc[:,'Loc_No'].apply[s.lstrip(\"0\") for s in listOfNum]\n",
    "dfSwitchGears['Loc_No'] = [s.lstrip(\"0\") for s in dfSwitchGears['Loc_No']]\n",
    "dfSwitchGears['Subclass'] = dfSwitchGears['Type'].apply(lambda x: dictSGassetSubclass[x])\n",
    "\n",
    "# MasterFile = pd.ExcelWriter('V2_GIS_SGs.xlsx')\n",
    "# dfSwitchGears.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "# print(dfSwitchGears.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 11)\n",
      "dfSG Shape: (451, 3)\n"
     ]
    }
   ],
   "source": [
    "dropSwitchesCols = ['ANCILLARYROLE','ENABLED','FEEDERINFO','ELECTRICTRACEWEIGHT','LOCATIONID','GPSDATE','LABELTEXT',\n",
    "                    'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXOPERATINGVOLTAGE','MAXCONTINUOUSCURRENT','PRESENTPOSITION_R', \n",
    "                    'PRESENTPOSITION_Y', 'PRESENTPOSITION_B','NORMALPOSITION_R','NORMALPOSITION_Y','NORMALPOSITION_B', \n",
    "                    'SCADACONTROLID', 'SCADAMONITORID','PREFERREDCIRCUITSOURCE','TIESWITCHINDICATOR',\n",
    "                    'GANGOPERATED', 'MANUALLYOPERATED','FEATURE_STATUS','HYPERLINK','HYPERLINK_PGDB','SYMBOLROTATION',\n",
    "                    'INSULATOR_MATERIAL']\n",
    "\n",
    "# drop columns and drop rows that are not UG Switch\n",
    "dfSwitches = drop_columns(dfSwitches,dropSwitchesCols)\n",
    "dfSwitches = dfSwitches[dfSwitches.SUBTYPECD == 6]\n",
    "# df.query('line_race != 0')\n",
    "# df = df[df.line_race != 0]\n",
    "\n",
    "# Rename Switch columns\n",
    "dfSwitches = dfSwitches.rename(columns={'SUBTYPECD':'Asset Class','DEVICENUMBER':'ID','COMPATIBLEUNITID':'Asset Subclass',\n",
    "                                        'PHASEDESIGNATION':'PHASING','FEEDERID':'CIRCUIT', 'FEEDERID2':'TIE_FEEDER',\n",
    "                                        'INSTALLATIONDATE':'INSTALL_YEAR'})\n",
    "# Separate year\n",
    "dfSwitches['INSTALL_YEAR'] = dfSwitches['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "# Add additional columns and fill with NaNs\n",
    "numSwitchRows = len(dfSwitches['ID'])\n",
    "dfSwitches['HI'] = new_columns(dfSwitches,numSwitchRows, 'HI')\n",
    "dfSwitches['TX_PHASE'] = new_columns(dfSwitches,numSwitchRows, 'TX_PHASE')\n",
    "dfSwitches['IN_VALLEY'] = new_columns(dfSwitches,numSwitchRows, 'IN_VALLEY')\n",
    "dfSwitches['PRID'] = new_columns(dfSwitches,numSwitchRows, 'PRID')\n",
    "\n",
    "print(dfSwitches.shape) # (537, 11) with all switches, (260,11) with subtype=6 ('Switch Switchgear')\n",
    "print('dfSG Shape:', dfSwitchGears.shape) #(111, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace 'Asset Subclass' col with actual names\n",
    "dfSwitches['ID'] = dfSwitches['ID'].astype(str)\n",
    "dfSwitches=pd.merge(dfSwitches, dfSwitchGears, how='left', left_on='ID', right_on='Loc_No')\n",
    "#dfSwitches['ID'] = dfSwitchGears['Loc_No'].apply(lambda x: )\n",
    "#df.merge(df1, on='sku', how='left')\n",
    "# print(len(pd.unique(dfSwitchGears['Loc_No'].values.ravel()))) # 111\n",
    "\n",
    "switchesDropMoreCols = ['Asset Subclass', 'Loc_No']\n",
    "dfSwitches = dfSwitches.drop(switchesDropMoreCols, axis=1)\n",
    "dfSwitches = dfSwitches.rename(columns={'Subclass':'Asset Subclass'})\n",
    "#Rearrange columns\n",
    "dfSwitches=dfSwitches[['Asset Class', 'Asset Subclass', 'ID','CIRCUIT','INSTALL_YEAR','TIE_FEEDER','PHASING','IN_VALLEY','HI','TX_PHASE','PRID','Type']]\n",
    "\n",
    "MasterFile = pd.ExcelWriter('V2_GIS_Switches.xlsx')\n",
    "dfSwitches.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dfSwitches.shape)\n",
    "print('dfSG Shape:', dfSwitchGears.shape)\n",
    "print(dfSwitchGears.uniquevalues())\n",
    "# print(dfSwitches.head(5))\n",
    "# print(dfSwitchGears.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INSTALL_YEAR CIRCUIT TIE_FEEDER  Asset Class  Asset Subclass      ID\n",
      "0   1981-09-01   3S2-1        NaN            6            1233    92-S\n",
      "1   1900-01-01   5S1-3        NaN            6            1233   336-S\n",
      "2   2008-06-01   3S2-1        NaN            6            1233   360-S\n",
      "3   2015-06-12   5S2-3        NaN            6            1233  380-MS\n",
      "4   1987-10-01   5S2-3      6S2-1            3             193    6-MS\n"
     ]
    }
   ],
   "source": [
    "# colNames = {'Transformers:': list(dfTransformers.columns), 'Switches:': list(dfSwitches.columns),\n",
    "#            'Poles:': list(dfPoles.columns), 'Cables:': list(dfCables.columns), 'Fuses:':list(dfFuses.columns),\n",
    "#            'UGStructures:':list(dfUGStructures.columns)}\n",
    "# dfColNames = pd.Series(colNames)\n",
    "# print(dfColNames['Transformers:'])\n",
    "\n",
    "# Cables\n",
    "dropCablesCols = ['ENABLED', 'INSTALLATIONDATE', 'FEEDERID', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', \n",
    "                 'LENGTHSOURCE', 'MEASUREDLENGTH', 'LENGTHUOMCODE', 'WIRECOUNT', 'SUBTYPECD', 'LABELTEXT', \n",
    "                 'COMPATIBLEUNITID', 'PHASEDESIGNATION', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'ISFEEDERTRUNK', \n",
    "                 'NEUTRALUSECD', 'FEATURE_STATUS', 'CONDUCTOR_REJUVENATION', 'SHAPE_Length']\n",
    "\n",
    "\n",
    "\n",
    "#print(dfSwitches.head(5))\n",
    "\n",
    "\n",
    "# Rename OH Tx columns\n",
    "\n",
    "# Rename UG Tx columns\n",
    "\n",
    "# Rename Distribution Poles columns\n",
    "\n",
    "# Rename UG Cable columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  INSTALL_YEAR CIRCUIT TIE_FEEDER  Asset Class  Asset Subclass      ID  HI  \\\n",
      "0   1981-09-01   3S2-1        NaN            6            1233    92-S NaN   \n",
      "1   1900-01-01   5S1-3        NaN            6            1233   336-S NaN   \n",
      "2   2008-06-01   3S2-1        NaN            6            1233   360-S NaN   \n",
      "3   2015-06-12   5S2-3        NaN            6            1233  380-MS NaN   \n",
      "4   1987-10-01   5S2-3      6S2-1            3             193    6-MS NaN   \n",
      "\n",
      "   TX_PHASE IN_VALLEY  \n",
      "0       NaN        No  \n",
      "1       NaN        No  \n",
      "2       NaN        No  \n",
      "3       NaN        No  \n",
      "4       NaN        No  \n"
     ]
    }
   ],
   "source": [
    "# Poles\n",
    "dropPolesCols = ['INSTALLATIONDATE', 'SYMBOLROTATION', 'GPSDATE', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLEUNITID', \n",
    "                 'STRUCTURENUMBER', 'FEATURE_STATUS', 'STREETLIGHT_FACILITY', 'REPLACED_DATE_MM_DD_YYYY', \n",
    "                 'DEVICENUMBER', 'CONDITION', 'CONDITION_STATUS', 'CONDITION_DATE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transformer\n",
    "\n",
    "# separate into UG and OH\n",
    "\n",
    "dropTransformersCols = ['ANCILLARYROLE', 'ENABLED', 'INSTALLATIONDATE', 'FEEDERID', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'SYMBOLROTATION', 'GPSDATE', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLEUNITID', 'PHASEDESIGNATION', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'GROUNDREACTANCE', 'GROUNDRESISTANCE', 'MAGNETIZINGREACTANCE', 'MAGNETIZINGRESISTANCE', 'HIGHSIDEGROUNDREACTANCE', 'HIGHSIDEGROUNDRESISTANCE', 'HIGHSIDEPROTECTION', 'LOCATIONTYPE', 'DEVICENUMBER', 'FAULTINDICATOR', 'COOLINGTYPE', 'FEATURE_STATUS', 'KVA', 'UNITS', 'DEMAND_KVA', 'DEMAND_DATE_MM_DD_YYYY', 'STREET_LIGHT_FACILITY', 'HIGHSIDECONFIGURATION', 'LOWSIDECONFIGURATION', 'LOWSIDEGROUNDRESISTANCE', 'LOWSIDEVOLTAGE', 'LATITUDE', 'LONGITUDE', 'RATEDKVA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INSTALL_YEAR CIRCUIT TIE_FEEDER  Asset Class  Asset Subclass      ID  HI  \\\n",
      "0          1981   3S2-1        NaN            6            1233    92-S NaN   \n",
      "1          1900   5S1-3        NaN            6            1233   336-S NaN   \n",
      "2          2008   3S2-1        NaN            6            1233   360-S NaN   \n",
      "3          2015   5S2-3        NaN            6            1233  380-MS NaN   \n",
      "\n",
      "   TX_PHASE IN_VALLEY  \n",
      "0       NaN        No  \n",
      "1       NaN        No  \n",
      "2       NaN        No  \n",
      "3       NaN        No  \n"
     ]
    }
   ],
   "source": [
    "# Fuses\n",
    "\n",
    "dropFusesCols = ['ANCILLARYROLE', 'ENABLED', 'INSTALLATIONDATE', 'FEEDERID', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'GPSDATE', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLEUNITID', 'PHASEDESIGNATION', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXCONTINUOUSCURRENT', 'MAXINTERRUPTINGCURRENT', 'MAXOPERATINGVOLTAGE', 'PRESENTPOSITION_R', 'PRESENTPOSITION_Y', 'PRESENTPOSITION_B', 'NORMALPOSITION_R', 'NORMALPOSITION_Y', 'NORMALPOSITION_B', 'DEVICENUMBER', 'FUSELINKSIZE', 'FEATURE_STATUS', 'SYMBOLROTATION', 'INSULATOR_MATERIAL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop_Switch_Columns = ['OBJECTID', 'ANCILLARYROLE', 'ENABLED', 'WORKORDERID', 'FIELDVERIFY', 'COMMENTS','CREATIONUSER', \n",
    "#                        'DATECREATED', 'LASTUSER', 'DATEMODIFIED', 'WORKREQUESTID', 'DESIGNID','WORKLOCATIONID', 'WMSID', \n",
    "#                        'WORKFLOWSTATUS', 'WORKFUNCTION', 'FEEDERINFO','ELECTRICTRACEWEIGHT', 'LOCATIONID', 'GPSDATE', \n",
    "#                        'GISONUMBER', 'GISOTYPENBR', 'LABELTEXT','OWNERSHIP', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE',\n",
    "#                        'MAXOPERATINGVOLTAGE', 'MAXCONTINUOUSCURRENT', 'PRESENTPOSITION_R', 'PRESENTPOSITION_Y', \n",
    "#                        'PRESENTPOSITION_B', 'NORMALPOSITION_R', 'NORMALPOSITION_Y', 'NORMALPOSITION_B', 'SCADACONTROLID', \n",
    "#                        'SCADAMONITORID', 'PREFERREDCIRCUITSOURCE', 'TIESWITCHINDICATOR', 'GANGOPERATED', 'MANUALLYOPERATED',\n",
    "#                         'FEATURE_STATUS', 'HYPERLINK', 'HYPERLINK_PGDB', 'SYMBOLROTATION', 'INSULATOR_MATERIAL']\n",
    "\n",
    "\n",
    "# %timeit\n",
    "# Strip '\\n' from column headers\n",
    "dfTopology.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfSpotLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfCables.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfSwitches.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfNodes.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfOHlines.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfFuses.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "\n",
    "# Rename column headers\n",
    "dfTopology.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "#dfSpotLoads.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
    "dfLoads.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
    "dfCables.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
    "dfSwitches.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
    "dfNodes.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "dfOHlines.rename(columns=lambda x: 'OHlines_'+x, inplace=True)\n",
    "dfFuses.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n",
    "\n",
    "# Merge assets: switch, transformers, fuses, cables, OHlines to Node worksheet\n",
    "dfNodesMaster = pd.merge(dfNodes, dfSwitches, how='outer', left_on='Nodes_Node Id', right_on ='Switches_From Node')\n",
    "dfNodesMaster = pd.merge(dfNodesMaster, dfLoads, how='outer', left_on='Nodes_Node Id', right_on='Loads_From Node')\n",
    "dfNodesMaster = pd.merge(dfNodesMaster, dfFuses, how='outer', left_on='Nodes_Node Id', right_on='Fuses_From Node')\n",
    "#dfNodesMaster = pd.merge(dfNodesMaster, dfOHlines, how='outer', left_on='Nodes_Node Id', right_on='OHlines_From Node')\n",
    "dfNodesMaster = pd.merge(dfNodesMaster, dfCables, how='outer', left_on='Nodes_Node Id', right_on='Cables_From Node')\n",
    "# print(dfNodesMaster.head(3))\n",
    "print(len(dfNodesMaster.columns))\n",
    "\n",
    "dfNodesMaster = dfNodesMaster.rename(columns={'Loads_Total CkVA(kVA)':'Nameplate', 'Loads_Spot Number':'TransformerID'})\n",
    "dfNodesCopy = dfNodesMaster\n",
    "#print(dfNodesCopy.dtypes)\n",
    "\n",
    "#Change to str\n",
    "dfNodesCopy['Cables_From Node']= dfNodesCopy['Cables_From Node'].astype(str)\n",
    "dfNodesCopy['Cables_To Node']= dfNodesCopy['Cables_To Node'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split 'Nodes_Node Id' to 'NodeID_1' and 'NodeID_2' for 'SwitchRegion'\n",
    "dfNodesCopy['NodeID_1'], dfNodesCopy['NodeID_2'] = zip(*dfNodesCopy['Nodes_Node Id'].\n",
    "                                                       apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "\n",
    "#******************************#\n",
    "#***DIFFERET FROM V5 BEGINS****#\n",
    "#******************************#\n",
    "dfNodesCopy['Cables_FromNodeID_1'], dfNodesCopy['Cables_FromNodeID_2'] = zip(*dfNodesCopy['Cables_From Node'].\n",
    "                                                       apply(lambda x: x.split('_') if '_' in x else (x,np.nan)))\n",
    "dfNodesCopy['Cables_ToNodeID_1'], dfNodesCopy['Cables_ToNodeID_2'] = zip(*dfNodesCopy['Cables_To Node'].\n",
    "                                                        apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "                # Columns 'Cables_FromNodeID_2' and 'Cables_ToNodeID_2' dropped in Cables_drop_cols\n",
    "#******************************#\n",
    "#***DIFFERET FROM V5 ENDS******#\n",
    "#******************************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns deleted:  70\n",
      "Number of rows:  735\n",
      "Number of remaining columnns:  16\n"
     ]
    }
   ],
   "source": [
    "#Switch region col a.fill(numpy.nan), a[:] = numpy.nan\n",
    "Num_rows = len(dfNodesCopy['Nodes_Network Id'])\n",
    "dfNodesCopy['SwitchRegion'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "dfNodesCopy['CablesSwitchRegionFrom'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "dfNodesCopy['CablesSwitchRegionEnd'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "# avoid chain indexing - http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
    "dfNodesCopy.loc[:,'SwitchRegion'] = np.nan\n",
    "dfNodesCopy.loc[:,'CablesSwitchRegionFrom'] = np.nan\n",
    "dfNodesCopy.loc[:,'CablesSwitchRegionEnd'] = np.nan\n",
    "\n",
    "# V6 changes\n",
    "#df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])\n",
    "#'Cables_FromNodeID_2' and 'Cables_ToNodeID_2'\n",
    "dfNodesCopy['CablesSwitchRegionFrom'] = dfNodesCopy['Cables_FromNodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "dfNodesCopy['CablesSwitchRegionEnd'] = dfNodesCopy['Cables_ToNodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "dfNodesCopy['SwitchRegion'] = dfNodesCopy['NodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "\n",
    "#FillNA\n",
    "dfNodesCopy['SwitchRegion'] = dfNodesCopy['SwitchRegion'].fillna(method='ffill')\n",
    "dfNodesCopy['CablesSwitchRegionFrom'] = dfNodesCopy['CablesSwitchRegionFrom'].fillna(method='ffill')\n",
    "dfNodesCopy['CablesSwitchRegionEnd'] = dfNodesCopy['CablesSwitchRegionEnd'].fillna(method='ffill')\n",
    "\n",
    "#V5\n",
    "#dfNodesCopy['SwitchRegion'] = dfNodesCopy['NodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "\n",
    "#http://stackoverflow.com/questions/27905295/how-to-replace-nans-by-preceding-values-in-pandas-dataframe\n",
    "# df.fillna(method='ffill')\n",
    "# http://stackoverflow.com/questions/11497206/regular-expression-for-letters-dash-underscore-numbers-and-space\n",
    "\n",
    "# Remove columns - temporary list for now\n",
    "Nodes_drop_cols = ['Nodes_Phase','Nodes_Node Id', 'NodeID_1','NodeID_2'] #['Nodes_Network Id','Nodes_Node Id','Nodes_Phase'] \n",
    "Switches_drop_cols = ['Switches_Network Id','Switches_Equipment Id','Switches_Device Type','Switches_Status',\n",
    "                         'Switches_Phase','Switches_From Node','Switches_Voltage(kV)'] \n",
    "                        #'Switches_Section Id','Switches_State','Switches_Rating(A)'\n",
    "Tx_drop_cols = ['Loads_Network Id','Loads_Section Id','Loads_Status','Loads_From Node','Loads_Spot Type',\n",
    "                   'Loads_Dist Number','Loads_Dist Type','Loads_Total kVA(kVA)','Loads_Total kW(kW)','Loads_Total kvar',\n",
    "                   'Loads_Aver. PF(%)','Loads_Total kWh(kWh)','Loads_Total Cust','Loads_Phase Type','Loads_Config',\n",
    "                   'Loads_Locked','Loads_Load Model'] #'Loads_TransformerID','Loads_Phase','Loads_Nameplate',\n",
    "\n",
    "Fuses_drop_cols =['Fuses_Network Id', 'Fuses_Status','Fuses_State','Fuses_Phase','Fuses_Manufacturer', \n",
    "                    'Fuses_Model', 'Fuses_Voltage(kV)', 'Fuses_Voltage Class', 'Fuses_Standard', 'Fuses_Rating(A)',\n",
    "                  'Fuses_Rating','Fuses_Interrupting Rating(A)', 'Fuses_From Node', 'Fuses_To Node'] \n",
    "                    #  'Fuses_Section Id', 'Fuses_Equipment Id', Fuses_Rating' \n",
    "\n",
    "#OHlines_deleted_cols =['OHlines_Network Id','OHlines_Phase','OHlines_Cond R','OHlines_Cond Y',\n",
    "                       #'OHlines_Cond B','OHlines_Neutral 1','OHlines_Neutral 2','OHlines_Spacing']\n",
    "                        #'OHlines_Section Id','OHlines_Length(m)',\n",
    "OHlines_drop_cols=[]\n",
    "\n",
    "#V6 changes\n",
    "Cables_drop_cols =['Cables_Network Id','Cables_Equipment Id','Cables_Line Id','Cables_Status','Cables_Phase',\n",
    "                      'Cables_# parallel','Cables_Manufacturer','Cables_Standard',\n",
    "                      'Cables_Rated Voltage(kV)','Cables_Ampacity(A)','Cables_Withstand(A)','Cables_Cable Type',\n",
    "                      'Cables_Conductor Material','Cables_Sheathed','Cables_Concentric Neutrals','Cables_Line R1(ohms)',\n",
    "                      'Cables_Line X1(ohms)','Cables_Line B1(µS)','Cables_Line R0(ohms)','Cables_Line X0(ohms)',\n",
    "                      'Cables_Line B0(µS)','Cables_Harmonic Model', 'Cables_FromNodeID_1','Cables_ToNodeID_1',\n",
    "                      'Cables_FromNodeID_2','Cables_ToNodeID_2','Cables_From Node', 'Cables_To Node',] \n",
    "                    #'Cables_From Node','Cables_To Node','Cables_Length(m)','Cables_Size','Cables_insulation'\n",
    "\n",
    "# Poles_deleted_cols=[]\n",
    "\n",
    "combined_drop_cols = (Nodes_drop_cols + Switches_drop_cols + Tx_drop_cols + Fuses_drop_cols + \n",
    "                      OHlines_drop_cols + Cables_drop_cols)\n",
    "\n",
    "print('Number of columns deleted: ', len(combined_drop_cols))\n",
    "print('Number of rows: ', len(dfNodesCopy['Nodes_Network Id']))\n",
    "\n",
    "#Drop columns\n",
    "dfNodesCopy=dfNodesCopy.drop(combined_drop_cols, axis=1)\n",
    "\n",
    "#print('new cols: ', len(dfNodesCopy.columns))\n",
    "print('Number of remaining columnns: ', len(dfNodesCopy.columns))\n",
    "#print(dfNodesCopy.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MasterFile = pd.ExcelWriter('V7_NodeIDs.xlsx')\n",
    "dfNodesCopy.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SwitchGrouped = dfNodesCopy.groupby('SwitchRegion')\n",
    "#print(SwitchGrouped.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #  Ctrl + A\n",
    "# # Ctrl + / to uncomment\n",
    "\n",
    "# # ****************************\n",
    "# # A. NODES sheet\n",
    "# # ****************************\n",
    "# # 1. Split 'Node Id' to 'NodeID_1' and 'NodeID_2'\n",
    "# dfNodes['NodeID_1'], dfNodes['NodeID_2'] = zip(*dfNodes['Node Id'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfNodesCopy = pd.DataFrame(dfNodes)\n",
    "# # 3. Rename all column headers to 'Nodes_' + x\n",
    "# dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "# #print(dfNodes_Copy.count())\n",
    "\n",
    "# # ****************************\n",
    "# # B. MASTER SPREADSHEET\n",
    "# # ****************************\n",
    "# # Copy dfNodesCopy into dfMaster\n",
    "# dfMaster = pd.DataFrame(dfNodesCopy)\n",
    "# # print(dfMaster.count())\n",
    "# # Nodes_NodeID_1 and Nodes_NodeID_2 are keys\n",
    "\n",
    "# # ****************************\n",
    "# # C. Topology sheet\n",
    "# # ****************************\n",
    "# # 1. No renaming here,so freate a 'copy' dataframe\n",
    "# dfTopologyCopy = pd.DataFrame(dfTopology)\n",
    "# # 2. Rename all column headers to 'Topology_' + x\n",
    "# dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "# #print(dfTopologyCopy.count())\n",
    "\n",
    "# # 3. Combine topology sheet\n",
    "# # pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')\n",
    "# # dfFinal = \n",
    "# # Topology - more match with 'Topology_Coord. Y' over 'Topology_Coord. X'\n",
    "# dfMaster = pd.merge(dfMaster, dfTopologyCopy, how='outer', left_on='Nodes_NodeID_2', right_on ='Topology_Coord. Y')\n",
    "# #print(dfMaster.count())\n",
    "\n",
    "\n",
    "# # ****************************\n",
    "# # D. Fuses sheet \n",
    "# # ****************************\n",
    "# # 1. Split 'From Node' to 'FromNode_xCoord' and 'FromNode_yCoord'\n",
    "# dfFuses['FromNode_xCoord'], dfFuses['FromNode_yCoord'] = zip(*dfFuses['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Split 'To Node' to 'ToNode_FuseID' and 'ToNode_FdrID'\n",
    "# dfFuses['ToNode_FuseID'], dfFuses['ToNode_FdrID'] = zip(*dfFuses['To Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 3. Create a 'Copy' dataframe\n",
    "# dfFusesCopy = pd.DataFrame(dfFuses)\n",
    "# # 4. Rename all column headers to 'Fuses_' + x\n",
    "# dfFusesCopy.rename(columns=lambda x:'Fuses_'+x, inplace=True)\n",
    "# # 5. Combine Fuses sheet with Master\n",
    "# dfMaster = pd.merge(dfMaster, dfFusesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Fuses_FromNode_xCoord')\n",
    "# #print(dfMaster.count())\n",
    "\n",
    "# # ****************************\n",
    "# # D1. Output excel file - For VERIFICATION purposes\n",
    "# # ****************************\n",
    "# # Verify the excel file \n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# # http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# # MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# # dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# # MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ctrl + / to uncomment\n",
    "\n",
    "# # ****************************\n",
    "# # E. Switch sheet \n",
    "# # ****************************\n",
    "# # 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "# dfSwitches['FromNode_1'], dfSwitches['FromNode_2'] = zip(*dfSwitches['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfSwitchesCopy = pd.DataFrame(dfSwitches)\n",
    "# # 3. Rename all column headers to 'Switches_' + x\n",
    "# dfSwitchesCopy.rename(columns=lambda x:'Switches_'+x, inplace=True)\n",
    "# # 4. Combine Switches sheet with Master: \n",
    "# # 4.1 First with 'Switches_FromNode_1' - NodeID_1 also has '109-D'/'7-S' switch id :)\n",
    "# dfMaster = pd.merge(dfMaster, dfSwitchesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Switches_FromNode_1')\n",
    "# # 4.2 Second with 'Section Id' of FusesCopy - maybe not necessary\n",
    "\n",
    "# # ****************************\n",
    "# # F. Transformer aka \"Loads\" in CYME\n",
    "# # ****************************\n",
    "# # \n",
    "# # 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "# dfLoads['FromNode_1'], dfLoads['FromNode_2'] = zip(*dfLoads['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfLoadsCopy = pd.DataFrame(dfLoads)\n",
    "# # 3. Rename all column headers to Loads_' + x\n",
    "# dfLoadsCopy.rename(columns=lambda x:'Loads_'+x, inplace=True)\n",
    "# # 4. Combine all Loads with 'FromNode_1'  with dfMaster\n",
    "# dfMaster = pd.merge(dfMaster, dfLoadsCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Loads_FromNode_1')\n",
    "# # 4.2 May need to combine dfLoadsCopy with dfSpotLoads if tx nameplate rating not same\n",
    "\n",
    "\n",
    "# #Plot\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# pd.options.display.mpl_style = 'default'\n",
    "# #dfSwitches.boxplot()\n",
    "# #dfFusesCopy.boxplot(column=\"Fuses_Rating(A)\")\n",
    "# #mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)\n",
    "# dfFusesCopy['Fuses_FromNode_xCoord'] = dfFusesCopy['Fuses_FromNode_xCord'].convert_objects(convert_numeric=True)\n",
    "# dfFusesCopy['Fuses_FromNode_yCoord'] = dfFusesCopy['Fuses_FromNode_yCord'].convert_objects(convert_numeric=True)\n",
    "# #dfFusesCopy.plot(kind='scatter', x='Fuses_FromNode_xCoord', y='Fuses_FromNode_yCoord')\n",
    "\n",
    "\n",
    "# # ****************************\n",
    "# # D1. Output excel file\n",
    "# # ****************************\n",
    "# # Verify the excel file \n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# # http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# #MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# #dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# #MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************************\n",
    "# G. PRID to each region\n",
    "# ****************************\n",
    "# combine PRID to Tx?\n",
    "\n",
    "# ****************************\n",
    "# H. Cable \n",
    "# ****************************\n",
    "# combine cable and conductors\n",
    "\n",
    "# ****************************\n",
    "# I. Conductors  \n",
    "# ****************************\n",
    "# combine poles\n",
    "\n",
    "# ****************************\n",
    "# J. Poles \n",
    "# ****************************\n",
    "# Output excel file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
