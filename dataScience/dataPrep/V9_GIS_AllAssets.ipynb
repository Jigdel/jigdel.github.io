{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cables:  Fuses:  Poles:  Switches:  Transformers:  UGStructures:\n",
      "0     3865     736   18961        537           3618          16883\n",
      "1       22      29      14         35             40             23\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Output table/file names and template\n",
    "OH_SWITCHES_TABLE ='IN_OH_SW.xlsx'\n",
    "UG_SWITCHES_TABLE ='IN_UG_SW.xls'\n",
    "OH_TX_TABLE = 'IN_OH_TX.xlsx'\n",
    "UG_TX_TABLE = 'IN_UG_TX.xlsx'\n",
    "POLES_TABLE = 'IN_POLES.xlsx'\n",
    "UG_PRI_CABLE_TABLE = 'IN_CABLES.xlsx'\n",
    "NTWK_TX_TABLE = 'IN_NTWK_TX.xlsx'\n",
    "OH_SWITCHES_TABLE_TEMPLATE ='IN_OH_SW_TEMPLATE.xlsx'\n",
    "UG_SWITCHES_TABLE_TEMPLATE ='IN_UG_SW_TEMPLATE.xls'\n",
    "OH_TX_TABLE_TEMPLATE = 'IN_OH_TX_TEMPLATE.xlsx'\n",
    "UG_TX_TABLE_TEMPLATE = 'IN_UG_TX_TEMPLATE.xlsx'\n",
    "POLES_TABLE_TEMPLATE = 'IN_POLES_TEMPLATE.xlsx'\n",
    "UG_PRI_CABLE_TABLE_TEMPLATE = 'IN_CABLES_TEMPLATE.xlsx'\n",
    "NTWK_TX_TABLE_TEMPLATE = 'IN_NTWK_TX_TEMPLATE.xlsx'\n",
    "\n",
    "# asset_class_code(ACC) names\n",
    "OH_SWITCHES_ASSET_CLASS ='OH_SWITCH'\n",
    "UG_SWITCHES_ASSET_CLASS ='UG_SWITCH'\n",
    "OH_TX_ASSET_CLASS = 'OH_TX'\n",
    "UG_TX_ASSET_CLASS = 'UG_TX'\n",
    "POLES_ASSET_CLASS = 'POLE'\n",
    "UG_PRI_CABLE_ASSET_CLASS = 'UG_CABLE'\n",
    "NTWK_TX_ASSET_CLASS = 'NTWK_TX'\n",
    "\n",
    "ASSET_CLASS ='asset_class_code'\n",
    "ASSET_SUBCLASS ='asset_subclass_code'\n",
    "\n",
    "#Template folder\n",
    "ASSET_TEMPLATE_FOLDER='AssetDataTemplates'\n",
    "\n",
    "#******************************************************\n",
    "# Declare column names\n",
    "#******************************************************\n",
    "UG_SWITCHES_COLS =['asset_id','id','asset_subclass_code','asset_class_code','install_year','hi',\n",
    "                   'phasing','prid','circuit','tx_phase','in_valley','tie_feeder']\n",
    "\n",
    "OH_TX_COLS = ['asset_id','asset_class_code','id','circuit','install_year','asset_subclass_code','hi',\n",
    "              'phasing','primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "              'device_commercial','device_industrial','upstream_device','prid','in_valley','pcb','banking']\n",
    "\n",
    "UG_TX_COLS = ['asset_id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "              'primary_voltage','kva','in_valley','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "              'device_commercial','device_industrial','upstream_device','pcb','pedestal','switchable','switch_type','id']\n",
    "\n",
    "UG_PRI_CABLE_COLS = ['asset_id','id','install_year','hi','asset_subclass_code','asset_class_code','phasing','prid',\n",
    "                     'circuit','arrangement','installation','material','cable_size','config','length','num_splices',\n",
    "                     'num_cables','prid_residential','prid_commercial','prid_industrial','nominal_voltage',\n",
    "                     'wc_prid_catastrophic_res','wc_prid_catastrophic_comm','wc_prid_catastrophic_ind','cable_phase',\n",
    "                     'wc_replacement','wc_switching_res','wc_switching_comm','wc_switching_ind','wc_switching_duration']\n",
    "\n",
    "POLES_COLS = ['asset_id','asset_class_code','asset_subclass_code','install_year','hi character','phasing character',\n",
    "              'prid character','pole_class','tx','tx_type','circuit1','circuit2','circuit3','circuit4','in_valley',\n",
    "              'tx_residential','tx_commercial','tx_industrial','height','num_circuits','device','tx_kva','id','prid2',\n",
    "              'prid3','prid4','tx_pcb']\n",
    "\n",
    "NTWK_TX_COLS = ['asset_id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "                'primary_voltage','kva character','load double','id character','network_type','tx1','tx2','tx3','tx4']\n",
    "\n",
    "#******************************************************\n",
    "# fileName - iterate through entire folder :)\n",
    "fileName = 'Original_FiveAssetClasses.xlsx'\n",
    "file_PolesLatLong = 'Asset_XY_files/V2_LatLongPoles.xls'\n",
    "file_SwitchesLatLong = 'Asset_XY_files/V2_LatLongSwitches.xls'\n",
    "file_PriOHLatLong = 'Asset_XY_files/V2_LatLongPriOH.xls'\n",
    "file_PriUGLatLong = 'Asset_XY_files/V2_LatLongPriUG.xls'\n",
    "file_TxLatLong = 'Asset_XY_files/V2_LatLongTx.xls'\n",
    "#fileNameOtherDevices = 'Other Device Numbers.xls'\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(fileName) as xlsx:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfTransformersV1 = pd.read_excel(xlsx, 'Transformers') # 280 rows\n",
    "    dfSwitchesV1 = pd.read_excel(xlsx, 'Switches') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "    dfPolesV1 = pd.read_excel(xlsx, 'Poles') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "    dfCablesV1 = pd.read_excel(xlsx, 'UGPrimaryCables')\n",
    "    dfFusesV1 = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "    dfUGStructuresV1 = pd.read_excel(xlsx,'UGStructures')\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(file_PolesLatLong) as xls:\n",
    "    dfPolesLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "    \n",
    "with pd.ExcelFile(file_SwitchesLatLong) as xls:\n",
    "    dfSwitchesLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "with pd.ExcelFile(file_PriOHLatLong) as xls:\n",
    "    dfOHCondLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "with pd.ExcelFile(file_PriUGLatLong) as xls:\n",
    "    dfCablesLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "    \n",
    "with pd.ExcelFile(file_TxLatLong) as xls:\n",
    "    dfTxLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "    \n",
    "Summary = {'Transformers:': dfTransformersV1.shape, 'Switches:': dfSwitchesV1.shape,'Poles:': dfPolesV1.shape, \n",
    "           'Cables:': dfCablesV1.shape, 'Fuses:':dfFusesV1.shape, 'UGStructures:':dfUGStructuresV1.shape}\n",
    "dfSummary = pd.DataFrame(Summary)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformersV2 = dfTransformersV1\n",
    "dfSwitchesV2 = dfSwitchesV1\n",
    "dfPolesV2 = dfPolesV1\n",
    "dfCablesV2 = dfCablesV1\n",
    "dfFusesV2 = dfFusesV1\n",
    "dfUGStructuresV2 = dfUGStructuresV1\n",
    "\n",
    "# 17 columns dropped\n",
    "dropCommonColumns = ['OBJECTID','WORKORDERID','FIELDVERIFY','COMMENTS','CREATIONUSER','DATECREATED','LASTUSER',\n",
    "                     'DATEMODIFIED','WORKREQUESTID','DESIGNID','WORKLOCATIONID','WMSID','WORKFLOWSTATUS',\n",
    "                     'WORKFUNCTION','GISONUMBER','GISOTYPENBR','OWNERSHIP']\n",
    "\n",
    "#******************************************************\n",
    "# FUNCTIONS\n",
    "#******************************************************\n",
    "def drop_columns(dfAssetClass, dropColumns):\n",
    "    dfAssetClass = dfAssetClass.drop(dropColumns, axis=1)\n",
    "    return dfAssetClass\n",
    "\n",
    "def new_columns(dfAssetClass, numAssetRows, columnID):\n",
    "    dfAssetClass[columnID] = pd.DataFrame(np.empty([numAssetRows,1]).cumsum(axis=1))\n",
    "    dfAssetClass.loc[:,columnID] = np.nan\n",
    "    return dfAssetClass[columnID]\n",
    "\n",
    "#******************************************************\n",
    "#Drop all common columns \n",
    "#******************************************************\n",
    "dfSwitchesV2 = drop_columns(dfSwitchesV2, dropCommonColumns)\n",
    "dfTransformersV2 = drop_columns(dfTransformersV2, dropCommonColumns)\n",
    "dfFusesV2 = drop_columns(dfFusesV2,dropCommonColumns)\n",
    "dfCablesV2 = drop_columns(dfCablesV2, dropCommonColumns)\n",
    "dfUGStructuresV2 = drop_columns(dfUGStructuresV2, dropCommonColumns)\n",
    "dfPolesV2 = drop_columns(dfPolesV2, dropCommonColumns)\n",
    "\n",
    "dfSwitchesV2['FEEDERID'] = dfSwitchesV2['FEEDERID'].astype(str)\n",
    "dfTransformersV2['FEEDERID'] = dfTransformersV2['FEEDERID'].astype(str)\n",
    "dfFusesV2['FEEDERID'] = dfFusesV2['FEEDERID'].astype(str)\n",
    "dfCablesV2['FEEDERID'] = dfCablesV2['FEEDERID'].astype(str)\n",
    "\n",
    "dfSwitchesV2['FEEDERID'] = dfSwitchesV2['FEEDERID'].apply(lambda x: re.sub('[\\s+]', '', x))\n",
    "dfTransformersV2['FEEDERID'] = dfTransformersV2['FEEDERID'].apply(lambda x: re.sub('[\\s+]', '', x))\n",
    "dfFusesV2['FEEDERID'] = dfFusesV2['FEEDERID'].apply(lambda x: re.sub('[\\s+]', '', x))\n",
    "dfCablesV2['FEEDERID'] = dfCablesV2['FEEDERID'].apply(lambda x: re.sub('[\\s+]', '', x))\n",
    "\n",
    "# Make one copy\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "SummaryV2 = {'Transformers:': dfTransformers.shape, 'Switches:': dfSwitches.shape,'Poles:': dfPoles.shape, \n",
    "           'Cables:': dfCables.shape, 'Fuses:':dfFuses.shape, 'UGStructures:':dfUGStructures.shape}\n",
    "dfSummaryV2 = pd.DataFrame(SummaryV2)\n",
    "#print(dfSummary)\n",
    "print(dfSummaryV2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 1.2 - Nearest Neighbor algorithm\n",
    "#*****************************************************************************************************\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "import math\n",
    "#nearest_neighbor(df_filled, 'x','y','OH_FEEDERID',3,df_empty)\n",
    "def nearest_neighbor(dfMain, trainX, trainY, classX, neighborCount, dfUnknown):\n",
    "    #https://www.dataquest.io/blog/k-nearest-neighbors/\n",
    "    # Randomly shuffle the index of df_filled.\n",
    "    random_indices = permutation(dfMain.index)\n",
    "    # Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "    test_cutoff = math.floor(len(dfMain)/3)\n",
    "    # Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "    dfMain_test = dfMain.loc[random_indices[1:test_cutoff]]\n",
    "    # Generate the train set with the rest of the data.\n",
    "    dfMain_train = dfMain.loc[random_indices[test_cutoff:]]\n",
    "\n",
    "    for k in [1, 2, 3, 5, 10, 20]:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(dfMain_train[[trainX, trainY]], dfMain_train[classX])\n",
    "\n",
    "        predictions = knn.predict(dfMain_test[[trainX,trainY]])\n",
    "        prediction_results = dfMain_test[classX] == predictions\n",
    "        print('With k =  ',k,',a score of: ', prediction_results.mean()*100)\n",
    "\n",
    "    # Let's initialize a classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighborCount)\n",
    "    # knn.fit takes two parameters # First, the content we want to train on. For us it's height and weight.\n",
    "    # Secondly, how we're classifying each element of the training data. We're classifying by position!\n",
    "    knn.fit(dfMain_train[[trainX, trainY]], dfMain_train[classX])\n",
    "    predictions = knn.predict(dfMain_test[[trainX,trainY]])\n",
    "    prediction_results = dfMain_test[classX] == predictions\n",
    "    print('Prediction accuracy: ',prediction_results.mean()*100) \n",
    "    # same as mse = (((prediction_results) ** 2).sum()) / len(predictions)\n",
    "    predictedValues = knn.predict(dfUnknown[[trainX, trainY]])\n",
    "    return predictedValues\n",
    "\n",
    "# Split the df_filled to train and test data\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine,test_size=0.30, random_state=123)\n",
    "\n",
    "# Compute the mean squared error of our predictions.\n",
    "# mse = (((predictions - actual) ** 2).sum()) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OH and UG Tx, UG Switches analyses completed\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 2: Switches and Transformers\n",
    "#*****************************************************************************************************\n",
    "\n",
    "# Save future wait times while running\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "# dfCables = dfCablesV2\n",
    "# dfFuses = dfFusesV2\n",
    "# dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfOHCondLatLong = dfOHCondLatLongV1\n",
    "dfCablesLatLong = dfCablesLatLongV1\n",
    "\n",
    "#******************************************************\n",
    "# ASSET CLASS SPECIFIC DICTIONARIES\n",
    "#******************************************************\n",
    "# OPERATING VOLTAGE 190=8kv, 250=13.8kv, 1267 = 0kv, 1237 = 138kv\n",
    "# Assets: Transformers,\n",
    "operatingVoltageDict = {'190':'8000','250':'13800','1267':'0','1237':'138000'}\n",
    "\n",
    "# Phasing change - need to change it to 'str' type, int/float dict key lookup doesn't work\n",
    "# Assets: UG Switches, Transformers\n",
    "#phasingDict = {'1.0': '1Ph', '2.0':'1Ph','4.0':'1Ph','3.0':'2Ph','5.0':'2Ph','6.0':'2Ph','7.0':'3Ph'}\n",
    "phasingDict = {'1': '1', '2':'1','4':'1','3':'2','5':'2','6':'2','7':'3'}\n",
    "\n",
    "# UG Switches\n",
    "dictSGassetSubclass = {'PMH-3':'AIR_INSULATED_LIVEFRONT_PMH-9','PMH-5':'AIR_INSULATED_LIVEFRONT_PMH-9',\n",
    "                       'PMH-9':'AIR_INSULATED_LIVEFRONT_PMH-9','PMH-11':'AIR_INSULATED_LIVEFRONT_PMH-11',\n",
    "                       'PME-9':'AIR_INSULATED_DEADFRONT_PME-9','PME-10':'AIR_INSULATED_DEADFRONT_PME-9',\n",
    "                       'PME-11':'AIR_INSULATED_DEADFRONT_PME-11','VISTA-321':'SF6_INSULATED_SWITCH_VISTA-321',\n",
    "                       'VISTA-422':'SF6_INSULATED_SWITCH_VISTA-422','VISTA-431':'SF6_INSULATED_SWITCH_VISTA-431',\n",
    "                       '422':'SC_ELEC','431':'SC_ELEC','321':'SC_ELEC','G&W':'GW',\n",
    "                       'NET':'CARTE_ELEC_LTD'}\n",
    "\n",
    "# Transformers\n",
    "# dictOHTxSubclass = {'1':'Standard 1Ph','9':'Standard 3Ph','10':'Standard 2Ph'}\n",
    "# dictUGTxSubclass = {'2':'Padmount 1Ph','3':'Network Submersible','5':'Submersible', '7':'Padmount 3Ph'}\n",
    "dictOHTxSubclass = {'1':'POLE_TOP','9':'POLE_TOP','10':'POLE_TOP'}\n",
    "dictUGTxSubclass = {'2':'PAD_MOUNTED','3':'NETWORK_SUBMERSIBLE','5':'SUBMERSIBLE', '7':'PAD_MOUNTED'}\n",
    "\n",
    "#****************************************************************************\n",
    "# UG Switches - Reading SwitchGears\n",
    "#****************************************************************************\n",
    "#**************************\n",
    "# Reading SwitchGears\n",
    "#***************************\n",
    "fileNameOtherDevices = 'Other Device Numbers.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameOtherDevices) as xls:\n",
    "    dfSwitchGears = pd.read_excel(xls, 'SWITCHGEARS') # 280 rows\n",
    "\n",
    "dropSGcols = ['Switch Gear', 'Adrs #','Location','City','Notes','To Type','Inst. Date','Mftr.','Catalog#','Serial#',\n",
    "             'DOM','Comments']\n",
    "\n",
    "dfSwitchGears = drop_columns(dfSwitchGears, dropSGcols)\n",
    "#dfSwitchGears = dfSwitchGears.dropna() # drop all rows with NaN values\n",
    "\n",
    "# 'Type' -> 'PMH'\n",
    "# 'Loc_No' -> '149-S'\n",
    "dfSwitchGears['Type'] = dfSwitchGears['Type'].fillna(method='ffill')\n",
    "numSGrows = len(dfSwitchGears['Loc_No'])\n",
    "dfSwitchGears['ASSET_SUBCLASS'] = new_columns(dfSwitchGears, numSGrows, 'ASSET_SUBCLASS')\n",
    "dfSwitchGears =dfSwitchGears.astype(str)\n",
    "#dfSwitchGears['Loc_No'] = dfSwitchGears.iloc[:,'Loc_No'].apply[s.lstrip(\"0\") for s in listOfNum]\n",
    "dfSwitchGears['Loc_No'] = [s.lstrip(\"0\") for s in dfSwitchGears['Loc_No']]\n",
    "dfSwitchGears['ASSET_SUBCLASS'] = dfSwitchGears['Type'].apply(lambda x: dictSGassetSubclass[x])\n",
    "\n",
    "#*******************\n",
    "# Drop columns\n",
    "#*******************\n",
    "dropSwitchesCols = ['ANCILLARYROLE','ENABLED','FEEDERINFO','ELECTRICTRACEWEIGHT','LOCATIONID','GPSDATE','LABELTEXT',\n",
    "                    'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXOPERATINGVOLTAGE','MAXCONTINUOUSCURRENT','PRESENTPOSITION_R', \n",
    "                    'PRESENTPOSITION_Y', 'PRESENTPOSITION_B','NORMALPOSITION_R','NORMALPOSITION_Y','NORMALPOSITION_B', \n",
    "                    'SCADACONTROLID', 'SCADAMONITORID','PREFERREDCIRCUITSOURCE','TIESWITCHINDICATOR',\n",
    "                    'GANGOPERATED', 'MANUALLYOPERATED','FEATURE_STATUS','HYPERLINK','HYPERLINK_PGDB','SYMBOLROTATION',\n",
    "                    'INSULATOR_MATERIAL']\n",
    "\n",
    "#******************************************************\n",
    "# drop asset columns\n",
    "#******************************************************\n",
    "dfSwitches = drop_columns(dfSwitches,dropSwitchesCols)\n",
    "#******************************************************\n",
    "# FILTER OUT ASSET CLASSES WITH THEIR RESPECTIVE SUBTYPES\n",
    "#******************************************************\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "# UG Switches rows\n",
    "dfSwitches = dfSwitches[dfSwitches.SUBTYPECD == 6]\n",
    "numSwitchRows = len(dfSwitches['DEVICENUMBER'])\n",
    "\n",
    "#*******************\n",
    "# ADD ADDITIONAL COLUMNS AND FILL WITH NaNs\n",
    "#*******************\n",
    "# UG Switches\n",
    "dfSwitches['HI'] = new_columns(dfSwitches,numSwitchRows, 'HI')\n",
    "dfSwitches['TX_PHASE'] = new_columns(dfSwitches,numSwitchRows, 'TX_PHASE')\n",
    "dfSwitches['IN_VALLEY'] = new_columns(dfSwitches,numSwitchRows, 'IN_VALLEY')\n",
    "dfSwitches['PRID'] = new_columns(dfSwitches,numSwitchRows, 'PRID')\n",
    "#**************************\n",
    "# RENAME ASSET COLUMNS\n",
    "#**************************\n",
    "# Rename Switch columns\n",
    "dfSwitches = dfSwitches.rename(columns={'SUBTYPECD':ASSET_CLASS,\n",
    "                                        'DEVICENUMBER':'ID',\n",
    "                                        'COMPATIBLEUNITID':ASSET_SUBCLASS,\n",
    "                                        'PHASEDESIGNATION':'PHASING',\n",
    "                                        'FEEDERID':'CIRCUIT', \n",
    "                                        'FEEDERID2':'TIE_FEEDER',\n",
    "                                        'INSTALLATIONDATE':'INSTALL_YEAR'})\n",
    "# Separate year\n",
    "dfSwitches['INSTALL_YEAR'] = dfSwitches['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "# Replace 'Asset Subclass' col with actual names\n",
    "dfSwitches['ID'] = dfSwitches['ID'].astype(str)\n",
    "dfSwitches=pd.merge(dfSwitches, dfSwitchGears, how='left', left_on='ID', right_on='Loc_No')\n",
    "#dfSwitches['ID'] = dfSwitchGears['Loc_No'].apply(lambda x: )\n",
    "#df.merge(df1, on='sku', how='left')\n",
    "# print(len(pd.unique(dfSwitchGears['Loc_No'].values.ravel()))) # 111\n",
    "\n",
    "#******************************************************\n",
    "switchesDropMoreCols = [ASSET_SUBCLASS, 'Loc_No']\n",
    "dfSwitches = dfSwitches.drop(switchesDropMoreCols, axis=1)\n",
    "dfSwitches = dfSwitches.rename(columns={'ASSET_SUBCLASS': ASSET_SUBCLASS})\n",
    "\n",
    "#******************************************************\n",
    "# Rename proper asset nomenclature\n",
    "dfSwitches[ASSET_CLASS] = UG_SWITCHES_ASSET_CLASS\n",
    "\n",
    "#******************************************************\n",
    "# Rename proper asset nomenclature\n",
    "dfSwitches[ASSET_CLASS] = UG_SWITCHES_ASSET_CLASS\n",
    "\n",
    "#******************************************************\n",
    "#phasingDict = {'1.0': '1Ph', '2.0':'1Ph','4.0':'1Ph','3.0':'2Ph','5.0':'2Ph','6.0':'2Ph','7.0':'3Ph'}\n",
    "# UG Switches - 'phasing' col\n",
    "dfSwitches['PHASING'] = dfSwitches['PHASING'].astype(int)\n",
    "dfSwitches['PHASING'] = dfSwitches['PHASING'].astype(str)\n",
    "dfSwitches['PHASING'] = dfSwitches['PHASING'].apply(lambda x: phasingDict[x])\n",
    "\n",
    "#******************************************************\n",
    "# Lower case column names\n",
    "dfSwitches.columns = map(str.lower, dfSwitches.columns)\n",
    "\n",
    "#******************************************************\n",
    "# REARRANGE COLUMNS\n",
    "#******************************************************\n",
    "# *All tables need 'asset_id' - rename index\n",
    "# UG Switches\n",
    "# UG_SWITCHES_COLS =['asset_id','id','asset_subclass_code','asset_class_code','install_year','hi',\n",
    "#                    'phasing','prid','circuit','tx_phase','in_valley','tie_feeder']\n",
    "dfSwitches =dfSwitches[['id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit','tx_phase','in_valley','tie_feeder','type']]\n",
    "\n",
    "#*********************\n",
    "# OUTPUT DATAFRAMES TO EXCEL FILES\n",
    "#*********************\n",
    "# Output table/file names\n",
    "# UG SWITCH\n",
    "dfUGSwLater = dfSwitches\n",
    "MasterFile = pd.ExcelWriter(UG_SWITCHES_TABLE_TEMPLATE)\n",
    "dfSwitches.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "#********************\n",
    "# Drop columns\n",
    "#*******************\n",
    "\n",
    "dropTxCols = ['ANCILLARYROLE', 'ENABLED', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'SYMBOLROTATION', \n",
    "              'GPSDATE', 'LABELTEXT', 'NOMINALVOLTAGE', 'GROUNDREACTANCE', 'GROUNDRESISTANCE', \n",
    "              'MAGNETIZINGREACTANCE', 'MAGNETIZINGRESISTANCE', 'HIGHSIDEGROUNDREACTANCE','HIGHSIDEGROUNDRESISTANCE', \n",
    "              'HIGHSIDEPROTECTION', 'LOCATIONTYPE','COOLINGTYPE', 'FEATURE_STATUS','KVA', 'DEMAND_KVA',\n",
    "              'DEMAND_DATE_MM_DD_YYYY', 'STREET_LIGHT_FACILITY', 'HIGHSIDECONFIGURATION', 'LOWSIDECONFIGURATION',\n",
    "              'LOWSIDEGROUNDRESISTANCE', 'LOWSIDEVOLTAGE', 'LATITUDE', 'LONGITUDE']\n",
    "\n",
    "#******************************************************\n",
    "# drop asset columns\n",
    "#******************************************************\n",
    "dfTransformers = drop_columns(dfTransformers,dropTxCols)\n",
    "\n",
    "#******************************************************\n",
    "# FILTER OUT ASSET CLASSES WITH THEIR RESPECTIVE SUBTYPES\n",
    "#******************************************************\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "# number of rows/observations \n",
    "numTxRows = len(dfTransformers['DEVICENUMBER'])\n",
    "\n",
    "#******************************************************\n",
    "# RENAME ASSET COLUMNS\n",
    "#******************************************************\n",
    "\n",
    "# Rename Transformer columns\n",
    "dfTransformers = dfTransformers.rename(columns={'DEVICENUMBER':'ID',\n",
    "                                                'PHASEDESIGNATION':'Type',\n",
    "                                                'INSTALLATIONDATE':'INSTALL_YEAR',\n",
    "                                                'FEEDERID':'CIRCUIT',\n",
    "                                                'RATEDKVA':'KVA'})\n",
    "\n",
    "# Separate year\n",
    "dfTransformers['INSTALL_YEAR'] = dfTransformers['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "#******************************************************\n",
    "# ADD ADDITIONAL COLUMNS AND FILL WITH NaNs\n",
    "#******************************************************\n",
    "\n",
    "# Transformers\n",
    "dfTransformers[ASSET_CLASS] = new_columns(dfTransformers, numTxRows, ASSET_CLASS)\n",
    "dfTransformers['HI'] = new_columns(dfTransformers, numTxRows,'HI')\n",
    "dfTransformers['PRID'] = new_columns(dfTransformers, numTxRows,'PRID')\n",
    "dfTransformers['IN_VALLEY'] = new_columns(dfTransformers, numTxRows,'IN_VALLEY')\n",
    "dfTransformers['TX_RESIDENTIAL'] = new_columns(dfTransformers, numTxRows,'TX_RESIDENTIAL')\n",
    "dfTransformers['TX_COMMERCIAL'] = new_columns(dfTransformers, numTxRows,'TX_COMMERCIAL')\n",
    "dfTransformers['TX_INDUSTRIAL'] = new_columns(dfTransformers, numTxRows,'TX_INDUSTRIAL')\n",
    "dfTransformers['DEVICE_RESIDENTIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_RESIDENTIAL')\n",
    "dfTransformers['DEVICE_COMMERCIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_COMMERCIAL')\n",
    "dfTransformers['DEVICE_INDUSTRIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_INDUSTRIAL')\n",
    "dfTransformers['UPSTREAM_DEVICE'] = new_columns(dfTransformers, numTxRows,'UPSTREAM_DEVICE')\n",
    "dfTransformers['PCB'] = new_columns(dfTransformers, numTxRows,'PCB')\n",
    "\n",
    "#******************************************************\n",
    "# FILTER OUT ASSET CLASSES WITH THEIR RESPECTIVE SUBTYPES\n",
    "#******************************************************\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "# UG Tx: 2/3/5/7 - 1Ph/Ntwk/Sub/Pad 3Ph [1436,27,4,507: 1642 counts]\n",
    "dfUGTransformers = pd.DataFrame(dfTransformers[(dfTransformers.SUBTYPECD == 2) | \n",
    "                                  (dfTransformers.SUBTYPECD == 3) | \n",
    "                                  (dfTransformers.SUBTYPECD == 5) | \n",
    "                                  (dfTransformers.SUBTYPECD == 7) ])\n",
    "\n",
    "# OH Tx: 1/9/10 - 1Ph/3Ph/2Ph [1125/510/7: 1347 counts]\n",
    "dfOHTransformers = pd.DataFrame(dfTransformers[(dfTransformers.SUBTYPECD == 1) | \n",
    "                                  (dfTransformers.SUBTYPECD == 9) | \n",
    "                                  (dfTransformers.SUBTYPECD == 10)])\n",
    "\n",
    "#******************************************************\n",
    "# Replace Asset class and 'SUBTYPECD' with actual tx types\n",
    "#******************************************************\n",
    "numOHTxRows = len(dfOHTransformers['ID'])\n",
    "numUGTxRows = len(dfUGTransformers['ID'])\n",
    "\n",
    "#******************************************************\n",
    "# TRANSFORMERS\n",
    "#******************************************************\n",
    "dfOHTransformers['SUBTYPECD'] = dfOHTransformers['SUBTYPECD'].astype(str)\n",
    "dfUGTransformers['SUBTYPECD'] = dfUGTransformers['SUBTYPECD'].astype(str)\n",
    "\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "dfOHTransformers.loc[:,'SUBTYPECD'] = dfOHTransformers['SUBTYPECD'].apply(lambda x: dictOHTxSubclass[x])\n",
    "dfUGTransformers.loc[:,'SUBTYPECD'] = dfUGTransformers['SUBTYPECD'].apply(lambda x: dictUGTxSubclass[x])\n",
    "\n",
    "# Fill in Asset and asset subclass columns\n",
    "dfOHTransformers = dfOHTransformers.rename(columns={'SUBTYPECD':ASSET_SUBCLASS})\n",
    "dfUGTransformers = dfUGTransformers.rename(columns={'SUBTYPECD':ASSET_SUBCLASS})\n",
    "\n",
    "# Remaining OH Tx and UG Tx specific columns\n",
    "dfOHTransformers['BANKING'] = new_columns(dfOHTransformers, numOHTxRows,'BANKING')\n",
    "dfOHTransformers['BANKING'] = dfOHTransformers['UNITS'].apply(lambda x: x)\n",
    "dfUGTransformers['BANKING'] = new_columns(dfUGTransformers, numOHTxRows,'BANKING')\n",
    "dfUGTransformers['BANKING'] = dfUGTransformers['UNITS'].apply(lambda x: x)\n",
    "dfUGTransformers['PEDESTAL'] = new_columns(dfUGTransformers, numUGTxRows,'PEDESTAL')\n",
    "dfUGTransformers['SWITCHABLE'] = new_columns(dfUGTransformers, numUGTxRows,'SWITCHABLE')\n",
    "dfUGTransformers['SWITCH_TYPE'] = new_columns(dfUGTransformers, numUGTxRows,'SWITCH_TYPE')\n",
    "#print(numOHTxRows, numUGTxRows)\n",
    "#print(dfOHTransformers.columns)\n",
    "\n",
    "# Tx Domain code tables\n",
    "fileNameDomainCodes_Tx = 'DomainCodes_Tx.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameDomainCodes_Tx) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfUGTxDomainCodes = pd.read_excel(xls, 'UGTransformers')\n",
    "    dfOHTxDomainCodes = pd.read_excel(xls, 'OHTransformers')\n",
    "\n",
    "# Convert to string for merge purposes\n",
    "dfOHTransformers['COMPATIBLEUNITID'] = dfOHTransformers['COMPATIBLEUNITID'].astype(str)\n",
    "dfUGTransformers['COMPATIBLEUNITID'] = dfUGTransformers['COMPATIBLEUNITID'].astype(str)\n",
    "dfOHTxDomainCodes['COMPATIBLEUNITID'] = dfOHTxDomainCodes['COMPATIBLEUNITID'].astype(str)\n",
    "dfUGTxDomainCodes['COMPATIBLEUNITID'] = dfUGTxDomainCodes['COMPATIBLEUNITID'].astype(str)\n",
    "#print(dfUGTxDomainCodes.head())\n",
    "\n",
    "#dfOHTransformers=pd.merge(dfOHTransformers, dfOHTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#dfUGTransformers=pd.merge(dfUGTransformers, dfUGTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "dfOHTransformers=dfOHTransformers.merge(dfOHTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "dfUGTransformers=dfUGTransformers.merge(dfUGTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#print(dfUGTransformers.head(2))\n",
    "\n",
    "dropOHTxCols = ['COMPATIBLEUNITID','Description','PRIMARY_VOLTAGE','NAMEPLATE','PHASING','FAULTINDICATOR','UNITS','Tx_type_counts']\n",
    "dropUGTxCols = ['COMPATIBLEUNITID','Description','PRIMARY_VOLTAGE','NAMEPLATE','PHASING','FAULTINDICATOR','UNITS','Tx_type_counts']\n",
    "#'Fused','UNITS',\n",
    "# drop columns\n",
    "dfOHTransformers = drop_columns(dfOHTransformers,dropOHTxCols)\n",
    "dfUGTransformers = drop_columns(dfUGTransformers,dropUGTxCols)\n",
    "\n",
    "#******************************************************\n",
    "# 3\n",
    "#******************************************************\n",
    "# Replace 'Asset Subclass' col with actual names\n",
    "# Rename proper asset nomenclature\n",
    "#dfSwitches[ASSET_CLASS] = OH_SWITCHES_ASSET_CLASS\n",
    "dfOHTransformers[ASSET_CLASS] = OH_TX_ASSET_CLASS\n",
    "dfUGTransformers[ASSET_CLASS] = UG_TX_ASSET_CLASS\n",
    "\n",
    "#******************************************************\n",
    "#phasingDict = {'1.0': '1Ph', '2.0':'1Ph','4.0':'1Ph','3.0':'2Ph','5.0':'2Ph','6.0':'2Ph','7.0':'3Ph'}\n",
    "\n",
    "# OH and UG Tx - 'operational voltage'\n",
    "#operatingVoltageDict = {'190':'8000','250':'13800','1267':'0','1237':'138000'}\n",
    "dfOHTransformers['OPERATINGVOLTAGE'] = dfOHTransformers['OPERATINGVOLTAGE'].astype(str)\n",
    "dfUGTransformers['OPERATINGVOLTAGE'] = dfUGTransformers['OPERATINGVOLTAGE'].astype(str)\n",
    "dfOHTransformers['OPERATINGVOLTAGE'] = dfOHTransformers['OPERATINGVOLTAGE'].apply(lambda x: operatingVoltageDict[x])\n",
    "dfUGTransformers['OPERATINGVOLTAGE'] = dfUGTransformers['OPERATINGVOLTAGE'].apply(lambda x: operatingVoltageDict[x])\n",
    "\n",
    "dfOHTransformers['Type'] = dfOHTransformers['Type'].astype(str)\n",
    "dfUGTransformers['Type'] = dfUGTransformers['Type'].astype(str)\n",
    "dfOHTransformers['Type'] = dfOHTransformers['Type'].apply(lambda x: phasingDict[x])\n",
    "dfUGTransformers['Type'] = dfUGTransformers['Type'].apply(lambda x: phasingDict[x])\n",
    "\n",
    "#******************************************************\n",
    "# Rename col names\n",
    "dfOHTransformers = dfOHTransformers.rename(columns={'OPERATINGVOLTAGE': 'primary_voltage',\n",
    "                                                    'Type': 'phasing'})\n",
    "dfUGTransformers = dfUGTransformers.rename(columns={'OPERATINGVOLTAGE': 'primary_voltage',\n",
    "                                                    'Type': 'phasing'})\n",
    "#******************************************************\n",
    "# Lower case column names\n",
    "# dfSwitches.columns = map(str.lower, dfSwitches.columns)\n",
    "dfOHTransformers.columns = map(str.lower, dfOHTransformers.columns)\n",
    "dfUGTransformers.columns = map(str.lower, dfUGTransformers.columns)\n",
    "\n",
    "#******************************************************\n",
    "# REARRANGE COLUMNS\n",
    "#******************************************************\n",
    "# *All tables need 'asset_id' - rename index\n",
    "# OH_TX_COLS = ['asset_id','asset_class_code','id','circuit','install_year','asset_subclass_code','hi',\n",
    "#               'phasing','primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "#               'device_commercial','device_industrial','upstream_device','prid','in_valley','pcb','banking']\n",
    "dfOHTransformers = dfOHTransformers[['asset_class_code','id','circuit','install_year','asset_subclass_code','hi','phasing',\n",
    "                                     'primary_voltage','kva','tx_residential','tx_commercial','tx_industrial',\n",
    "                                     'device_residential','device_commercial','device_industrial','upstream_device',\n",
    "                                     'prid','in_valley','pcb','banking','secondary_voltage','fused']]\n",
    "#'faultindicator','type','units','tx_type_counts','sec_voltage','fused'\n",
    "\n",
    "# UG_TX_COLS = ['asset_id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "#               'primary_voltage','kva','in_valley','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "#               'device_commercial','device_industrial','upstream_device','pcb','pedestal','switchable','switch_type','id']\n",
    "dfUGTransformers = dfUGTransformers[['asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "                                     'primary_voltage','kva','in_valley','tx_residential','tx_commercial','tx_industrial',\n",
    "                                     'device_residential','device_commercial','device_industrial','upstream_device','pcb',\n",
    "                                     'pedestal','switchable','switch_type','id','secondary_voltage','fused','banking']]\n",
    "\n",
    "\n",
    "#******************************************************\n",
    "# OUTPUT DATAFRAMES TO EXCEL FILES\n",
    "#******************************************************\n",
    "# OH TX\n",
    "dfOHTxLater = dfOHTransformers\n",
    "MasterFile = pd.ExcelWriter(OH_TX_TABLE_TEMPLATE)\n",
    "dfOHTransformers.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "# UG TX\n",
    "dfUGTxLater = dfUGTransformers\n",
    "MasterFile = pd.ExcelWriter(UG_TX_TABLE_TEMPLATE)\n",
    "dfUGTransformers.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('OH and UG Tx, UG Switches analyses completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poles analysis completed\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 3: Poles Analysis - set up template\n",
    "#*****************************************************************************************************\n",
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# Save future wait times while running\n",
    "dfPoles = dfPolesV2\n",
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# keep only distribution poles\n",
    "dfPoles = dfPoles[dfPoles.SUBTYPECD == 1] #1 - Dist(47%), 5-TrafficLights(2%), 7-streetlight(51%)\n",
    "\n",
    "dropPolesCols = ['SYMBOLROTATION','GPSDATE','SUBTYPECD','LABELTEXT','STRUCTURENUMBER','FEATURE_STATUS',\n",
    "                 'STREETLIGHT_FACILITY','REPLACED_DATE_MM_DD_YYYY','CONDITION','CONDITION_STATUS','CONDITION_DATE']\n",
    "dfPoles = drop_columns(dfPoles,dropPolesCols)\n",
    "\n",
    "# Add additional columns and fill with NaNs\n",
    "#dfPoles[''] = new_columns(dfPoles, numPolesRows,'')\n",
    "numPolesRows = len(dfPoles['DEVICENUMBER'])\n",
    "dfPoles[ASSET_CLASS] = new_columns(dfPoles, numPolesRows,ASSET_CLASS)\n",
    "dfPoles[ASSET_SUBCLASS] = new_columns(dfPoles, numPolesRows,ASSET_SUBCLASS)\n",
    "dfPoles['HI'] = new_columns(dfPoles, numPolesRows,'HI')\n",
    "dfPoles['PHASING'] = new_columns(dfPoles, numPolesRows,'PHASING')\n",
    "dfPoles['PRID'] = new_columns(dfPoles, numPolesRows,'PRID')\n",
    "dfPoles['TX'] = new_columns(dfPoles, numPolesRows,'TX')\n",
    "dfPoles['TX_TYPE'] = new_columns(dfPoles, numPolesRows,'TX_TYPE')\n",
    "dfPoles['CIRCUIT1'] = new_columns(dfPoles, numPolesRows,'CIRCUIT1')\n",
    "dfPoles['CIRCUIT2'] = new_columns(dfPoles, numPolesRows,'CIRCUIT2')\n",
    "dfPoles['CIRCUIT3'] = new_columns(dfPoles, numPolesRows,'CIRCUIT3')\n",
    "dfPoles['CIRCUIT4'] = new_columns(dfPoles, numPolesRows,'CIRCUIT4')\n",
    "dfPoles['CIRCUIT5'] = new_columns(dfPoles, numPolesRows,'CIRCUIT5')\n",
    "dfPoles['CIRCUIT6'] = new_columns(dfPoles, numPolesRows,'CIRCUIT6')\n",
    "dfPoles['CIRCUIT7'] = new_columns(dfPoles, numPolesRows,'CIRCUIT7')\n",
    "dfPoles['CIRCUIT8'] = new_columns(dfPoles, numPolesRows,'CIRCUIT8')\n",
    "dfPoles['IN_VALLEY'] = new_columns(dfPoles, numPolesRows,'IN_VALLEY')\n",
    "dfPoles['TX_RESIDENTIAL'] = new_columns(dfPoles, numPolesRows,'TX_RESIDENTIAL')\n",
    "dfPoles['TX_COMMERCIAL'] = new_columns(dfPoles, numPolesRows,'TX_COMMERCIAL')\n",
    "dfPoles['TX_INDUSTRIAL'] = new_columns(dfPoles, numPolesRows,'TX_INDUSTRIAL')\n",
    "#dfPoles['HEIGHT'] = new_columns(dfPoles, numPolesRows,'HEIGHT')\n",
    "dfPoles['NUM_CIRCUITS'] = new_columns(dfPoles, numPolesRows,'NUM_CIRCUITS')\n",
    "dfPoles['DEVICE'] = new_columns(dfPoles, numPolesRows,'DEVICE')\n",
    "dfPoles['TX_KVA'] = new_columns(dfPoles, numPolesRows,'TX_KVA')\n",
    "dfPoles['TX_PHASING'] = new_columns(dfPoles, numPolesRows,'TX_PHASING')\n",
    "\n",
    "# Fill with values\n",
    "dfPoles[ASSET_CLASS] = POLES_ASSET_CLASS\n",
    "dfPoles[ASSET_SUBCLASS] = 'WOOD'\n",
    "\n",
    "# Poles_class_height table\n",
    "fileNamePolesClassHeight = 'DomainCodes_PolesClassHeight.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNamePolesClassHeight) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfPolesClassHeight = pd.read_excel(xls, 'Sheet1') # 280 rows\n",
    "#print(dfPoles.shape) \n",
    "# Merge tables\n",
    "dfPoles = dfPoles.merge(dfPolesClassHeight, how='left', on='COMPATIBLEUNITID')\n",
    "\n",
    "# Rename Pole columns\n",
    "dfPoles = dfPoles.rename(columns={'DEVICENUMBER':'ID',\n",
    "                                  'TYPE':'POLE_CLASS',\n",
    "                                  'INSTALLATIONDATE':'INSTALL_YEAR'})\n",
    "# Separate year\n",
    "dfPoles['INSTALL_YEAR'] = dfPoles['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "dropPolesCols2 = ['COMPATIBLEUNITID']\n",
    "dfPoles = drop_columns(dfPoles, dropPolesCols2)\n",
    "# POLES_COLS = ['asset_id','asset_class_code','asset_subclass_code','install_year','hi character','phasing character',\n",
    "#               'prid character','pole_class','tx','tx_type','circuit1','circuit2','circuit3','circuit4','in_valley',\n",
    "#               'tx_residential','tx_commercial','tx_industrial','height','num_circuits','device','tx_kva','id','prid2',\n",
    "#               'prid3','prid4','tx_pcb']\n",
    "# ['phasing', 'prid', 'tx', 'tx_type', 'circuit1', 'circuit2', 'circuit3',\n",
    "#        'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'in_valley',\n",
    "#        'tx_residential', 'tx_commercial', 'tx_industrial', 'num_circuits',\n",
    "#        'device', 'tx_kva', 'tx_phasing']\n",
    "\n",
    "# Lower case column names\n",
    "dfPoles.columns = map(str.lower, dfPoles.columns)\n",
    "dfPoles = dfPoles[dfPoles.id.notnull()]\n",
    "dfPolesLater = dfPoles\n",
    "#NEED to Rearrange columns - will do when pole attachment info available\n",
    "# POLES_TABLE = 'IN_POLES.xlsx'\n",
    "MasterFile = pd.ExcelWriter(POLES_TABLE_TEMPLATE)\n",
    "dfPoles.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "#print(dfPoles.columns)\n",
    "print('Poles analysis completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cables analysis completed\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 4: UG Primary Cable analysis\n",
    "#*****************************************************************************************************\n",
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# Save future wait times while running\n",
    "dfCables = dfCablesV2\n",
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# Cables\n",
    "dropCablesCols = ['ENABLED',  'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID',\n",
    "                  'LENGTHSOURCE',  'LENGTHUOMCODE', 'LABELTEXT', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', \n",
    "                  'ISFEEDERTRUNK', 'NEUTRALUSECD', 'FEATURE_STATUS', 'CONDUCTOR_REJUVENATION']\n",
    "# drop columns not related to Tx\n",
    "dfCables = drop_columns(dfCables,dropCablesCols)\n",
    "\n",
    "# Add additional columns and fill with NaNs\n",
    "numCablesRows = len(dfCables['INSTALLATIONDATE'])\n",
    "\n",
    "#dfCables\n",
    "dfCables[ASSET_CLASS] = new_columns(dfCables, numCablesRows, ASSET_CLASS)\n",
    "dfCables[ASSET_SUBCLASS] = new_columns(dfCables, numCablesRows, ASSET_SUBCLASS)\n",
    "dfCables['HI'] = new_columns(dfCables,numCablesRows,'HI')\n",
    "dfCables['PRID'] = new_columns(dfCables, numCablesRows,'PRID')\n",
    "dfCables['ARRANGEMENT'] = new_columns(dfCables, numCablesRows,'ARRANGEMENT')\n",
    "dfCables['INSTALLATION'] = new_columns(dfCables, numCablesRows,'INSTALLATION')\n",
    "dfCables['CONFIG'] = new_columns(dfCables, numCablesRows,'CONFIG')\n",
    "dfCables['NUM_SPLICES'] = new_columns(dfCables, numCablesRows,'NUM_SPLICES')\n",
    "dfCables['PRID_RESIDENTIAL'] = new_columns(dfCables, numCablesRows,'PRID_RESIDENTIAL')\n",
    "dfCables['PRID_COMMERCIAL'] = new_columns(dfCables, numCablesRows,'PRID_COMMERCIAL')\n",
    "dfCables['PRID_INDUSTRIAL'] = new_columns(dfCables, numCablesRows,'PRID_INDUSTRIAL')\n",
    "dfCables['WC_CATASTROPHIC_RES'] = new_columns(dfCables, numCablesRows,'WC_CATASTROPHIC_RES')\n",
    "dfCables['WC_CATASTROPHIC_COMM'] = new_columns(dfCables, numCablesRows,'WC_CATASTROPHIC_COMM')\n",
    "dfCables['WC_CATASTROPHIC_IND'] = new_columns(dfCables, numCablesRows,'WC_CATASTROPHIC_IND')\n",
    "dfCables['WC_REPLACEMENT'] = new_columns(dfCables, numCablesRows,'WC_REPLACEMENT')\n",
    "#dfCables['CABLE_PHASE'] = new_columns(dfCables, numCablesRows,'CABLE_PHASE')\n",
    "\n",
    "# Rename Cable columns\n",
    "dfCables = dfCables.rename(columns={'SHAPE_Length':'ID',\n",
    "                                    'SUBTYPECD':'PHASING',\n",
    "                                    'INSTALLATIONDATE':'INSTALL_YEAR',\n",
    "                                    'FEEDERID':'CIRCUIT',\n",
    "                                    'MEASUREDLENGTH':'LENGTH',\n",
    "                                    'WIRECOUNT': 'NUM_CABLES',\n",
    "                                    'PHASEDESIGNATION':'CABLE_PHASE'})\n",
    "# Separate year\n",
    "dfCables['INSTALL_YEAR'] = dfCables['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "#print(dfCables.head(3))\n",
    "dfCables[ASSET_SUBCLASS] = 'XLPE'\n",
    "# Replace Asset class and 'SUBTYPECD' with actual tx types\n",
    "dictCablesPhasing = {'1':'1','2':'1','3':'1','4':'2','5':'3','6':'Abandon'}\n",
    "dictCablesPhase = {'0.0':'', '1.0':'B','2.0':'Y','3.0':'YB','4.0':'R','6.0':'RB','7.0':'RYB','':''}\n",
    "\n",
    "dfCables['PHASING'] = dfCables['PHASING'].astype(str)\n",
    "dfCables['CABLE_PHASE'] = dfCables['CABLE_PHASE'].astype(str)\n",
    "\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "dfCables.loc[:,'PHASING'] = dfCables['PHASING'].apply(lambda x: dictCablesPhasing[x])\n",
    "dfCables.loc[:,'CABLE_PHASE'] = dfCables['CABLE_PHASE'].apply(lambda x: dictCablesPhase[x])\n",
    "\n",
    "# Fill in Asset and asset subclass columns\n",
    "dfCables[ASSET_CLASS] = UG_PRI_CABLE_ASSET_CLASS\n",
    "\n",
    "# Cables Domain code tables\n",
    "fileNameDomainCodes_Cables = 'DomainCodes_Cables.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameDomainCodes_Cables) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfCablesDomainCodes = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "dfCables=dfCables.merge(dfCablesDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#print(dfUGTransformers.head(2))\n",
    "dropCablesCols2 = ['COMPATIBLEUNITID','Description','Percent']\n",
    "dfCables = drop_columns(dfCables,dropCablesCols2)\n",
    "\n",
    "# Lower case column names\n",
    "dfCables.columns = map(str.lower, dfCables.columns)\n",
    "\n",
    "# UG_PRI_CABLE_COLS = ['asset_id','id','install_year','hi','asset_subclass_code','asset_class_code','phasing','prid',\n",
    "#                      'circuit','arrangement','installation','material','cable_size','config','length','num_splices',\n",
    "#                      'num_cables','prid_residential','prid_commercial','prid_industrial','nominal_voltage',\n",
    "#                      'wc_prid_catastrophic_res','wc_prid_catastrophic_comm','wc_prid_catastrophic_ind','cable_phase',\n",
    "#                      'wc_replacement','wc_switching_res','wc_switching_comm','wc_switching_ind','wc_switching_duration']\n",
    "\n",
    "# print(dfCables.columns)\n",
    "# ['install_year', 'circuit', 'length', 'num_cables', 'phasing',\n",
    "#        'cable_phase', 'id', 'asset_class_code', 'asset_subclass_code', 'hi',\n",
    "#        'prid', 'arrangement', 'installation', 'config', 'num_splices',\n",
    "#        'prid_residential', 'prid_commercial', 'prid_industrial',\n",
    "#        'wc_catastrophic_res', 'wc_catastrophic_comm', 'wc_catastrophic_ind',\n",
    "#        'wc_replacement', 'cable_size', 'material', 'cnshld',\n",
    "#        'nominal_voltage'],\n",
    "\n",
    "# UG_PRI_CABLE_TABLE = 'IN_CABLES.xlsx'\n",
    "# UG_PRI_CABLE_ASSET_CLASS = 'UG_CABLE'\n",
    "\n",
    "dfCablesLater = dfCables\n",
    "\n",
    "MasterFile = pd.ExcelWriter(UG_PRI_CABLE_TABLE_TEMPLATE)\n",
    "dfCables.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Cables analysis completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "With k =   1 ,a score of:  45.9665144597\n",
      "With k =   2 ,a score of:  43.3789954338\n",
      "With k =   3 ,a score of:  43.9878234399\n",
      "With k =   5 ,a score of:  42.7701674277\n",
      "With k =   10 ,a score of:  38.203957382\n",
      "With k =   20 ,a score of:  31.6590563166\n",
      "Prediction accuracy:  43.9878234399\n",
      "UG Switches Prediction:\n",
      "With k =   1 ,a score of:  58.0448065173\n",
      "With k =   2 ,a score of:  55.0916496945\n",
      "With k =   3 ,a score of:  51.0183299389\n",
      "With k =   5 ,a score of:  46.5376782077\n",
      "With k =   10 ,a score of:  39.7148676171\n",
      "With k =   20 ,a score of:  33.7067209776\n",
      "Prediction accuracy:  58.0448065173\n",
      "Index(['id', 'asset_subclass_code', 'asset_class_code', 'install_year', 'hi',\n",
      "       'phasing', 'prid', 'circuit', 'tx_phase', 'in_valley', 'tie_feeder',\n",
      "       'type'],\n",
      "      dtype='object')\n",
      "dfUGSwLater:  Index(['id', 'asset_subclass_code', 'asset_class_code', 'install_year', 'hi',\n",
      "       'phasing', 'prid', 'circuit', 'tx_phase', 'in_valley', 'tie_feeder',\n",
      "       'type'],\n",
      "      dtype='object')\n",
      "UG Cables Prediction:\n",
      "With k =   1 ,a score of:  42.7701674277\n",
      "With k =   2 ,a score of:  40.9436834094\n",
      "With k =   3 ,a score of:  41.8569254186\n",
      "With k =   5 ,a score of:  38.0517503805\n",
      "With k =   10 ,a score of:  32.5722983257\n",
      "With k =  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:420: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:187: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20 ,a score of:  27.5494672755\n",
      "Prediction accuracy:  41.8569254186\n",
      "ML Cables analysis completed\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 5: Using Machine Learning to map installation years for UG switches/Poles/UG cables\n",
    "#*****************************************************************************************************\n",
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfOHCondLatLong = dfOHCondLatLongV1\n",
    "dfCablesLatLong = dfCablesLatLongV1\n",
    "dfTxLatLong = dfTxLatLongV1\n",
    "#**********************************************************************\n",
    "# UG Switches match\n",
    "#**********************************************************************\n",
    "# dfSwitches age need to be fixed\n",
    "# 20% of UG Switches with install_year 1900\n",
    "# match with other 80%\n",
    "#**********************************************************************\n",
    "dfUGTxLater = dfUGTransformers\n",
    "# drop XY cols, only 'DEVICENUMB', 'x','y', 'installation_year'\n",
    "switchXYDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI','FIELDVERIF', 'COMMENTS', \n",
    "                         'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', \n",
    "                         'WMSID','WORKFLOWST', 'WORKFUNCTI',  'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'GPSDATE', \n",
    "                         'GISONUMBER', 'GISOTYPENB','LABELTEXT', 'OWNERSHIP', 'PHASEDESIG','OPERATINGV', 'NOMINALVOL', \n",
    "                         'MAXOPERATI', 'MAXCONTINU', 'PRESENTPOS', 'PRESENTP_1', 'PRESENTP_2', 'NORMALPOSI', 'NORMALPO_1',\n",
    "                         'NORMALPO_2','SCADACONTR', 'SCADAMONIT', 'PREFERREDC', 'TIESWITCHI', 'GANGOPERAT','MANUALLYOP',\n",
    "                         'FEATURE_ST', 'HYPERLINK', 'HYPERLINK_','SYMBOLROTA', 'INSULATOR_', 'FeederID_1', 'EnergizedP', \n",
    "                         'SourceCoun','Loop', 'Tie','COMPATIBLE','SUBTYPECD','FEEDERID', 'FEEDERID2']\n",
    "\n",
    "#***********\n",
    "# Tx\n",
    "#***********\n",
    "# UG Tx: 2/3/5/7 - 1Ph/Ntwk/Sub/Pad 3Ph [1436,27,4,507: 1642 counts]\n",
    "dfUGTxXY = pd.DataFrame(dfTxLatLong[(dfTxLatLong.SUBTYPECD == 2) | \n",
    "                                    (dfTxLatLong.SUBTYPECD == 3) |\n",
    "                                    (dfTxLatLong.SUBTYPECD == 5) |\n",
    "                                    (dfTxLatLong.SUBTYPECD == 7) ])\n",
    "\n",
    "# OH Tx: 1/9/10 - 1Ph/3Ph/2Ph [1125/510/7: 1347 counts]\n",
    "dfOHTxXY = pd.DataFrame(dfTxLatLong[(dfTxLatLong.SUBTYPECD == 1) |\n",
    "                                 (dfTxLatLong.SUBTYPECD == 9) |\n",
    "                                 (dfTxLatLong.SUBTYPECD == 10)])\n",
    "\n",
    "\n",
    "txXYDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI','FEEDERID','FIELDVERIF', 'COMMENTS', \n",
    "                     'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID',\n",
    "                     'WORKFLOWST', 'WORKFUNCTI', 'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'SYMBOLROTA', 'GPSDATE', \n",
    "                     'GISONUMBER','GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE', 'OWNERSHIP','PHASEDESIG', \n",
    "                     'OPERATINGV', 'NOMINALVOL', 'GROUNDREAC', 'GROUNDRESI','MAGNETIZIN', 'MAGNETIZ_1', 'HIGHSIDEGR', \n",
    "                     'HIGHSIDE_1', 'HIGHSIDEPR','LOCATIONTY', 'FAULTINDIC', 'COOLINGTYP', 'FEATURE_ST','KVA', 'UNITS', \n",
    "                     'DEMAND_KVA', 'DEMAND_DAT', 'STREET_LIG', 'HIGHSIDECO','LOWSIDECON', 'LOWSIDEGRO', 'LOWSIDEVOL', \n",
    "                     'LATITUDE', 'LONGITUDE','RATEDKVA', 'FeederID_1', 'EnergizedP', 'SourceCoun', 'Loop','FEEDERID2']\n",
    "\n",
    "dfUGTxXY = drop_columns(dfUGTxXY, txXYDropCols)\n",
    "dfOHTxXY = drop_columns(dfOHTxXY, txXYDropCols)\n",
    "dfSwitchesXY = drop_columns(dfSwitchesLatLong, switchXYDropCols)\n",
    "\n",
    "#print(dfSwitchesXY.columns) # 'INSTALLATI','DEVICENUMB', 'x', 'y']\n",
    "#print(dfTxXY.columns) # 'INSTALLATI','DEVICENUMB', 'x', 'y']\n",
    "dfUGTxXY = dfUGTxXY.rename(columns={'INSTALLATI':'install_year', 'DEVICENUMB':'id'})\n",
    "dfSwitchesXY = dfSwitchesXY.rename(columns={'INSTALLATI':'install_year','DEVICENUMB':'id'})\n",
    "\n",
    "dfSwitchesXY['install_year'] = dfSwitchesXY['install_year'].apply(lambda x: x.year)\n",
    "dfUGTxXY['install_year'] = dfUGTxXY['install_year'].apply(lambda x: x.year)\n",
    "\n",
    "\n",
    "#******************************************************\n",
    "# UG Tx - 1 tx missing installation years - use k-NN\n",
    "#******************************************************\n",
    "# separate empty and non-empty 'install_year' values\n",
    "dfUGTxXY_Train = dfUGTxXY[dfUGTxXY['install_year'].notnull()] \n",
    "dfUGTxXY_Empty = dfUGTxXY[dfUGTxXY['install_year'].isnull()] \n",
    "print(dfUGTxXY_Empty.shape)\n",
    "# train the model\n",
    "\n",
    "dfUGTxXY_Empty.loc[:,'install_year'] = nearest_neighbor(dfUGTxXY_Train, 'x','y','install_year',3,dfUGTxXY_Empty)\n",
    "dfUGTxXY_new = pd.concat([dfUGTxXY_Train,dfUGTxXY_Empty])\n",
    "# fill in empty values\n",
    "\n",
    "# merge with original df\n",
    "dfUGTxLater = drop_columns(dfUGTxLater,'install_year')\n",
    "dfUGTxLater = dfUGTxLater.merge(dfUGTxXY_new, how='left', on='id')\n",
    "dfUGTxLater = drop_columns(dfUGTxLater,['x','y'])\n",
    "# Machine Learning: empty and filled\n",
    "#def nearest_neighbor(dfMain, trainX, trainY, classX, neighborCount, dfUnknown):\n",
    "dfSwitchesXY_Unknown = dfSwitchesXY.loc[dfSwitchesXY['install_year'] == 1900]\n",
    "dfSwitchesXY_Train = dfSwitchesXY.loc[dfSwitchesXY['install_year'] != 1900]\n",
    "dfSwitchesXY_Train = pd.concat([dfUGTxXY_new,dfSwitchesXY_Train]) #4093 rows\n",
    "dfSwitchesXY_Train = dfSwitchesXY_Train[np.isfinite(dfSwitchesXY_Train['install_year'])] # drop NaNs\n",
    "\n",
    "print('UG Switches Prediction:')\n",
    "dfSwitchesXY_Unknown.loc[:,'install_year'] = nearest_neighbor(dfSwitchesXY_Train, 'x','y','install_year',1, \n",
    "                                                              dfSwitchesXY_Unknown)\n",
    "# 60% accuracy\n",
    "dfSwitchesXY_Unknown = drop_columns(dfSwitchesXY_Unknown, ['x','y'])\n",
    "dfSwitchesXY_Train = drop_columns(dfSwitchesXY_Train, ['x','y'])\n",
    "dfSwitchesXY = pd.concat([dfSwitchesXY_Unknown,dfSwitchesXY_Train])\n",
    "print(dfUGSwLater.columns)\n",
    "# # overwrite template file: Merge with NGN dfSwitches on Device\n",
    "dfUGSwLater = dfSwitches\n",
    "print('dfUGSwLater: ', dfUGSwLater.columns)\n",
    "dfUGSwLater = drop_columns(dfUGSwLater,['install_year'])\n",
    "dfUGSwLater = dfUGSwLater.merge(dfSwitchesXY, how='left', on='id')\n",
    "MasterFile = pd.ExcelWriter(UG_SWITCHES_TABLE_TEMPLATE)\n",
    "dfUGSwLater.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "# Overwrite original UG Tx file\n",
    "#dfOHTxLater = dfOHTransformers\n",
    "MasterFile = pd.ExcelWriter(UG_TX_TABLE_TEMPLATE)\n",
    "dfUGTxLater.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "#**********************************************************************\n",
    "# UG Cables\n",
    "#**********************************************************************\n",
    "# dfCables age need to be fixed\n",
    "# 60% cables installed in 1900 and 1998\n",
    "# match with other 80%\n",
    "#**********************************************************************\n",
    "cablesXYDropCols = ['FID', 'OBJECTID', 'ENABLED', 'WORKORDERI',  'FIELDVERIF','COMMENTS', 'CREATIONUS', 'DATECREATE', \n",
    "                         'LASTUSER', 'DATEMODIFI','WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID', 'WORKFLOWST','WORKFUNCTI',\n",
    "                         'FEEDERID2', 'FEEDERINFO', 'ELECTRICTR','LOCATIONID', 'LENGTHSOUR', 'MEASUREDLE', 'LENGTHUOMC', \n",
    "                         'WIRECOUNT','GISONUMBER', 'GISOTYPENB', 'LABELTEXT', 'COMPATIBLE','OWNERSHIP', \n",
    "                         'PHASEDESIG', 'OPERATINGV', 'NOMINALVOL', 'ISFEEDERTR','NEUTRALUSE', 'FEATURE_ST', 'CONDUCTOR_', \n",
    "                         'SHAPE_LEN', 'FeederID_1','EnergizedP', 'SourceCoun', 'Loop']\n",
    "\n",
    "dfCablesXY = drop_columns(dfCablesLatLong, cablesXYDropCols)\n",
    "dfCablesXY = dfCablesXY.rename(columns={'xStart': 'x','yStart': 'y','INSTALLATI':'install_year'})\n",
    "\n",
    "# use UG tx to train and test, fill cable where years <=2002\n",
    "cableCutoffYr = 2002\n",
    "\n",
    "#df[~df.C.str.contains(\"XYZ\")] # Remove all 'abandon' phasing\n",
    "#dfCablesXY = dfCablesXY[dfCablesXY.SUBTYPECD != 6]\n",
    "dfCablesXY['install_year'] = dfCablesXY['install_year'].apply(lambda x: x.year)\n",
    "\n",
    "# Machine Learning: empty and filled\n",
    "#def nearest_neighbor(dfMain, trainX, trainY, classX, neighborCount, dfUnknown):\n",
    "#print('Shape of dfCablesXY: ', dfCablesXY.shape)# (3888, 9)\n",
    "dfCablesXY_Unknown = dfCablesXY.loc[dfCablesXY['install_year'] != cableCutoffYr]\n",
    "dfCablesXY_2002 = dfCablesXY.loc[dfCablesXY['install_year'] == cableCutoffYr]\n",
    "#print('Shape of dfCablesXY Unknown: ', dfCablesXY_Unknown.shape) #(3853, 9)\n",
    "dfCablesXY_Train = dfUGTxXY_new\n",
    "#print('Shape of dfCablesXY_Train: ', dfCablesXY_Train.shape) #(1975, 4)\n",
    "# print('Before Year NaNs: ', dfCablesXY_Train.shape)\n",
    "dfCablesXY_Train = dfCablesXY_Train[np.isfinite(dfCablesXY_Train['install_year'])] #one NaN value\n",
    "# print('After Year NaNs: ', dfCablesXY_Train.shape)\n",
    "\n",
    "# if combined both UGtx and UGCable > 2002 ~ 45-50% prediction accuracy\n",
    "# dfCablesXY_Train = dfCablesXY.loc[dfCablesXY['install_year'] == cableCutoffYr]\n",
    "# dfCablesXY_Train = pd.concat([dfUGTxXY,dfCablesXY_Train]) #4093 rows\n",
    "# dfCablesXY_Train = dfCablesXY_Train[np.isfinite(dfCablesXY_Train['install_year'])] # drop NaNs\n",
    "#dfCablesXY_Train = dfCablesXY_Train[np.isfinite(dfCablesXY_Train['FEEDERID'])] # drop NaNs, mostly 'Abandon' phasing\n",
    "\n",
    "print('UG Cables Prediction:')\n",
    "dfCablesXY_Unknown.loc[:,'install_year'] = nearest_neighbor(dfCablesXY_Train, 'x','y','install_year',3,dfCablesXY_Unknown)\n",
    "# 60% accuracy\n",
    "# cablesXYdropCol = ['xEnd','yEnd','xMid','yMid','SUBTYPECD']\n",
    "# dfCablesXY_Unknown = drop_columns(dfCablesXY_Unknown, cablesXYdropCol)\n",
    "# MasterFile = pd.ExcelWriter('V6.1Cables_test.xlsx')\n",
    "# dfCablesXY_Unknown.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "# uncomment if UGCable included in training set\n",
    "# dfCablesXY_Train = drop_columns(dfCablesXY_Train, cablesXYdropCol)\n",
    "\n",
    "dfCablesXY_all = pd.concat([dfCablesXY_Unknown,dfCablesXY_2002])\n",
    "\n",
    "#print(dfCablesXY_all.head(4)) # FEEDERID   id  install_year          x   y\n",
    "dfCablesXY_uniqueX = pd.DataFrame(pd.unique(dfCablesXY_all[['x']].values.ravel()))\n",
    "#print(\"all: \",dfCablesXY_all.shape)\n",
    "\n",
    "\n",
    "dfCablesLater = dfCables\n",
    "dfCablesLater['x'] = new_columns(dfCablesLater,numCablesRows,'x')\n",
    "#print('After: ',dfCablesLater.columns)\n",
    "\n",
    "#print('1:',dfCablesLater.shape) #(3865, 27) | (7869, 50) only if both UGTx and UG cable joined - not recommended\n",
    "# print(dfCablesXY.shape) # (3888, 8) (3750, 9)\n",
    "dfCablesLater['x']= dfCablesXY_uniqueX[0].apply(lambda x: x)\n",
    "#'install_year', 'FEEDERID', 'SUBTYPECD', 'x', 'y', 'xMid', 'yMid', 'xEnd', 'yEnd'\n",
    "#print('Before: ',dfCablesXY_all.columns)\n",
    "#dfCablesXY_all = drop_columns(dfCablesXY_all, cablesXYdropCol)\n",
    "dfCablesXY_all = drop_columns(dfCablesXY_all, ['xMid', 'yMid', 'xEnd', 'yEnd','SUBTYPECD'])\n",
    "#dfCablesLater = drop_columns(dfCablesLater,cablesXYdropCol)\n",
    "dfCablesLater = dfCablesLater.merge(dfCablesXY_all, how='left', on='x')\n",
    "#print(dfCablesXY_all.columns)\n",
    "\n",
    "dfCablesLater = dfCablesLater.drop_duplicates(['x'], take_last=True)\n",
    "\n",
    "#used for finding cable installation years with poles in CYME node\n",
    "dfCablesLater_XY = dfCablesLater\n",
    "dfCablesLater_XY = drop_columns(dfCablesLater_XY,['install_year_x', 'x','FEEDERID','y'])\n",
    "dfCablesLater_XY = dfCablesLater_XY.rename(columns = {'install_year_y': 'install_year'})\n",
    "\n",
    "#Final cleanup\n",
    "dfCablesLater = drop_columns(dfCablesLater,['install_year_x', 'x','FEEDERID','y'])\n",
    "dfCablesLater = dfCablesLater.rename(columns = {'install_year_y': 'install_year'})\n",
    "\n",
    "dfCablesLater = dfCablesLater[np.isfinite(dfCablesLater['install_year'])] #one blank value\n",
    "#print('After duplicate:',dfCablesLater.shape)\n",
    "#print(dfCablesXY.columns)\n",
    "MasterFile = pd.ExcelWriter(UG_PRI_CABLE_TABLE_TEMPLATE)\n",
    "dfCablesLater.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('ML Cables analysis completed')\n",
    "# print('Before:', dfCablesLatLongV1.shape) # Before: (3888, 50)\n",
    "# dfCablesLatLongV1 = dfCablesLatLongV1.drop_duplicates(['xStart'], take_last=True)\n",
    "# print('After:', dfCablesLatLongV1.shape) # After: (3188, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4833, 4)\n",
      "With k =   1 ,a score of:  37.7981651376\n",
      "With k =   2 ,a score of:  40.0\n",
      "With k =   3 ,a score of:  38.3486238532\n",
      "With k =   5 ,a score of:  36.6972477064\n",
      "With k =   10 ,a score of:  37.247706422\n",
      "With k =   20 ,a score of:  34.6788990826\n",
      "Prediction accuracy:  38.3486238532\n",
      "With k =   1 ,a score of:  35.1648351648\n",
      "With k =   2 ,a score of:  36.9963369963\n",
      "With k =   3 ,a score of:  36.63003663\n",
      "With k =   5 ,a score of:  38.6446886447\n",
      "With k =   10 ,a score of:  37.9120879121\n",
      "With k =   20 ,a score of:  37.1794871795\n",
      "Prediction accuracy:  36.63003663\n",
      "Pole installation year matching analysis completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:420: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Poles Match with installation years - over 54% installed 97-2000\n",
    "#**********************************************************************\n",
    "# Match poles with OH Tx\n",
    "#**********************************************************************\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "#dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "#dfOHCondLatLong = dfOHCondLatLongV1\n",
    "#dfCablesLatLong = dfCablesLatLongV1\n",
    "dfTxLatLong = dfTxLatLongV1\n",
    "\n",
    "polesXYDropCols = ['FID', 'OBJECTID', 'WORKORDERI','FIELDVERIF', 'COMMENTS','CREATIONUS', \n",
    "                        'DATECREATE', 'LASTUSER', 'DATEMODIFI', 'WORKREQUES','DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                        'WORKFLOWST', 'WORKFUNCTI','SYMBOLROTA', 'GPSDATE', 'GISONUMBER', 'GISOTYPENB', 'SUBTYPECD',\n",
    "                        'LABELTEXT', 'OWNERSHIP', 'COMPATIBLE', 'STRUCTUREN', 'FEATURE_ST','STREETLIGH', 'REPLACED_D', \n",
    "                        'CONDITION', 'CONDITION_','CONDITION1']\n",
    "\n",
    "\n",
    "# OH Tx: 1/9/10 - 1Ph/3Ph/2Ph [1125/510/7: 1347 counts]\n",
    "dfPolesLater = dfPoles\n",
    "dfOHTxLater = dfOHTransformers\n",
    "dfOHTxXY = pd.DataFrame(dfTxLatLong[(dfTxLatLong.SUBTYPECD == 1) |\n",
    "                                    (dfTxLatLong.SUBTYPECD == 9) |\n",
    "                                    (dfTxLatLong.SUBTYPECD == 10)])\n",
    "\n",
    "\n",
    "txXYDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI','FEEDERID','FIELDVERIF', 'COMMENTS', \n",
    "                     'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID',\n",
    "                     'WORKFLOWST', 'WORKFUNCTI', 'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'SYMBOLROTA', 'GPSDATE', \n",
    "                     'GISONUMBER','GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE', 'OWNERSHIP','PHASEDESIG', \n",
    "                     'OPERATINGV', 'NOMINALVOL', 'GROUNDREAC', 'GROUNDRESI','MAGNETIZIN', 'MAGNETIZ_1', 'HIGHSIDEGR', \n",
    "                     'HIGHSIDE_1', 'HIGHSIDEPR','LOCATIONTY', 'FAULTINDIC', 'COOLINGTYP', 'FEATURE_ST','KVA', 'UNITS', \n",
    "                     'DEMAND_KVA', 'DEMAND_DAT', 'STREET_LIG', 'HIGHSIDECO','LOWSIDECON', 'LOWSIDEGRO', 'LOWSIDEVOL', \n",
    "                     'LATITUDE', 'LONGITUDE','RATEDKVA', 'FeederID_1', 'EnergizedP', 'SourceCoun', 'Loop','FEEDERID2']\n",
    "\n",
    "dfOHTxXY = drop_columns(dfOHTxXY, txXYDropCols)\n",
    "\n",
    "# drop XY cols, only 'DEVICENUMB', 'x','y', 'installation_year'\n",
    "\n",
    "dfPolesXY = drop_columns(dfPolesLatLong, polesXYDropCols)\n",
    "dfPolesXY = dfPolesXY.rename(columns={'DEVICENUMB': 'id','INSTALLATI':'install_year'})\n",
    "dfOHTxXY = dfOHTxXY.rename(columns={'DEVICENUMB': 'tx','INSTALLATI':'install_year'})\n",
    "#print(dfPolesXY.columns)\n",
    "dfPolesXY = dfPolesXY[dfPolesXY.id.notnull()]\n",
    "\n",
    "dfPolesXY['install_year'] = dfPolesXY['install_year'].apply(lambda x: x.year)\n",
    "dfOHTxXY['install_year'] = dfOHTxXY['install_year'].apply(lambda x: x.year)\n",
    "# print(dfPolesXY.head(2))\n",
    "# print(dfOHTxXY.head(2))\n",
    "\n",
    "# # Machine Learning: empty and filled\n",
    "# #def nearest_neighbor(dfMain, trainX, trainY, classX, neighborCount, dfUnknown):\n",
    "#years_list =[1997,1998,1999,2000]\n",
    "#df = df[(df.one > 0) | (df.two > 0) | (df.three > 0) & (df.four < 1)]\n",
    "dfPolesXY_Unknown = dfPolesXY.loc[(dfPolesXY.install_year == 1997) |\n",
    "                                  (dfPolesXY.install_year == 1998) |\n",
    "                                  (dfPolesXY.install_year == 1999) |\n",
    "                                  (dfPolesXY.install_year == 2000) |\n",
    "                                  (dfPolesXY.install_year.isnull())]\n",
    "\n",
    "print(dfPolesXY_Unknown.shape) #4771, 4\n",
    "\n",
    "#******************************************************\n",
    "# OH Tx - 3 tx missing installation years - use k-NN\n",
    "#******************************************************\n",
    "# separate empty and non-empty 'install_year' values\n",
    "dfOHTxXY_Train = dfOHTxXY[dfOHTxXY['install_year'].notnull()] \n",
    "dfOHTxXY_Empty = dfOHTxXY[dfOHTxXY['install_year'].isnull()] \n",
    "#print(dfOHTxXY_Empty.shape)\n",
    "# train the model\n",
    "\n",
    "dfOHTxXY_Empty.loc[:,'install_year'] = nearest_neighbor(dfOHTxXY_Train, 'x','y','install_year',3,dfOHTxXY_Empty)\n",
    "dfOHTxXY_new = pd.concat([dfOHTxXY_Train,dfOHTxXY_Empty])\n",
    "# fill in empty values\n",
    "\n",
    "# merge with original df\n",
    "dfOHTxLater = drop_columns(dfOHTxLater,'install_year')\n",
    "dfOHTxLater = dfOHTxLater.merge(dfOHTxXY_new, how='left', left_on='id', right_on='tx')\n",
    "dfOHTxLater = drop_columns(dfOHTxLater,['x','y','tx'])\n",
    "\n",
    "dfPolesXY_Train = dfOHTxXY_new\n",
    "dfPolesXY_Train = dfPolesXY_Train[np.isfinite(dfPolesXY_Train['install_year'])] # drop NaNs\n",
    "\n",
    "# print('UG Switches Prediction:')\n",
    "dfPolesXY_Unknown.loc[:,'install_year'] = nearest_neighbor(dfPolesXY_Train, 'x','y','install_year',3, dfPolesXY_Unknown)\n",
    "#print(dfPolesXY_Unknown.columns)\n",
    "dfPolesXY_Unknown = drop_columns(dfPolesXY_Unknown, ['x','y'])\n",
    "#dfPolesXY_All = dfPolesXY.merge(dfPolesXY_Unknown, how='left', on='x', suffixes=('_all', '_uk'))\n",
    "dfPolesXY_All = dfPoles.merge(dfPolesXY_Unknown, how='left', on='id', suffixes=('_all', '_uk'))\n",
    "#dfPolesXY_All = drop_columns(dfPolesXY_All, ['install_year_all'])\n",
    "#dfPolesXY_All = dfPolesXY_All.rename(columns={'install_year_uk': 'install_year'})\n",
    "#print(dfPolesXY_All.head(3))\n",
    "#dfPolesXY_All['install_year_all'] = dfPolesXY_All['install_year_uk'].apply(lambda x: None if math.isnan(x) else x)\n",
    "#This is a where conditional, saying give me the value for A if A > B, else give me B\n",
    "# df['A'].where(df['A']>df['B'],df['B'])\n",
    "dfPolesXY_All['install_year'] = dfPolesXY_All['install_year_uk'].where(dfPolesXY_All['install_year_uk']> 0,\n",
    "                                                                     dfPolesXY_All['install_year_all'])\n",
    "dfPolesXY_All = drop_columns(dfPolesXY_All, ['install_year_uk','install_year_all'])\n",
    "# # 40% accuracy\n",
    "\n",
    "# Overwrite original OH Tx file\n",
    "#dfOHTxLater = dfOHTransformers\n",
    "MasterFile = pd.ExcelWriter(OH_TX_TABLE_TEMPLATE)\n",
    "dfOHTxLater.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "dfPolesXY_YY = dfPolesXY_All\n",
    "# Overwrite original pole template file\n",
    "MasterFile = pd.ExcelWriter(POLES_TABLE_TEMPLATE)\n",
    "dfPolesXY_All.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole installation year matching analysis completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Feeders:  36\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 6 : Read all CYME feeders to populate dfAllNodes df - tie Poles with respective feeder ids\n",
    "#*****************************************************************************************************\n",
    "# fileName - iterate through entire folder :)\n",
    "#fileName = '3S3-1_Crestwood_Feeder_Details.xlsx'\n",
    "#input directory\n",
    "inputDirectory = 'Metsco_Feeder_Reports'\n",
    "\n",
    "# define filepath and sort the file list\n",
    "filesList = glob(os.path.join(inputDirectory, '*.xlsx'))\n",
    "numFiles = len(filesList)\n",
    "sortedFileList = sorted(filesList)\n",
    "\n",
    "# variables\n",
    "dictFeeders = {}\n",
    "dfAllNodes_list = pd.DataFrame()\n",
    "\n",
    "# read text files in tweet_input directory\n",
    "for f in sortedFileList:\n",
    "\n",
    "    fileName = os.path.basename(f).split('_')\n",
    "    FeederKey = fileName[0]\n",
    "    #print(FeederKey)\n",
    "    \n",
    "    if ('$' not in FeederKey):\n",
    "        # Read CYME Feeder xlsx file into dataframes\n",
    "        with pd.ExcelFile(f) as xlsx:\n",
    "            #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "            dfTopology = pd.read_excel(xlsx, 'Topology') # 280 rows\n",
    "            dfSpotLoads = pd.read_excel(xlsx, 'Spot Loads') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "            dfLoads = pd.read_excel(xlsx, 'Loads') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "            dfCables = pd.read_excel(xlsx, 'Cables')\n",
    "            dfSwitches = pd.read_excel(xlsx, 'Switches') # 41 items\n",
    "            dfNodes = pd.read_excel(xlsx, 'Nodes') # 249 items\n",
    "            dfOHlines = pd.read_excel(xlsx, 'OverheadLinesByPhase') #Neutral - 94, Section Id - 381\n",
    "            dfFuses = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "\n",
    "            # # Strip '\\n' from column headers\n",
    "            dfTopology.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSpotLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfCables.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSwitches.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfNodes.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfOHlines.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfFuses.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            #print(dfNodes.columns)\n",
    "            dfAllNodes_list = dfAllNodes_list.append(dfNodes)\n",
    "\n",
    "print('Number of Feeders: ', numFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole installation year matching analysis completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:21: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:22: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 7: Finding circuits: For both poles and UG Cables by matching with all nodes \n",
    "#*****************************************************************************************************\n",
    "from collections import defaultdict\n",
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "# dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "# dfCablesLatLong = dfCablesLatLongV1\n",
    "# dfTxLatLong = dfTxLatLongV1\n",
    "\n",
    "#print(dfAllNodes_list.columns)\n",
    "dfPolesXY_All = dfPolesXY_YY\n",
    "dfAllNodes_list = dfAllNodes_list.rename(columns={'Network Id': 'CIRCUIT',\n",
    "                                                  'Node Id': 'xy'})\n",
    "\n",
    "dfAllNodes_list['NodeID_x'], dfAllNodes_list['NodeID_y'] = zip(*dfAllNodes_list['xy'].\n",
    "                                                               apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "\n",
    "# Convert circuit ids, fuse ids, switch ids and/or drop them\n",
    "#dfAllNodes_list['NodeID_x'] = dfAllNodes_list['NodeID_x'].astype(float)\n",
    "dfAllNodes_list.loc[:,'NodeID_x'] = dfAllNodes_list.loc[:,'NodeID_x'].convert_objects(convert_numeric=True)\n",
    "dfAllNodes_list.loc[:,'NodeID_y'] = dfAllNodes_list.loc[:,'NodeID_y'].convert_objects(convert_numeric=True)\n",
    "\n",
    "dfAllNodes_list = dfAllNodes_list[dfAllNodes_list.NodeID_x.notnull()]\n",
    "#print(dfAllNodes_XY_remain.isnull().sum())\n",
    "dfAllNodes_list = dfAllNodes_list[dfAllNodes_list.NodeID_y.notnull()]\n",
    "\n",
    "dfPoles.columns = map(str.lower, dfPoles.columns)\n",
    "\n",
    "polesLatLongDropCols = ['FID', 'OBJECTID', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF', 'COMMENTS','CREATIONUS', \n",
    "                        'DATECREATE', 'LASTUSER', 'DATEMODIFI', 'WORKREQUES','DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                        'WORKFLOWST', 'WORKFUNCTI','SYMBOLROTA', 'GPSDATE', 'GISONUMBER', 'GISOTYPENB', 'SUBTYPECD',\n",
    "                        'LABELTEXT', 'OWNERSHIP', 'COMPATIBLE', 'STRUCTUREN', 'FEATURE_ST','STREETLIGH', 'REPLACED_D', \n",
    "                        'CONDITION', 'CONDITION_','CONDITION1']\n",
    "\n",
    "# 'DEVICENUMB', 'x', 'y'\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, polesLatLongDropCols)\n",
    "\n",
    "# ['DEVICENUMB', 'x', 'y', 'xy']\n",
    "dfPolesLatLong = dfPolesLatLong.rename(columns={'DEVICENUMB': 'POLE_ID'})\n",
    "dropMoreLatLongCols =['x','y']\n",
    "#dropMoreWireLatLongCols =['x','y','xMid','yMid','xEnd', 'yEnd']\n",
    "dropMoreWireLatLongCols =['xStart','yStart','xMid','yMid','xEnd', 'yEnd']\n",
    "\n",
    "dfPoleIDs = dfPolesLatLong['POLE_ID']\n",
    "dictPoleIDs = defaultdict(list)\n",
    "\n",
    "xDelta = 5\n",
    "yDelta = 5\n",
    "\n",
    "for poleID, Px, Py in zip(dfPolesLatLong['POLE_ID'],dfPolesLatLong['x'],dfPolesLatLong['y']):\n",
    "    for circuitID, Nx, Ny in zip(dfAllNodes_list['CIRCUIT'],dfAllNodes_list['NodeID_x'],dfAllNodes_list['NodeID_y']):\n",
    "        if(abs(Px-Nx) < xDelta and abs(Py-Ny) < yDelta):\n",
    "            if circuitID not in dictPoleIDs[poleID]:\n",
    "                dictPoleIDs[poleID].append(circuitID)\n",
    "\n",
    "dfPolesNodes = pd.DataFrame.from_dict(dictPoleIDs, orient='index')\n",
    "\n",
    "#df.reset_index(level=0, inplace=True)\n",
    "dfPolesNodes.reset_index(level=0, inplace=True)\n",
    "dfPolesNodes = dfPolesNodes.rename(columns={0:'CIRCUIT1', \n",
    "                                            1:'CIRCUIT2',\n",
    "                                            2:'CIRCUIT3',\n",
    "                                            'index':'POLE_ID'})\n",
    "#print(dfPolesNodes.columns) #['POLE_ID', 'CIRCUIT1', 'CIRCUIT2', 'CIRCUIT3']\n",
    "\n",
    "MasterFile = pd.ExcelWriter('V8_PolesNodes.xlsx')\n",
    "dfPolesNodes.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "#print('Pole Nodes')\n",
    "\n",
    "dfPolesXY_All = dfPolesXY_All.merge(dfPolesNodes, how='left', left_on='id', right_on='POLE_ID')\n",
    "#print(dfPolesXY_All.columns)\n",
    "\n",
    "MasterFile = pd.ExcelWriter(POLES_TABLE_TEMPLATE)\n",
    "dfPolesXY_All.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole installation year matching analysis completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeder load table completed\n"
     ]
    }
   ],
   "source": [
    "#********************************************\n",
    "# Feeder loading table\n",
    "#********************************************\n",
    "\n",
    "RES_LOAD = 'feeder_residential_load'\n",
    "COM_LOAD = 'feeder_commercial_load'\n",
    "IND_LOAD = 'feeder_industrial_load'\n",
    "\n",
    "fdr_dropCols = ['asset_class_code','asset_subclass_code', 'hi', 'primary_voltage', 'tx_residential', \n",
    "                'tx_commercial','tx_industrial', 'device_residential', 'device_commercial','device_industrial', \n",
    "                'upstream_device','prid', 'in_valley', 'pcb', 'install_year','id']\n",
    "\n",
    "dfFdrs_total = 0\n",
    "dfFdr_OHtx = dfOHTxLater\n",
    "dfFdr_UGtx = dfUGTxLater\n",
    "dfFdr_OHtx = drop_columns(dfFdr_OHtx,fdr_dropCols)\n",
    "dfFdr_UGtx = drop_columns(dfFdr_UGtx,fdr_dropCols)\n",
    "dfFdr_OHtx = drop_columns(dfFdr_OHtx,['banking'])\n",
    "dfFdr_UGtx = drop_columns(dfFdr_UGtx,['pedestal','switchable', 'switch_type'])\n",
    "\n",
    "#This is a where conditional, saying give me the value for A if A > B, else give me B\n",
    "# df['A'].where(df['A']>df['B'],df['B'])\n",
    "#http://stackoverflow.com/questions/27041724/using-conditional-to-generate-new-column-in-pandas-dataframe\n",
    "#df.loc[(df['used'] >0.0) & (df['used'] < 1.0), 'alert'] = 'Partial'\n",
    "#print(dfFdr_OHtx_Rx.aggregate(np.sum))\n",
    "#UGTx: 1-2Ph <=100kVA #OHTx: 1Ph/2Ph < 150kVA\n",
    "#df.groupby(['col5','col2']).size().reset_index()\n",
    "dfFdr_OHtx_Rx = dfFdr_OHtx[(dfFdr_OHtx['phasing'] != 3) & (dfFdr_OHtx['kva'] <=150)]\n",
    "dfFdr_UGtx_Rx = dfFdr_UGtx[(dfFdr_UGtx['phasing'] != 3) & (dfFdr_UGtx['kva'] <=100)]\n",
    "dfFdr_Rx = pd.concat([dfFdr_OHtx_Rx,dfFdr_UGtx_Rx])\n",
    "dfFdr_Rx = dfFdr_Rx.rename(columns={'kva': RES_LOAD})\n",
    "# UGtx: 3Ph: 100-350kVA, 1Ph: <100kVA; group it by less than 350kVA # OHtx: 3Ph, \n",
    "dfFdr_OHtx_Med = dfFdr_OHtx[(dfFdr_OHtx['phasing'] == 3)]\n",
    "dfFdr_UGtx_Med = dfFdr_UGtx[(dfFdr_UGtx['phasing'] == 3) & (dfFdr_UGtx['kva'] <=100) |\n",
    "                            (dfFdr_UGtx['phasing'] != 3) & ((dfFdr_UGtx['kva'] > 100) & (dfFdr_UGtx['kva'] <=350))]\n",
    "dfFdr_Med = pd.concat([dfFdr_OHtx_Med,dfFdr_UGtx_Med])\n",
    "dfFdr_Med = dfFdr_Med.rename(columns={'kva': COM_LOAD})\n",
    "#UGTx: Greater than 350kVA\n",
    "dfFdr_UGtx_Large = dfFdr_UGtx[(dfFdr_UGtx['kva'] > 350)]\n",
    "dfFdr_Large = dfFdr_UGtx_Large\n",
    "dfFdr_Large = dfFdr_Large.rename(columns={'kva': IND_LOAD})\n",
    "#\n",
    "dfFdrs_Loads = pd.concat([dfFdr_Rx, dfFdr_Med, dfFdr_Large])\n",
    "dfFdrs_Loads = drop_columns(dfFdrs_Loads, ['phasing'])\n",
    "dfFdrs_total = pd.DataFrame(dfFdrs_Loads.groupby('circuit').sum()).reset_index()\n",
    "\n",
    "#50% nameplate rating\n",
    "dfFdrs_total[RES_LOAD] = dfFdrs_total[RES_LOAD].apply(lambda x: x/2)\n",
    "dfFdrs_total[COM_LOAD] = dfFdrs_total[COM_LOAD].apply(lambda x: x/2)\n",
    "dfFdrs_total[IND_LOAD] = dfFdrs_total[IND_LOAD].apply(lambda x: x/2)\n",
    "\n",
    "# asset_id, feeder,scada_switch_count,manual_switch_count,da_switch_count,\n",
    "#feeder_residential_load,feeder_commercial_load,feeder_industrial_load,configuration,\n",
    "#switching_sections \n",
    "#Fdrs_key = pd.Series(dfFdr_Load['circuit'].values.ravel()).unique()\n",
    "\n",
    "dfFdrs_total['circuit'] = dfFdrs_total['circuit'].apply(lambda x: re.sub('[\\s+]', '', x))\n",
    "# print(dfFdrs_total.head(3))\n",
    "# print(dfFdrs_total.columns)\n",
    "\n",
    "# Switches\n",
    "dfSwitchesCount = dfSwitchesV2\n",
    "\n",
    "dropSwitchesColsCount = ['ANCILLARYROLE','ENABLED','FEEDERINFO','ELECTRICTRACEWEIGHT','LOCATIONID','GPSDATE','LABELTEXT',\n",
    "                         'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXOPERATINGVOLTAGE','MAXCONTINUOUSCURRENT','PRESENTPOSITION_R', \n",
    "                         'PRESENTPOSITION_Y', 'PRESENTPOSITION_B','NORMALPOSITION_R','NORMALPOSITION_Y','NORMALPOSITION_B', \n",
    "                         'SCADACONTROLID', 'SCADAMONITORID','PREFERREDCIRCUITSOURCE','TIESWITCHINDICATOR','GANGOPERATED', \n",
    "                         'MANUALLYOPERATED','FEATURE_STATUS','HYPERLINK','HYPERLINK_PGDB','SYMBOLROTATION','INSULATOR_MATERIAL',\n",
    "                         'INSTALLATIONDATE','FEEDERID2','SUBTYPECD','COMPATIBLEUNITID','PHASEDESIGNATION']\n",
    "\n",
    "dfSwitchesCount = drop_columns(dfSwitchesCount, dropSwitchesColsCount)\n",
    "dfSwitchesCircuit = pd.DataFrame(dfSwitchesCount.groupby('FEEDERID').count()).reset_index()\n",
    "\n",
    "dfSwitchesCircuit = dfSwitchesCircuit.rename(columns={'FEEDERID': 'circuit', 'DEVICENUMBER': 'manual_switch_count'})\n",
    "dfFdrs_total = dfFdrs_total.merge(dfSwitchesCircuit, how='left', on='circuit')\n",
    "dfFdrs_total = dfFdrs_total.rename(columns={'circuit':'feeder'})\n",
    "#print(dfFdrs_total.head(4))\n",
    "# Remaining columns \n",
    "dfFdrs_total['scada_switch_count'] = 0\n",
    "dfFdrs_total['da_switch_count'] = 0\n",
    "dfFdrs_total['configuration'] = 'None'\n",
    "dfFdrs_total['switching_sections'] = 0\n",
    "dfFdrs_total['asset_id'] = pd.Series(range(0,len(dfFdrs_total['feeder'])))\n",
    "\n",
    "dfFdrs_total = dfFdrs_total[['asset_id','feeder','scada_switch_count','manual_switch_count','da_switch_count',\n",
    "                             'feeder_residential_load','feeder_commercial_load','feeder_industrial_load',\n",
    "                             'configuration','switching_sections']]\n",
    "dfFdrs_total=dfFdrs_total.fillna(0)\n",
    "MasterFile = pd.ExcelWriter('V8_FeederLoads.xlsx')\n",
    "dfFdrs_total.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Feeder load table completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begins\n",
      "UG and OH Tx PRIDs matched and loading types classified\n"
     ]
    }
   ],
   "source": [
    "print('begins')\n",
    "RES_LOAD = 'feeder_residential_load'\n",
    "MED_COM_LOAD = 'feeder_small_med_commercial_load'\n",
    "LARGE_LOAD = 'feeder_large_commercial_load'\n",
    "\n",
    "with pd.ExcelFile('V5_PRID_TX_LOOKUP.xlsx') as xls:\n",
    "    dfPRIDtx = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "#remove the column and rename it in near future\n",
    "dfPRIDtx = dfPRIDtx.rename(columns={'transformerid':'id'})\n",
    "#dfPRIDtx = drop_columns(dfPRIDtx, ['TransformerID_x', 'TransformerID_y'])\n",
    "\n",
    "dfPRID_OHtx = dfOHTxLater\n",
    "dfPRID_UGtx = dfUGTxLater\n",
    "dfPRID_OHtx = drop_columns(dfPRID_OHtx,['prid'])\n",
    "dfPRID_UGtx = drop_columns(dfPRID_UGtx,['prid'])\n",
    "\n",
    "dfPRID_OHtx = dfPRID_OHtx.merge(dfPRIDtx, how='left', on='id')\n",
    "dfPRID_UGtx = dfPRID_UGtx.merge(dfPRIDtx, how='left', on='id')\n",
    "\n",
    "#PRIDdropCols = ['tx_residential','tx_commercial','tx_industrial']\n",
    "PRIDdropCols = [RES_LOAD,MED_COM_LOAD,LARGE_LOAD]\n",
    "\n",
    "dfPRID_OHtx = drop_columns(dfPRID_OHtx, PRIDdropCols)\n",
    "\n",
    "# dfPRID_OHtx = dfPRID_OHtx.rename(columns={RES_LOAD:'tx_residential',\n",
    "#                                           MED_COM_LOAD:'tx_med_com_load',\n",
    "#                                           LARGE_LOAD:'tx_large_commercial_load',\n",
    "#                                           'PRID':'prid'})\n",
    "\n",
    "#'secondary_voltage','fused','banking'\n",
    "\n",
    "\n",
    "dfPRID_OHtx['kva'] = dfPRID_OHtx['kva'].astype(float)\n",
    "dfPRID_UGtx['kva'] = dfPRID_UGtx['kva'].astype(float)\n",
    "dfPRID_OHtx['phasing'] = dfPRID_OHtx['phasing'].astype(float)\n",
    "dfPRID_UGtx['phasing'] = dfPRID_UGtx['phasing'].astype(float)\n",
    "\n",
    "def phasing_kva(phasing,kva,custClass):\n",
    "    if((kva > 350) & (custClass=='classLarge')):\n",
    "        return kva/2\n",
    "    elif((phasing == 3) & (kva <=350) & (custClass=='classMed')):\n",
    "        return kva/2\n",
    "    elif((phasing != 3) & (kva <=150) & (custClass=='classRx')):\n",
    "        return kva/2\n",
    "    else:\n",
    "        return 0\n",
    "# def valuation_formula(x, y):\n",
    "#     return x * y * 0.5\n",
    "#df['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n",
    "\n",
    "dfPRID_OHtx['tx_residential'] = dfPRID_OHtx.apply(lambda row: phasing_kva( row['phasing'],row['kva'], 'classRx'), axis=1)\n",
    "dfPRID_OHtx['tx_commercial'] = dfPRID_OHtx.apply(lambda row: phasing_kva( row['phasing'],row['kva'], 'classMed'), axis=1)\n",
    "dfPRID_OHtx['tx_industrial'] = dfPRID_OHtx.apply(lambda row: phasing_kva( row['phasing'],row['kva'], 'classLarge'), axis=1)\n",
    "\n",
    "dfPRID_UGtx['tx_residential'] = dfPRID_UGtx.apply(lambda row: phasing_kva( row['phasing'],row['kva'], 'classRx'), axis=1)\n",
    "dfPRID_UGtx['tx_commercial'] = dfPRID_UGtx.apply(lambda row: phasing_kva( row['phasing'],row['kva'], 'classMed'), axis=1)\n",
    "dfPRID_UGtx['tx_industrial'] = dfPRID_UGtx.apply(lambda row: phasing_kva( row['phasing'],row['kva'], 'classLarge'), axis=1)\n",
    "\n",
    "# for index, row in dfPRID_OHtx.iterrows():\n",
    "#     row['tx_residential'] = phasing_kva(row['phasing'],row['kva'])\n",
    "\n",
    "#device_residential-device_commercial-device_industrial\tupstream_device\tprid\n",
    "dfPRID_OHtx['in_valley'] = 'No'\n",
    "dfPRID_OHtx['pcb'] ='refer Eval data'\n",
    "dfPRID_OHtx['hi'] = 'NA'\n",
    "dfPRID_OHtx.index.name = 'asset_id'\n",
    "dfPRID_OHtx = dfPRID_OHtx[['asset_class_code','id','circuit','install_year','asset_subclass_code','hi','phasing',\n",
    "                           'primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "                           'device_commercial','device_industrial','upstream_device','prid','in_valley','pcb','banking',\n",
    "                           'secondary_voltage','fused']]\n",
    "\n",
    "MasterFile = pd.ExcelWriter(OH_TX_TABLE_TEMPLATE)\n",
    "dfPRID_OHtx.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "dfPRID_UGtx = drop_columns(dfPRID_UGtx, PRIDdropCols)\n",
    "\n",
    "#device_residential-device_commercial-device_industrial\tupstream_device\tprid\n",
    "dfPRID_UGtx['pedestal'] = 'NA'\n",
    "dfPRID_UGtx['pcb'] ='refer Eval data'\n",
    "dfPRID_UGtx['switch_type'] = 'NA'\n",
    "dfPRID_UGtx['hi'] = 'NA'\n",
    "dfPRID_UGtx['switch_type'] = 'NA'\n",
    "dfPRID_UGtx['switchable'] = 'NA'\n",
    "dfPRID_UGtx.index.name = 'asset_id'\n",
    "\n",
    "dfPRID_UGtx = dfPRID_UGtx[['asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "                           'primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "                           'device_commercial','device_industrial','upstream_device','pcb','pedestal','switchable',\n",
    "                           'switch_type','id','secondary_voltage','fused','banking']]\n",
    "\n",
    "dfPRID_UGtx = dfPRID_UGtx[dfPRID_UGtx['asset_subclass_code'] !='NETWORK_SUBMERSIBLE']\n",
    "\n",
    "MasterFile = pd.ExcelWriter(UG_TX_TABLE_TEMPLATE)\n",
    "dfPRID_UGtx.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('UG and OH Tx PRIDs matched and loading types classified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole attachments analysis completed\n"
     ]
    }
   ],
   "source": [
    "#*****************************************************************************************************\n",
    "# Cell # 7.1: Pole attachments: Poles XY with TX, Switches\n",
    "#*****************************************************************************************************\n",
    "# Switches\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfTxLatLong = dfTxLatLongV1\n",
    "\n",
    "dfPolesXY_aa = dfPolesXY_All\n",
    "\n",
    "#print(dfPolesXY_aa.columns)\n",
    "#print(dfPolesXY_aa.columns)\n",
    "polesLatLongDropCols = ['FID', 'OBJECTID', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF', 'COMMENTS','CREATIONUS', \n",
    "                        'DATECREATE', 'LASTUSER', 'DATEMODIFI', 'WORKREQUES','DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                        'WORKFLOWST', 'WORKFUNCTI','SYMBOLROTA', 'GPSDATE', 'GISONUMBER', 'GISOTYPENB', 'SUBTYPECD',\n",
    "                        'LABELTEXT', 'OWNERSHIP', 'COMPATIBLE', 'STRUCTUREN', 'FEATURE_ST','STREETLIGH', 'REPLACED_D', \n",
    "                        'CONDITION', 'CONDITION_','CONDITION1']\n",
    "\n",
    "# 'DEVICENUMB', 'x', 'y'\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, polesLatLongDropCols)\n",
    "dfPolesXY_aa = drop_columns(dfPolesXY_aa, ['device','circuit1','circuit2','circuit3','tx','tx_kva','tx_phasing'])\n",
    "#Change datatype to str for concatenation\n",
    "dfPolesLatLong['x'] = dfPolesLatLong['x'].astype(str)\n",
    "dfPolesLatLong['y'] = dfPolesLatLong['y'].astype(str)\n",
    "dfPolesLatLong['xy'] = dfPolesLatLong['x']+'-'+dfPolesLatLong['y']\n",
    "# ['DEVICENUMB', 'x', 'y', 'xy']\n",
    "dfPolesLatLong = dfPolesLatLong.rename(columns={'DEVICENUMB': 'POLE_ID'})\n",
    "dropMoreLatLongCols =['x','y']\n",
    "#dropMoreWireLatLongCols =['x','y','xMid','yMid','xEnd', 'yEnd']\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, dropMoreLatLongCols)\n",
    "\n",
    "#SWITCHES\n",
    "switchLatLongDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI', 'INSTALLATI','FIELDVERIF', 'COMMENTS', \n",
    "                         'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', \n",
    "                         'WMSID','WORKFLOWST', 'WORKFUNCTI',  'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'GPSDATE', \n",
    "                         'GISONUMBER', 'GISOTYPENB','LABELTEXT', 'OWNERSHIP', 'PHASEDESIG','OPERATINGV', 'NOMINALVOL', \n",
    "                         'MAXOPERATI', 'MAXCONTINU', 'PRESENTPOS', 'PRESENTP_1', 'PRESENTP_2', 'NORMALPOSI', 'NORMALPO_1',\n",
    "                         'NORMALPO_2','SCADACONTR', 'SCADAMONIT', 'PREFERREDC', 'TIESWITCHI', 'GANGOPERAT','MANUALLYOP',\n",
    "                         'FEATURE_ST', 'HYPERLINK', 'HYPERLINK_','SYMBOLROTA', 'INSULATOR_', 'FeederID_1', 'EnergizedP', \n",
    "                         'SourceCoun','Loop', 'Tie','COMPATIBLE','SUBTYPECD']\n",
    "\n",
    "dfSwitchesLatLong = drop_columns(dfSwitchesLatLong, switchLatLongDropCols)\n",
    "dfSwitchesLatLong = dfSwitchesLatLong.rename(columns={'DEVICENUMB': 'device',\n",
    "                                                      'FEEDERID': 'CIRCUIT1',\n",
    "                                                      'FEEDERID2': 'CIRCUIT2'})\n",
    "#Change datatype to str for concatenation\n",
    "dfSwitchesLatLong['x'] = dfSwitchesLatLong['x'].astype(str)\n",
    "dfSwitchesLatLong['y'] = dfSwitchesLatLong['y'].astype(str)\n",
    "dfSwitchesLatLong['xy'] = dfSwitchesLatLong['x']+'-'+dfSwitchesLatLong['y']\n",
    "# print(dfSwitchesLatLong.columns)\n",
    "#['FEEDERID', 'FEEDERID2', 'SUBTYPECD','DEVICENUMB', 'x','y', 'xy']\n",
    "dfSwitchesLatLong = drop_columns(dfSwitchesLatLong, dropMoreLatLongCols)\n",
    "\n",
    "# Poles and Switch match - 98 matches\n",
    "dfPolesSwitchLatLong = dfPolesLatLong.merge(dfSwitchesLatLong, how='left', on='xy')\n",
    "dfPolesSwitchLatLong = dfPolesSwitchLatLong[dfPolesSwitchLatLong.device.notnull()]\n",
    "# Pole-Switch Output\n",
    "MasterFile = pd.ExcelWriter('V7_PolesSwitches.xlsx')\n",
    "dfPolesSwitchLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "# drop Pole switch columns\n",
    "dfPolesSwitchLatLong = drop_columns(dfPolesSwitchLatLong, ['xy','CIRCUIT1', 'CIRCUIT2'])\n",
    "dfPolesXY_aa = dfPolesXY_aa.merge(dfPolesSwitchLatLong, how='left', left_on='id', right_on='POLE_ID')\n",
    "\n",
    "#print('dfPolesXY_aa cols:',dfPolesXY_aa.columns)\n",
    "#**********************************************************************\n",
    "# Tx\n",
    "#**********************************************************************\n",
    "txLatLongDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI', 'INSTALLATI','FIELDVERIF', 'COMMENTS', \n",
    "                     'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID',\n",
    "                     'WORKFLOWST', 'WORKFUNCTI', 'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'SYMBOLROTA', 'GPSDATE', \n",
    "                     'GISONUMBER','GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE', 'OWNERSHIP','PHASEDESIG', \n",
    "                     'OPERATINGV', 'NOMINALVOL', 'GROUNDREAC', 'GROUNDRESI','MAGNETIZIN', 'MAGNETIZ_1', 'HIGHSIDEGR', \n",
    "                     'HIGHSIDE_1', 'HIGHSIDEPR','LOCATIONTY', 'FAULTINDIC', 'COOLINGTYP', 'FEATURE_ST','KVA', 'UNITS', \n",
    "                     'DEMAND_KVA', 'DEMAND_DAT', 'STREET_LIG', 'HIGHSIDECO','LOWSIDECON', 'LOWSIDEGRO', 'LOWSIDEVOL', \n",
    "                     'LATITUDE', 'LONGITUDE','RATEDKVA', 'FeederID_1', 'EnergizedP', 'SourceCoun', 'Loop','FEEDERID2']\n",
    "\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, txLatLongDropCols)\n",
    "\n",
    "dfTxLatLong = dfTxLatLong.merge(dfOHTransformers, how='left', left_on='DEVICENUMB', right_on='id')\n",
    "\n",
    "txLatLongDropCols2 = ['DEVICENUMB','asset_class_code','asset_subclass_code', 'hi', 'primary_voltage','device_residential', \n",
    "                      'device_commercial','device_industrial','upstream_device', 'prid', 'in_valley', 'pcb','banking',\n",
    "                      'FEEDERID', 'install_year','tx_residential','tx_commercial', 'tx_industrial']\n",
    "\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, txLatLongDropCols2)\n",
    "\n",
    "#dfPRID_UGtx = dfPRID_UGtx.merge(dfPRIDtx, how='left', on='id')\n",
    "dfTxLatLong = dfTxLatLong.merge(dfPRIDtx, how='left', on='id')\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, ['fused', 'secondary_voltage'])\n",
    "dfTxLatLong = dfTxLatLong.rename(columns={'prid':'PRID'})\n",
    "#print(dfTxLatLong.isnull().sum())\n",
    "dfTxLatLong = dfTxLatLong.rename(columns={'feeder_residential_load':'tx_residential', \n",
    "                                          'feeder_small_med_commercial_load':'tx_commercial',\n",
    "                                          'feeder_large_commercial_load':'tx_industrial'})\n",
    "\n",
    "#print('dfTxLatLong',dfTxLatLong.columns)\n",
    "# print(dfTxLatLong.head(3))\n",
    "#Change datatype to str for concatenation\n",
    "dfTxLatLong['x'] = dfTxLatLong['x'].astype(str)\n",
    "dfTxLatLong['y'] = dfTxLatLong['y'].astype(str)\n",
    "dfTxLatLong['xy'] = dfTxLatLong['x']+'-'+dfTxLatLong['y']\n",
    "\n",
    "#['FEEDERID','DEVICENUMB', 'x','y', 'xy']\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, dropMoreLatLongCols)\n",
    "dfTxLatLong = dfTxLatLong.rename(columns={'circuit': 'CIRCUIT1', 'id':'txID'})\n",
    "dfPolesTxLatLong = drop_columns(dfPolesTxLatLong,['tx_residential','tx_commercial', 'tx_industrial'])\n",
    "dfPolesTxLatLong = dfPolesLatLong.merge(dfTxLatLong, how='left', on='xy') # Poles and Tx match - 1553 matches out of 1642 [89 no matches ~ 5%]\n",
    "dfPolesTxLatLong = dfPolesTxLatLong[dfPolesTxLatLong.txID.notnull()]\n",
    "#print('dfPolesTxLatLong',dfPolesTxLatLong.columns)\n",
    "# will merge each df independently\n",
    "dfPolesTxLatLong = drop_columns(dfPolesTxLatLong, ['xy','CIRCUIT1'])\n",
    "\n",
    "dfPolesXY_aa = drop_columns(dfPolesXY_aa, ['tx_residential', 'tx_commercial', 'tx_industrial'])\n",
    "\n",
    "dfPolesXY_aa = dfPolesXY_aa.merge(dfPolesTxLatLong, how='left', left_on='id', right_on='POLE_ID')\n",
    "#print('dfPolesXY_aa with TX cols:',dfPolesXY_aa.columns)\n",
    "dfPolesXY_aa = dfPolesXY_aa.rename(columns={'phasing_x': 'phasing', \n",
    "                                            'phasing_y':'tx_phasing',\n",
    "                                            'txID':'tx',\n",
    "                                            'kva':'tx_kva'})\n",
    "#                                             'CIRCUIT1_x':'circuit1',\n",
    "#                                             'CIRCUIT2_x':'circuit2',\n",
    "#                                             'CIRCUIT3_x':'circuit3'})\n",
    "\n",
    "# dfNPTS = pd.concat([dfPolesNodes, dfPolesTxSwitchLatLong])\n",
    "# dfNPTS = drop_columns(dfNPTS, ['xy','CIRCUIT1','CIRCUIT2','CIRCUIT3'])\n",
    "# dfPolesXY_aa = dfPolesXY_aa.merge(dfNPTS, how='left', on='POLE_ID')\n",
    "\n",
    "dfPolesXY_aa['phasing'] = dfPolesXY_aa['tx_phasing']\n",
    "#dfPolesXY_aa['num_circuits'] ='refer Eval data'\n",
    "dfPolesXY_aa['in_valley'] = 'NA'\n",
    "dfPolesXY_aa['hi'] = 'NA'\n",
    "\n",
    "polesXY_dropCols = ['POLE_ID_x','POLE_ID_y','POLE_ID','prid']\n",
    "dfPolesXY_aa = drop_columns(dfPolesXY_aa, polesXY_dropCols)\n",
    "dfPolesXY_aa.columns = map(str.lower, dfPolesXY_aa.columns)\n",
    "\n",
    "def isCircuit(c1, c2, c3):\n",
    "    if c3:\n",
    "        return 3\n",
    "    elif(c2):\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "dfPolesXY_aa['num_circuits'] = dfPolesXY_aa.apply(lambda row: \n",
    "                                                  isCircuit(row['circuit1'],row['circuit2'],row['circuit3']), axis=1)\n",
    "#print(dfPolesXY_aa.columns)\n",
    "\n",
    "#rearrange\n",
    "dfPolesXY_aa = dfPolesXY_aa[['install_year','id','asset_class_code','asset_subclass_code','hi','phasing','prid','tx',\n",
    "                             'tx_type','circuit1','circuit2','circuit3','circuit4','circuit5','circuit6','circuit7',\n",
    "                             'circuit8','in_valley','tx_residential','tx_commercial','tx_industrial','num_circuits',\n",
    "                             'device','tx_kva','tx_phasing','height','pole_class']]\n",
    "\n",
    "MasterFile = pd.ExcelWriter(POLES_TABLE_TEMPLATE)\n",
    "dfPolesXY_aa.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole attachments analysis completed')\n",
    "\n",
    "#Transformer-Poles match output\n",
    "# MasterFile = pd.ExcelWriter('V5_PolesTx.xlsx')\n",
    "# dfPolesTxLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "#Transformer-Switch-Poles match output\n",
    "# dfPolesTxSwitchLatLong.columns = map(str.lower, dfPolesTxSwitchLatLong.columns)\n",
    "# MasterFile = pd.ExcelWriter('V7_PolesTxSwitch.xlsx')\n",
    "# dfPolesTxSwitchLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "#NPTS(NodesPolesTxSwitch) match output\n",
    "# MasterFile = pd.ExcelWriter('V7_PolesNodesTxSwitch.xlsx')\n",
    "# dfNPTS.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "# print(dfNPTS['POLE_ID'].nunique()) #7237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#*****************************************************************************************************\n",
    "# End for now\n",
    "#*****************************************************************************************************\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
