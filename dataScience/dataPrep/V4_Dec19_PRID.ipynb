{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Feeders:  35\n",
      "(3585, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# fileName - iterate through entire folder :)\n",
    "#fileName = '3S3-1_Crestwood_Feeder_Details.xlsx'\n",
    "#******************************************************\n",
    "# FUNCTIONS\n",
    "#******************************************************\n",
    "def drop_columns(dfAssetClass, dropColumns):\n",
    "    dfAssetClass = dfAssetClass.drop(dropColumns, axis=1)\n",
    "    return dfAssetClass\n",
    "\n",
    "RES_LOAD = 'feeder_residential_load'\n",
    "MED_COM_LOAD = 'feeder_small_med_commercial_load'\n",
    "LARGE_LOAD = 'feeder_large_commercial_load'\n",
    "#input directory\n",
    "inputDirectory = 'Metsco_Feeder_Reports'\n",
    "\n",
    "# define filepath and sort the file list\n",
    "filesList = glob(os.path.join(inputDirectory, '*.xlsx'))\n",
    "numFiles = len(filesList)\n",
    "print('Number of Feeders: ', numFiles)\n",
    "sortedFileList = sorted(filesList)\n",
    "count = 0\n",
    "# variables\n",
    "dictFeeders = {}\n",
    "allNodes_list = pd.DataFrame()\n",
    "\n",
    "# read text files in tweet_input directory\n",
    "for f in sortedFileList:\n",
    "\n",
    "    fileName = os.path.basename(f).split('_')\n",
    "    FeederKey = fileName[0]\n",
    "    #print(FeederKey)\n",
    "    \n",
    "    if ('$' not in FeederKey):\n",
    "        count += 1\n",
    "        # Read CYME Feeder xlsx file into dataframes\n",
    "        with pd.ExcelFile(f) as xlsx:\n",
    "            #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "            dfTopology = pd.read_excel(xlsx, 'Topology') # 280 rows\n",
    "            dfSpotLoads = pd.read_excel(xlsx, 'Spot Loads') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "            dfLoads = pd.read_excel(xlsx, 'Loads') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "            dfCables = pd.read_excel(xlsx, 'Cables')\n",
    "            dfSwitches = pd.read_excel(xlsx, 'Switches') # 41 items\n",
    "            dfNodes = pd.read_excel(xlsx, 'Nodes') # 249 items\n",
    "            dfOHlines = pd.read_excel(xlsx, 'OverheadLinesByPhase') #Neutral - 94, Section Id - 381\n",
    "            dfFuses = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "\n",
    "            # # Strip '\\n' from column headers\n",
    "            dfTopology.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSpotLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfCables.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSwitches.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfNodes.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfOHlines.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfFuses.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            #print(dfNodes.columns)\n",
    "            #allNodes_list = allNodes_list.append(dfNodes)\n",
    "            # Rename column headers\n",
    "            dfTopology.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "            #dfSpotLoads.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
    "            dfLoads.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
    "            dfCables.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
    "            dfSwitches.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
    "            dfNodes.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "            dfOHlines.rename(columns=lambda x: 'OHlines_'+x, inplace=True)\n",
    "            dfFuses.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n",
    "            \n",
    "            # Merge assets: switch, transformers, fuses, cables, OHlines to Node worksheet\n",
    "            dfNodesMaster = pd.merge(dfNodes, dfSwitches, how='outer', left_on='Nodes_Node Id', \n",
    "                                     right_on ='Switches_From Node')\n",
    "            dfNodesMaster = pd.merge(dfNodesMaster, dfLoads, how='outer', left_on='Nodes_Node Id', \n",
    "                                     right_on='Loads_From Node')\n",
    "            dfNodesMaster = pd.merge(dfNodesMaster, dfFuses, how='outer', left_on='Nodes_Node Id', \n",
    "                                     right_on='Fuses_From Node')\n",
    "            #dfNodesMaster = pd.merge(dfNodesMaster, dfOHlines, how='outer', left_on='Nodes_Node Id', right_on='OHlines_From Node')\n",
    "            dfNodesMaster = pd.merge(dfNodesMaster, dfCables, how='outer', left_on='Nodes_Node Id', \n",
    "                                     right_on='Cables_From Node')\n",
    "            # print(dfNodesMaster.head(3))\n",
    "            #print(len(dfNodesMaster.columns))\n",
    "\n",
    "            dfNodesMaster = dfNodesMaster.rename(columns={'Loads_Total CkVA(kVA)':'Nameplate', \n",
    "                                                          'Loads_Spot Number':'TransformerID'})\n",
    "            dfNodesCopy = dfNodesMaster\n",
    "            #print(dfNodesCopy.dtypes)\n",
    "\n",
    "            #Change to str\n",
    "            dfNodesCopy['Cables_From Node']= dfNodesCopy['Cables_From Node'].astype(str)\n",
    "            dfNodesCopy['Cables_To Node']= dfNodesCopy['Cables_To Node'].astype(str)\n",
    "\n",
    "            # Split 'Nodes_Node Id' to 'NodeID_1' and 'NodeID_2' for 'SwitchRegion'\n",
    "            dfNodesCopy['NodeID_1'], dfNodesCopy['NodeID_2'] = zip(*dfNodesCopy['Nodes_Node Id'].\n",
    "                                                                   apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "\n",
    "            #******************************#\n",
    "            #***DIFFERET FROM V5 BEGINS****#\n",
    "            #******************************#\n",
    "            dfNodesCopy['Cables_FromNodeID_1'], dfNodesCopy['Cables_FromNodeID_2'] = zip(*dfNodesCopy['Cables_From Node'].\n",
    "                                                                   apply(lambda x: x.split('_') if '_' in x else (x,np.nan)))\n",
    "            dfNodesCopy['Cables_ToNodeID_1'], dfNodesCopy['Cables_ToNodeID_2'] = zip(*dfNodesCopy['Cables_To Node'].\n",
    "                                                                    apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "\n",
    "            \n",
    "            #Switch region col a.fill(numpy.nan), a[:] = numpy.nan\n",
    "            Num_rows = len(dfNodesCopy['Nodes_Network Id'])\n",
    "            dfNodesCopy['SwitchRegion'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "            dfNodesCopy['CablesSwitchRegionFrom'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "            dfNodesCopy['CablesSwitchRegionEnd'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "            # avoid chain indexing - http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
    "            dfNodesCopy.loc[:,'SwitchRegion'] = np.nan\n",
    "            dfNodesCopy.loc[:,'CablesSwitchRegionFrom'] = np.nan\n",
    "            dfNodesCopy.loc[:,'CablesSwitchRegionEnd'] = np.nan\n",
    "\n",
    "            # V6 changes\n",
    "            #df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])\n",
    "            #'Cables_FromNodeID_2' and 'Cables_ToNodeID_2'\n",
    "            dfNodesCopy['CablesSwitchRegionFrom'] = dfNodesCopy['Cables_FromNodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "            dfNodesCopy['CablesSwitchRegionEnd'] = dfNodesCopy['Cables_ToNodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "            dfNodesCopy['SwitchRegion'] = dfNodesCopy['NodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "\n",
    "            #FillNA\n",
    "            dfNodesCopy['SwitchRegion'] = dfNodesCopy['SwitchRegion'].fillna(method='ffill')\n",
    "            dfNodesCopy['CablesSwitchRegionFrom'] = dfNodesCopy['CablesSwitchRegionFrom'].fillna(method='ffill')\n",
    "            dfNodesCopy['CablesSwitchRegionEnd'] = dfNodesCopy['CablesSwitchRegionEnd'].fillna(method='ffill')\n",
    "\n",
    "\n",
    "            # Remove columns - temporary list for now\n",
    "            Nodes_drop_cols = ['Nodes_Phase','Nodes_Node Id', 'NodeID_1','NodeID_2'] #['Nodes_Network Id','Nodes_Node Id','Nodes_Phase'] \n",
    "            Switches_drop_cols = ['Switches_Network Id','Switches_Equipment Id','Switches_Device Type','Switches_Status',\n",
    "                                     'Switches_Phase','Switches_From Node','Switches_Voltage(kV)'] \n",
    "                                    #'Switches_Section Id','Switches_State','Switches_Rating(A)'\n",
    "            Tx_drop_cols = ['Loads_Network Id','Loads_Section Id','Loads_Status','Loads_From Node','Loads_Spot Type',\n",
    "                               'Loads_Dist Number','Loads_Dist Type','Loads_Total kVA(kVA)','Loads_Total kW(kW)','Loads_Total kvar',\n",
    "                               'Loads_Aver. PF(%)','Loads_Total kWh(kWh)','Loads_Total Cust','Loads_Phase Type','Loads_Config',\n",
    "                               'Loads_Locked','Loads_Load Model'] #'Loads_TransformerID','Loads_Phase','Loads_Nameplate',\n",
    "\n",
    "            Fuses_drop_cols =['Fuses_Network Id', 'Fuses_Status','Fuses_State','Fuses_Phase','Fuses_Manufacturer',\n",
    "                              'Fuses_Model', 'Fuses_Voltage(kV)', 'Fuses_Voltage Class', 'Fuses_Standard', 'Fuses_Rating(A)',\n",
    "                              'Fuses_Rating','Fuses_Interrupting Rating(A)', 'Fuses_From Node', 'Fuses_To Node'] \n",
    "                                #  'Fuses_Section Id', 'Fuses_Equipment Id', Fuses_Rating' \n",
    "\n",
    "            OHlines_drop_cols=[]\n",
    "\n",
    "            #V6 changes\n",
    "            Cables_drop_cols =['Cables_Network Id','Cables_Equipment Id','Cables_Line Id','Cables_Status','Cables_Phase',\n",
    "                                  'Cables_# parallel','Cables_Manufacturer','Cables_Standard',\n",
    "                                  'Cables_Rated Voltage(kV)','Cables_Ampacity(A)','Cables_Withstand(A)','Cables_Cable Type',\n",
    "                                  'Cables_Conductor Material','Cables_Sheathed','Cables_Concentric Neutrals','Cables_Line R1(ohms)',\n",
    "                                  'Cables_Line X1(ohms)','Cables_Line B1(µS)','Cables_Line R0(ohms)','Cables_Line X0(ohms)',\n",
    "                                  'Cables_Line B0(µS)','Cables_Harmonic Model', 'Cables_FromNodeID_1','Cables_ToNodeID_1',\n",
    "                                  'Cables_FromNodeID_2','Cables_ToNodeID_2','Cables_From Node', 'Cables_To Node',] \n",
    "                                #'Cables_From Node','Cables_To Node','Cables_Length(m)','Cables_Size','Cables_insulation'\n",
    "\n",
    "            # Poles_deleted_cols=[]\n",
    "\n",
    "            combined_drop_cols = (Nodes_drop_cols + Switches_drop_cols + Tx_drop_cols + Fuses_drop_cols + \n",
    "                                  OHlines_drop_cols + Cables_drop_cols)\n",
    "\n",
    "            #print('Number of columns deleted: ', len(combined_drop_cols))\n",
    "            #print('Number of rows: ', len(dfNodesCopy['Nodes_Network Id']))\n",
    "\n",
    "            #Drop columns\n",
    "            dfNodesCopy=dfNodesCopy.drop(combined_drop_cols, axis=1)\n",
    "\n",
    "            dfNodesPRID = dfNodesCopy\n",
    "\n",
    "            moreNodesCols = ['Switches_Section Id', 'Switches_State','Switches_Rating(A)', 'Fuses_Section Id', 'Fuses_Equipment Id', \n",
    "                 'Cables_Section Id','Cables_Length(m)', 'Cables_Size', 'Cables_Insulation','CablesSwitchRegionFrom', \n",
    "                 'CablesSwitchRegionEnd']\n",
    "            dfNodesPRID = drop_columns(dfNodesPRID, moreNodesCols)\n",
    "\n",
    "            dfNodesPRID = dfNodesPRID[(dfNodesPRID.TransformerID.notnull())]\n",
    "            dfNodesPRID_lookup = dfNodesPRID\n",
    "            #print(dfNodesPRID.shape)\n",
    "            #dfNodesPRID = dfNodesPRID.rename(columns={'Nodes_Network Id':'circuit'})\n",
    "            #print(dfNodesPRID.dtypes)\n",
    "            dfNodesPRID['Nameplate'] = dfNodesPRID['Nameplate'].astype(float)\n",
    "            #dfNodesPRID['Loads_Phase'] = dfNodesPRID['Loads_Phase'].astype(str)\n",
    "            #SwitchPRID = pd.Series(dfNodesPRID['SwitchRegion'].values.ravel()).unique()\n",
    "\n",
    "            #change this to reflect UG and OH Tx\n",
    "            # currently assumed all under 150kVA is Rx in 1-2Ph\n",
    "            dfFdr_Rx = dfNodesPRID[(dfNodesPRID['Loads_Phase'] != 'RWB') & (dfNodesPRID['Nameplate'] <=150)]\n",
    "            #dfFdr_UGtx_Rx = dfFdr_UGtx[(dfFdr_UGtx['phasing'] != 3) & (dfFdr_UGtx['kva'] <=100)]\n",
    "            dfFdr_Rx = dfFdr_Rx.rename(columns={'Nameplate': RES_LOAD})\n",
    "            # UGtx: 3Ph: 100-350kVA, 1Ph: <100kVA; group it by less than 350kVA # OHtx: 3Ph, \n",
    "            dfFdr_Med = dfNodesPRID[(dfNodesPRID['Loads_Phase'] == 'RWB') & (dfNodesPRID['Nameplate'] <=350)]\n",
    "            # dfFdr_UGtx_Med = dfFdr_UGtx[(dfFdr_UGtx['phasing'] == 3) & (dfFdr_UGtx['kva'] <=100) |\n",
    "            #                             (dfFdr_UGtx['phasing'] != 3) & ((dfFdr_UGtx['kva'] > 100) & (dfFdr_UGtx['kva'] <=350))]\n",
    "            dfFdr_Med = dfFdr_Med.rename(columns={'Nameplate': MED_COM_LOAD})\n",
    "            #UGTx: Greater than 350kVA\n",
    "            dfFdr_Large = dfNodesPRID[(dfNodesPRID['Nameplate'] > 350)]\n",
    "            dfFdr_Large = dfFdr_Large.rename(columns={'Nameplate': LARGE_LOAD})\n",
    "            dfFdrs_Loads = pd.concat([dfFdr_Rx, dfFdr_Med, dfFdr_Large])\n",
    "            dfFdrs_Loads = drop_columns(dfFdrs_Loads, ['Loads_Phase'])\n",
    "            dfFdrs_total = pd.DataFrame(dfFdrs_Loads.groupby('SwitchRegion').sum()).reset_index()\n",
    "\n",
    "            #50% nameplate rating\n",
    "            #**********************UNCOMMENT THIS**********#\n",
    "            # dfFdrs_total[RES_LOAD] = dfFdrs_total[RES_LOAD].apply(lambda x: x/2)\n",
    "            # dfFdrs_total[COM_LOAD] = dfFdrs_total[COM_LOAD].apply(lambda x: x/2)\n",
    "            # dfFdrs_total[IND_LOAD] = dfFdrs_total[IND_LOAD].apply(lambda x: x/2)\n",
    "\n",
    "            dfFdrs_total = dfFdrs_total.merge(dfNodesPRID_lookup, how='left', on='SwitchRegion')\n",
    "            dfFdrs_total['SwitchRegion'] = dfFdrs_total['SwitchRegion'].astype(str)\n",
    "            dfFdrs_total['Nodes_Network Id'] = dfFdrs_total['Nodes_Network Id'].astype(str)\n",
    "            \n",
    "            dfFdrs_total['PRID'] = dfFdrs_total['SwitchRegion'] + '_' + dfFdrs_total['Nodes_Network Id']\n",
    "            dfFdrs_total = drop_columns(dfFdrs_total, ['Nameplate', 'Loads_Phase', 'SwitchRegion', 'Nodes_Network Id'])\n",
    "            #print(dfFdrs_total.head())\n",
    "            #dfFdrs_temp = dfFdrs_total\n",
    "            if count == 1:\n",
    "                dfFdrs_Final = dfFdrs_total\n",
    "                dfFdrs_temp = dfFdrs_Final\n",
    "            else:\n",
    "                dfFdrs_Final = pd.concat([dfFdrs_temp, dfFdrs_total])\n",
    "                dfFdrs_temp = dfFdrs_Final\n",
    "\n",
    "            #'TransformerID', 'Loads_Phase', 'Nameplate', 'SwitchRegion'\n",
    "\n",
    "            \n",
    "            \n",
    "MasterFile = pd.ExcelWriter('V4_PRID_AllNodes.xlsx')\n",
    "dfFdrs_Final.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "print(dfFdrs_Final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
