{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cables:  Fuses:  Poles:  Switches:  Transformers:  UGStructures:\n",
      "0     3865     736   18961        537           3618          16883\n",
      "1       22      29      14         35             40             23\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output table/file names\n",
    "OH_SWITCHES_TABLE ='IN_OH_SW.xlsx'\n",
    "UG_SWITCHES_TABLE ='IN_UG_SW.xls'\n",
    "OH_TX_TABLE = 'IN_OH_TX.xlsx'\n",
    "UG_TX_TABLE = 'IN_UG_TX.xlsx'\n",
    "POLES_TABLE = 'IN_POLES.xlsx'\n",
    "UG_PRI_CABLE_TABLE = 'IN_CABLES.xlsx'\n",
    "NTWK_TX_TABLE = 'IN_NTWK_TX.xlsx'\n",
    "\n",
    "# asset_class_code(ACC) names\n",
    "OH_SWITCHES_ASSET_CLASS ='OH_SWITCH'\n",
    "OH_TX_ASSET_CLASS = 'OH_TX'\n",
    "UG_TX_ASSET_CLASS = 'UG_TX'\n",
    "POLES_ASSET_CLASS = 'POLE'\n",
    "UG_PRI_CABLE_ASSET_CLASS = 'UG_CABLE'\n",
    "NTWK_TX_ASSET_CLASS = 'NTWK_TX'\n",
    "\n",
    "ASSET_CLASS ='asset_class_code'\n",
    "ASSET_SUBCLASS ='asset_subclass_code'\n",
    "\n",
    "#Template folder\n",
    "ASSET_TEMPLATE_FOLDER='AssetDataTemplates'\n",
    "\n",
    "# #  First method to read col names: read from the entire folder\n",
    "# # define filepath and sort the file list\n",
    "# filesList = glob(os.path.join(ASSET_TEMPLATE_FOLDER, '*.xlsx'))\n",
    "# numFiles = len(filesList)\n",
    "# print('Number of Files: ', numFiles)\n",
    "# sortedFileList = sorted(filesList)\n",
    "\n",
    "# # read text files in tweet_input directory\n",
    "# for f in sortedFileList:\n",
    "#     fileName = os.path.basename(f).split('.')\n",
    "#     print(fileName[0])\n",
    "    \n",
    "#     if ('$' not in fileName):\n",
    "#         # Read CYME Feeder xlsx file into dataframes\n",
    "#         with pd.ExcelFile(f) as xlsx:\n",
    "#             dfTemp = pd.read_excel(xlsx, 'Sheet2') # 280 rows\n",
    "            \n",
    "#             # # Strip '\\n' from column headers\n",
    "#             dfTemp.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    \n",
    "#     #fileName[0]= dfTemp\n",
    "#     #print(fileName[0].columns)\n",
    "#     print(dfTemp.columns)\n",
    "\n",
    "#******************************************************\n",
    "# Declare column names\n",
    "#******************************************************\n",
    "UG_SWITCHES_COLS =['asset_id','id','asset_subclass_code','asset_class_code','install_year','hi',\n",
    "                   'phasing','prid','circuit','tx_phase','in_valley','tie_feeder']\n",
    "\n",
    "OH_TX_COLS = ['asset_id','asset_class_code','id','circuit','install_year','asset_subclass_code','hi',\n",
    "              'phasing','primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "              'device_commercial','device_industrial','upstream_device','prid','in_valley','pcb','banking']\n",
    "\n",
    "UG_TX_COLS = ['asset_id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "              'primary_voltage','kva','in_valley','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "              'device_commercial','device_industrial','upstream_device','pcb','pedestal','switchable','switch_type','id']\n",
    "\n",
    "UG_PRI_CABLE_COLS = ['asset_id','id','install_year','hi','asset_subclass_code','asset_class_code','phasing','prid',\n",
    "                     'circuit','arrangement','installation','material','cable_size','config','length','num_splices',\n",
    "                     'num_cables','prid_residential','prid_commercial','prid_industrial','nominal_voltage',\n",
    "                     'wc_prid_catastrophic_res','wc_prid_catastrophic_comm','wc_prid_catastrophic_ind','cable_phase',\n",
    "                     'wc_replacement','wc_switching_res','wc_switching_comm','wc_switching_ind','wc_switching_duration']\n",
    "\n",
    "POLES_COLS = ['asset_id','asset_class_code','asset_subclass_code','install_year','hi character','phasing character',\n",
    "              'prid character','pole_class','tx','tx_type','circuit1','circuit2','circuit3','circuit4','in_valley',\n",
    "              'tx_residential','tx_commercial','tx_industrial','height','num_circuits','device','tx_kva','id','prid2',\n",
    "              'prid3','prid4','tx_pcb']\n",
    "\n",
    "NTWK_TX_COLS = ['asset_id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "                'primary_voltage','kva character','load double','id character','network_type','tx1','tx2','tx3','tx4']\n",
    "\n",
    "#******************************************************\n",
    "# fileName - iterate through entire folder :)\n",
    "fileName = 'Original_FiveAssetClasses.xlsx'\n",
    "file_PolesLatLong = 'V2_LatLongPoles.xls'\n",
    "file_SwitchesLatLong = 'V2_LatLongSwitches.xls'\n",
    "file_PriOHLatLong = 'V2_LatLongPriOH.xls'\n",
    "file_PriUGLatLong = 'V2_LatLongPriUG.xls'\n",
    "file_TxLatLong = 'V2_LatLongTx.xls'\n",
    "#fileNameOtherDevices = 'Other Device Numbers.xls'\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(fileName) as xlsx:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfTransformersV1 = pd.read_excel(xlsx, 'Transformers') # 280 rows\n",
    "    dfSwitchesV1 = pd.read_excel(xlsx, 'Switches') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "    dfPolesV1 = pd.read_excel(xlsx, 'Poles') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "    dfCablesV1 = pd.read_excel(xlsx, 'UGPrimaryCables')\n",
    "    dfFusesV1 = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "    dfUGStructuresV1 = pd.read_excel(xlsx,'UGStructures')\n",
    "\n",
    "# Read xlsx file into dataframes\n",
    "with pd.ExcelFile(file_PolesLatLong) as xls:\n",
    "    dfPolesLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "    \n",
    "with pd.ExcelFile(file_SwitchesLatLong) as xls:\n",
    "    dfSwitchesLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "with pd.ExcelFile(file_PriOHLatLong) as xls:\n",
    "    dfOHCondLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "with pd.ExcelFile(file_PriUGLatLong) as xls:\n",
    "    dfCablesLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "    \n",
    "with pd.ExcelFile(file_TxLatLong) as xls:\n",
    "    dfTxLatLongV1 = pd.read_excel(xls, 'Sheet1')\n",
    "    \n",
    "Summary = {'Transformers:': dfTransformersV1.shape, 'Switches:': dfSwitchesV1.shape,'Poles:': dfPolesV1.shape, \n",
    "           'Cables:': dfCablesV1.shape, 'Fuses:':dfFusesV1.shape, 'UGStructures:':dfUGStructuresV1.shape}\n",
    "dfSummary = pd.DataFrame(Summary)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformersV2 = dfTransformersV1\n",
    "dfSwitchesV2 = dfSwitchesV1\n",
    "dfPolesV2 = dfPolesV1\n",
    "dfCablesV2 = dfCablesV1\n",
    "dfFusesV2 = dfFusesV1\n",
    "dfUGStructuresV2 = dfUGStructuresV1\n",
    "\n",
    "# 17 columns dropped\n",
    "dropCommonColumns = ['OBJECTID','WORKORDERID','FIELDVERIFY','COMMENTS','CREATIONUSER','DATECREATED','LASTUSER',\n",
    "                     'DATEMODIFIED','WORKREQUESTID','DESIGNID','WORKLOCATIONID','WMSID','WORKFLOWSTATUS',\n",
    "                     'WORKFUNCTION','GISONUMBER','GISOTYPENBR','OWNERSHIP']\n",
    "\n",
    "#******************************************************\n",
    "# FUNCTIONS\n",
    "#******************************************************\n",
    "def drop_columns(dfAssetClass, dropColumns):\n",
    "    dfAssetClass = dfAssetClass.drop(dropColumns, axis=1)\n",
    "    return dfAssetClass\n",
    "\n",
    "def new_columns(dfAssetClass, numAssetRows, columnID):\n",
    "    dfAssetClass[columnID] = pd.DataFrame(np.empty([numAssetRows,1]).cumsum(axis=1))\n",
    "    dfAssetClass.loc[:,columnID] = np.nan\n",
    "    return dfAssetClass[columnID]\n",
    "\n",
    "#******************************************************\n",
    "#Drop all common columns \n",
    "#******************************************************\n",
    "dfSwitchesV2 = drop_columns(dfSwitchesV2, dropCommonColumns)\n",
    "dfTransformersV2 = drop_columns(dfTransformersV2, dropCommonColumns)\n",
    "dfFusesV2 = drop_columns(dfFusesV2,dropCommonColumns)\n",
    "dfCablesV2 = drop_columns(dfCablesV2, dropCommonColumns)\n",
    "dfUGStructuresV2 = drop_columns(dfUGStructuresV2, dropCommonColumns)\n",
    "dfPolesV2 = drop_columns(dfPolesV2, dropCommonColumns)\n",
    "\n",
    "# Make one copy\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "SummaryV2 = {'Transformers:': dfTransformers.shape, 'Switches:': dfSwitches.shape,'Poles:': dfPoles.shape, \n",
    "           'Cables:': dfCables.shape, 'Fuses:':dfFuses.shape, 'UGStructures:':dfUGStructures.shape}\n",
    "dfSummaryV2 = pd.DataFrame(SummaryV2)\n",
    "#print(dfSummary)\n",
    "print(dfSummaryV2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OH and UG Tx analyses completed\n"
     ]
    }
   ],
   "source": [
    "# Save future wait times while running\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "\n",
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfOHCondLatLong = dfOHCondLatLongV1\n",
    "dfCablesLatLong = dfCablesLatLongV1\n",
    "\n",
    "#******************************************************\n",
    "# ASSET CLASS SPECIFIC DICTIONARIES\n",
    "#******************************************************\n",
    "# OPERATING VOLTAGE 190=8kv, 250=13.8kv, 1267 = 0kv, 1237 = 138kv\n",
    "# Assets: Transformers,\n",
    "operatingVoltageDict = {'190':'8000','250':'13800','1267':'0','1237':'138000'}\n",
    "\n",
    "# Phasing change - need to change it to 'str' type, int/float dict key lookup doesn't work\n",
    "# Assets: UG Switches, Transformers\n",
    "#phasingDict = {'1.0': '1Ph', '2.0':'1Ph','4.0':'1Ph','3.0':'2Ph','5.0':'2Ph','6.0':'2Ph','7.0':'3Ph'}\n",
    "phasingDict = {'1': '1Ph', '2':'1Ph','4':'1Ph','3':'2Ph','5':'2Ph','6':'2Ph','7':'3Ph'}\n",
    "\n",
    "# UG Switches\n",
    "dictSGassetSubclass = {'PMH-3':'AIR_INSULATED_LIVEFRONT','PMH-5':'AIR_INSULATED_LIVEFRONT',\n",
    "                       'PMH-9':'AIR_INSULATED_LIVEFRONT','PMH-11':'AIR_INSULATED_LIVEFRONT',\n",
    "                       'PME-9':'AIR_INSULATED_DEADFRONT','PME-10':'AIR_INSULATED_DEADFRONT',\n",
    "                       'PME-11':'AIR_INSULATED_DEADFRONT','VISTA-321':'SF6_INSULATED_SWITCH',\n",
    "                       'VISTA-422':'SF6_INSULATED_SWITCH','VISTA-431':'SF6_INSULATED_SWITCH',\n",
    "                       '422':'SC_ELEC','431':'SC_ELEC','321':'SC_ELEC','G&W':'GW',\n",
    "                       'NET':'CARTE_ELEC_LTD'}\n",
    "\n",
    "# Transformers\n",
    "# dictOHTxSubclass = {'1':'Standard 1Ph','9':'Standard 3Ph','10':'Standard 2Ph'}\n",
    "# dictUGTxSubclass = {'2':'Padmount 1Ph','3':'Network Submersible','5':'Submersible', '7':'Padmount 3Ph'}\n",
    "dictOHTxSubclass = {'1':'Standard','9':'Standard','10':'Standard'}\n",
    "dictUGTxSubclass = {'2':'Padmount','3':'Network Submersible','5':'Submersible', '7':'Padmount'}\n",
    "\n",
    "#****************************************************************************\n",
    "# UG Switches - Reading SwitchGears\n",
    "#****************************************************************************\n",
    "#**************************\n",
    "# Reading SwitchGears\n",
    "#***************************\n",
    "fileNameOtherDevices = 'Other Device Numbers.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameOtherDevices) as xls:\n",
    "    dfSwitchGears = pd.read_excel(xls, 'SWITCHGEARS') # 280 rows\n",
    "\n",
    "dropSGcols = ['Switch Gear', 'Adrs #','Location','City','Notes','To Type','Inst. Date','Mftr.','Catalog#','Serial#',\n",
    "             'DOM','Comments']\n",
    "\n",
    "dfSwitchGears = drop_columns(dfSwitchGears, dropSGcols)\n",
    "#dfSwitchGears = dfSwitchGears.dropna() # drop all rows with NaN values\n",
    "\n",
    "# 'Type' -> 'PMH'\n",
    "# 'Loc_No' -> '149-S'\n",
    "dfSwitchGears['Type'] = dfSwitchGears['Type'].fillna(method='ffill')\n",
    "numSGrows = len(dfSwitchGears['Loc_No'])\n",
    "dfSwitchGears['ASSET_SUBCLASS'] = new_columns(dfSwitchGears, numSGrows, 'ASSET_SUBCLASS')\n",
    "dfSwitchGears =dfSwitchGears.astype(str)\n",
    "#dfSwitchGears['Loc_No'] = dfSwitchGears.iloc[:,'Loc_No'].apply[s.lstrip(\"0\") for s in listOfNum]\n",
    "dfSwitchGears['Loc_No'] = [s.lstrip(\"0\") for s in dfSwitchGears['Loc_No']]\n",
    "dfSwitchGears['ASSET_SUBCLASS'] = dfSwitchGears['Type'].apply(lambda x: dictSGassetSubclass[x])\n",
    "\n",
    "#*******************\n",
    "# Drop columns\n",
    "#*******************\n",
    "dropSwitchesCols = ['ANCILLARYROLE','ENABLED','FEEDERINFO','ELECTRICTRACEWEIGHT','LOCATIONID','GPSDATE','LABELTEXT',\n",
    "                    'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXOPERATINGVOLTAGE','MAXCONTINUOUSCURRENT','PRESENTPOSITION_R', \n",
    "                    'PRESENTPOSITION_Y', 'PRESENTPOSITION_B','NORMALPOSITION_R','NORMALPOSITION_Y','NORMALPOSITION_B', \n",
    "                    'SCADACONTROLID', 'SCADAMONITORID','PREFERREDCIRCUITSOURCE','TIESWITCHINDICATOR',\n",
    "                    'GANGOPERATED', 'MANUALLYOPERATED','FEATURE_STATUS','HYPERLINK','HYPERLINK_PGDB','SYMBOLROTATION',\n",
    "                    'INSULATOR_MATERIAL']\n",
    "\n",
    "#******************************************************\n",
    "# drop asset columns\n",
    "#******************************************************\n",
    "dfSwitches = drop_columns(dfSwitches,dropSwitchesCols)\n",
    "#******************************************************\n",
    "# FILTER OUT ASSET CLASSES WITH THEIR RESPECTIVE SUBTYPES\n",
    "#******************************************************\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "# UG Switches rows\n",
    "dfSwitches = dfSwitches[dfSwitches.SUBTYPECD == 6]\n",
    "numSwitchRows = len(dfSwitches['DEVICENUMBER'])\n",
    "\n",
    "#*******************\n",
    "# ADD ADDITIONAL COLUMNS AND FILL WITH NaNs\n",
    "#*******************\n",
    "# UG Switches\n",
    "dfSwitches['HI'] = new_columns(dfSwitches,numSwitchRows, 'HI')\n",
    "dfSwitches['TX_PHASE'] = new_columns(dfSwitches,numSwitchRows, 'TX_PHASE')\n",
    "dfSwitches['IN_VALLEY'] = new_columns(dfSwitches,numSwitchRows, 'IN_VALLEY')\n",
    "dfSwitches['PRID'] = new_columns(dfSwitches,numSwitchRows, 'PRID')\n",
    "#**************************\n",
    "# RENAME ASSET COLUMNS\n",
    "#**************************\n",
    "# Rename Switch columns\n",
    "dfSwitches = dfSwitches.rename(columns={'SUBTYPECD':ASSET_CLASS,\n",
    "                                        'DEVICENUMBER':'ID',\n",
    "                                        'COMPATIBLEUNITID':ASSET_SUBCLASS,\n",
    "                                        'PHASEDESIGNATION':'PHASING',\n",
    "                                        'FEEDERID':'CIRCUIT', \n",
    "                                        'FEEDERID2':'TIE_FEEDER',\n",
    "                                        'INSTALLATIONDATE':'INSTALL_YEAR'})\n",
    "# Separate year\n",
    "dfSwitches['INSTALL_YEAR'] = dfSwitches['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "# Replace 'Asset Subclass' col with actual names\n",
    "dfSwitches['ID'] = dfSwitches['ID'].astype(str)\n",
    "dfSwitches=pd.merge(dfSwitches, dfSwitchGears, how='left', left_on='ID', right_on='Loc_No')\n",
    "#dfSwitches['ID'] = dfSwitchGears['Loc_No'].apply(lambda x: )\n",
    "#df.merge(df1, on='sku', how='left')\n",
    "# print(len(pd.unique(dfSwitchGears['Loc_No'].values.ravel()))) # 111\n",
    "\n",
    "#******************************************************\n",
    "switchesDropMoreCols = [ASSET_SUBCLASS, 'Loc_No']\n",
    "dfSwitches = dfSwitches.drop(switchesDropMoreCols, axis=1)\n",
    "dfSwitches = dfSwitches.rename(columns={'ASSET_SUBCLASS': ASSET_SUBCLASS})\n",
    "\n",
    "#******************************************************\n",
    "# Rename proper asset nomenclature\n",
    "dfSwitches[ASSET_CLASS] = OH_SWITCHES_ASSET_CLASS\n",
    "\n",
    "#******************************************************\n",
    "# Rename proper asset nomenclature\n",
    "dfSwitches[ASSET_CLASS] = OH_SWITCHES_ASSET_CLASS\n",
    "\n",
    "#******************************************************\n",
    "#phasingDict = {'1.0': '1Ph', '2.0':'1Ph','4.0':'1Ph','3.0':'2Ph','5.0':'2Ph','6.0':'2Ph','7.0':'3Ph'}\n",
    "# UG Switches - 'phasing' col\n",
    "dfSwitches['PHASING'] = dfSwitches['PHASING'].astype(int)\n",
    "dfSwitches['PHASING'] = dfSwitches['PHASING'].astype(str)\n",
    "dfSwitches['PHASING'] = dfSwitches['PHASING'].apply(lambda x: phasingDict[x])\n",
    "\n",
    "#******************************************************\n",
    "# Lower case column names\n",
    "dfSwitches.columns = map(str.lower, dfSwitches.columns)\n",
    "\n",
    "#******************************************************\n",
    "# REARRANGE COLUMNS\n",
    "#******************************************************\n",
    "# *All tables need 'asset_id' - rename index\n",
    "# UG Switches\n",
    "# UG_SWITCHES_COLS =['asset_id','id','asset_subclass_code','asset_class_code','install_year','hi',\n",
    "#                    'phasing','prid','circuit','tx_phase','in_valley','tie_feeder']\n",
    "dfSwitches =dfSwitches[['id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit','tx_phase','in_valley','tie_feeder','type']]\n",
    "\n",
    "#*********************\n",
    "# OUTPUT DATAFRAMES TO EXCEL FILES\n",
    "#*********************\n",
    "# Output table/file names\n",
    "# OH_SWITCHES_TABLE ='IN_OH_SW.xlsx'\n",
    "# UG_SWITCHES_TABLE ='IN_UG_SW.xls'\n",
    "# UG SWITCH\n",
    "MasterFile = pd.ExcelWriter(UG_SWITCHES_TABLE)\n",
    "dfSwitches.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "#********************\n",
    "# Drop columns\n",
    "#*******************\n",
    "\n",
    "dropTxCols = ['ANCILLARYROLE', 'ENABLED', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'SYMBOLROTATION', \n",
    "              'GPSDATE', 'LABELTEXT', 'NOMINALVOLTAGE', 'GROUNDREACTANCE', 'GROUNDRESISTANCE', \n",
    "              'MAGNETIZINGREACTANCE', 'MAGNETIZINGRESISTANCE', 'HIGHSIDEGROUNDREACTANCE','HIGHSIDEGROUNDRESISTANCE', \n",
    "              'HIGHSIDEPROTECTION', 'LOCATIONTYPE','COOLINGTYPE', 'FEATURE_STATUS','KVA', 'DEMAND_KVA',\n",
    "              'DEMAND_DATE_MM_DD_YYYY', 'STREET_LIGHT_FACILITY', 'HIGHSIDECONFIGURATION', 'LOWSIDECONFIGURATION',\n",
    "              'LOWSIDEGROUNDRESISTANCE', 'LOWSIDEVOLTAGE', 'LATITUDE', 'LONGITUDE']\n",
    "\n",
    "#******************************************************\n",
    "# drop asset columns\n",
    "#******************************************************\n",
    "dfTransformers = drop_columns(dfTransformers,dropTxCols)\n",
    "\n",
    "#******************************************************\n",
    "# FILTER OUT ASSET CLASSES WITH THEIR RESPECTIVE SUBTYPES\n",
    "#******************************************************\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "# number of rows/observations \n",
    "numTxRows = len(dfTransformers['DEVICENUMBER'])\n",
    "\n",
    "#******************************************************\n",
    "# RENAME ASSET COLUMNS\n",
    "#******************************************************\n",
    "\n",
    "# Rename Transformer columns\n",
    "dfTransformers = dfTransformers.rename(columns={'DEVICENUMBER':'ID',\n",
    "                                                'PHASEDESIGNATION':'Type',\n",
    "                                                'INSTALLATIONDATE':'INSTALL_YEAR',\n",
    "                                                'FEEDERID':'CIRCUIT',\n",
    "                                                'RATEDKVA':'KVA'})\n",
    "\n",
    "# Separate year\n",
    "dfTransformers['INSTALL_YEAR'] = dfTransformers['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "#******************************************************\n",
    "# ADD ADDITIONAL COLUMNS AND FILL WITH NaNs\n",
    "#******************************************************\n",
    "# UG Switches\n",
    "# Transformers\n",
    "dfTransformers[ASSET_CLASS] = new_columns(dfTransformers, numTxRows, ASSET_CLASS)\n",
    "dfTransformers['HI'] = new_columns(dfTransformers, numTxRows,'HI')\n",
    "dfTransformers['PRID'] = new_columns(dfTransformers, numTxRows,'PRID')\n",
    "dfTransformers['IN_VALLEY'] = new_columns(dfTransformers, numTxRows,'IN_VALLEY')\n",
    "dfTransformers['TX_RESIDENTIAL'] = new_columns(dfTransformers, numTxRows,'TX_RESIDENTIAL')\n",
    "dfTransformers['TX_COMMERCIAL'] = new_columns(dfTransformers, numTxRows,'TX_COMMERCIAL')\n",
    "dfTransformers['TX_INDUSTRIAL'] = new_columns(dfTransformers, numTxRows,'TX_INDUSTRIAL')\n",
    "dfTransformers['DEVICE_RESIDENTIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_RESIDENTIAL')\n",
    "dfTransformers['DEVICE_COMMERCIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_COMMERCIAL')\n",
    "dfTransformers['DEVICE_INDUSTRIAL'] = new_columns(dfTransformers, numTxRows,'DEVICE_INDUSTRIAL')\n",
    "dfTransformers['UPSTREAM_DEVICE'] = new_columns(dfTransformers, numTxRows,'UPSTREAM_DEVICE')\n",
    "dfTransformers['PCB'] = new_columns(dfTransformers, numTxRows,'PCB')\n",
    "\n",
    "#******************************************************\n",
    "# FILTER OUT ASSET CLASSES WITH THEIR RESPECTIVE SUBTYPES\n",
    "#******************************************************\n",
    "# To avoid index vs copy error: pd.DataFrame...necessary (spent 4 hours getting rid of the warning error!)\n",
    "# UG Tx: 2/3/5/7 - 1Ph/Ntwk/Sub/Pad 3Ph [1436,27,4,507: 1642 counts]\n",
    "dfUGTransformers = pd.DataFrame(dfTransformers[(dfTransformers.SUBTYPECD == 2) | \n",
    "                                  (dfTransformers.SUBTYPECD == 3) | \n",
    "                                  (dfTransformers.SUBTYPECD == 5) | \n",
    "                                  (dfTransformers.SUBTYPECD == 7) ])\n",
    "\n",
    "# OH Tx: 1/9/10 - 1Ph/3Ph/2Ph [1125/510/7: 1347 counts]\n",
    "dfOHTransformers = pd.DataFrame(dfTransformers[(dfTransformers.SUBTYPECD == 1) | \n",
    "                                  (dfTransformers.SUBTYPECD == 9) | \n",
    "                                  (dfTransformers.SUBTYPECD == 10)])\n",
    "\n",
    "#******************************************************\n",
    "# Replace Asset class and 'SUBTYPECD' with actual tx types\n",
    "#******************************************************\n",
    "numOHTxRows = len(dfOHTransformers['ID'])\n",
    "numUGTxRows = len(dfUGTransformers['ID'])\n",
    "\n",
    "#******************************************************\n",
    "# TRANSFORMERS\n",
    "#******************************************************\n",
    "dfOHTransformers['SUBTYPECD'] = dfOHTransformers['SUBTYPECD'].astype(str)\n",
    "dfUGTransformers['SUBTYPECD'] = dfUGTransformers['SUBTYPECD'].astype(str)\n",
    "\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "dfOHTransformers.loc[:,'SUBTYPECD'] = dfOHTransformers['SUBTYPECD'].apply(lambda x: dictOHTxSubclass[x])\n",
    "dfUGTransformers.loc[:,'SUBTYPECD'] = dfUGTransformers['SUBTYPECD'].apply(lambda x: dictUGTxSubclass[x])\n",
    "\n",
    "# Fill in Asset and asset subclass columns\n",
    "dfOHTransformers = dfOHTransformers.rename(columns={'SUBTYPECD':ASSET_SUBCLASS})\n",
    "dfUGTransformers = dfUGTransformers.rename(columns={'SUBTYPECD':ASSET_SUBCLASS})\n",
    "\n",
    "# Remaining OH Tx and UG Tx specific columns\n",
    "dfOHTransformers['BANKING'] = new_columns(dfOHTransformers, numOHTxRows,'BANKING')\n",
    "dfUGTransformers['PEDESTAL'] = new_columns(dfUGTransformers, numUGTxRows,'PEDESTAL')\n",
    "dfUGTransformers['SWITCHABLE'] = new_columns(dfUGTransformers, numUGTxRows,'SWITCHABLE')\n",
    "dfUGTransformers['SWITCH_TYPE'] = new_columns(dfUGTransformers, numUGTxRows,'SWITCH_TYPE')\n",
    "#print(numOHTxRows, numUGTxRows)\n",
    "#print(dfOHTransformers.columns)\n",
    "\n",
    "# Tx Domain code tables\n",
    "fileNameDomainCodes_Tx = 'DomainCodes_Tx.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameDomainCodes_Tx) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfUGTxDomainCodes = pd.read_excel(xls, 'UGTransformers')\n",
    "    dfOHTxDomainCodes = pd.read_excel(xls, 'OHTransformers')\n",
    "\n",
    "# Convert to string for merge purposes\n",
    "dfOHTransformers['COMPATIBLEUNITID'] = dfOHTransformers['COMPATIBLEUNITID'].astype(str)\n",
    "dfUGTransformers['COMPATIBLEUNITID'] = dfUGTransformers['COMPATIBLEUNITID'].astype(str)\n",
    "dfOHTxDomainCodes['COMPATIBLEUNITID'] = dfOHTxDomainCodes['COMPATIBLEUNITID'].astype(str)\n",
    "dfUGTxDomainCodes['COMPATIBLEUNITID'] = dfUGTxDomainCodes['COMPATIBLEUNITID'].astype(str)\n",
    "#print(dfUGTxDomainCodes.head())\n",
    "\n",
    "#dfOHTransformers=pd.merge(dfOHTransformers, dfOHTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#dfUGTransformers=pd.merge(dfUGTransformers, dfUGTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "dfOHTransformers=dfOHTransformers.merge(dfOHTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "dfUGTransformers=dfUGTransformers.merge(dfUGTxDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#print(dfUGTransformers.head(2))\n",
    "\n",
    "dropOHTxCols = ['COMPATIBLEUNITID','Description','PRIMARY_VOLTAGE','NAMEPLATE','PHASING','Fused','UNITS','FAULTINDICATOR','Tx_type_counts']\n",
    "dropUGTxCols = ['COMPATIBLEUNITID','Description','PRIMARY_VOLTAGE','NAMEPLATE','PHASING','Fused','UNITS','FAULTINDICATOR','Tx_type_counts']\n",
    "\n",
    "# drop columns\n",
    "dfOHTransformers = drop_columns(dfOHTransformers,dropOHTxCols)\n",
    "dfUGTransformers = drop_columns(dfUGTransformers,dropUGTxCols)\n",
    "\n",
    "#******************************************************\n",
    "# 3\n",
    "#******************************************************\n",
    "# Replace 'Asset Subclass' col with actual names\n",
    "# Rename proper asset nomenclature\n",
    "#dfSwitches[ASSET_CLASS] = OH_SWITCHES_ASSET_CLASS\n",
    "dfOHTransformers[ASSET_CLASS] = OH_TX_ASSET_CLASS\n",
    "dfUGTransformers[ASSET_CLASS] = UG_TX_ASSET_CLASS\n",
    "\n",
    "#******************************************************\n",
    "#phasingDict = {'1.0': '1Ph', '2.0':'1Ph','4.0':'1Ph','3.0':'2Ph','5.0':'2Ph','6.0':'2Ph','7.0':'3Ph'}\n",
    "# UG Switches - 'phasing' col\n",
    "# dfSwitches['PHASING'] = dfSwitches['PHASING'].astype(int)\n",
    "# dfSwitches['PHASING'] = dfSwitches['PHASING'].astype(str)\n",
    "# dfSwitches['PHASING'] = dfSwitches['PHASING'].apply(lambda x: phasingDict[x])\n",
    "\n",
    "# OH and UG Tx - 'operational voltage'\n",
    "#operatingVoltageDict = {'190':'8000','250':'13800','1267':'0','1237':'138000'}\n",
    "dfOHTransformers['OPERATINGVOLTAGE'] = dfOHTransformers['OPERATINGVOLTAGE'].astype(str)\n",
    "dfUGTransformers['OPERATINGVOLTAGE'] = dfUGTransformers['OPERATINGVOLTAGE'].astype(str)\n",
    "dfOHTransformers['OPERATINGVOLTAGE'] = dfOHTransformers['OPERATINGVOLTAGE'].apply(lambda x: operatingVoltageDict[x])\n",
    "dfUGTransformers['OPERATINGVOLTAGE'] = dfUGTransformers['OPERATINGVOLTAGE'].apply(lambda x: operatingVoltageDict[x])\n",
    "\n",
    "dfOHTransformers['Type'] = dfOHTransformers['Type'].astype(str)\n",
    "dfUGTransformers['Type'] = dfUGTransformers['Type'].astype(str)\n",
    "dfOHTransformers['Type'] = dfOHTransformers['Type'].apply(lambda x: phasingDict[x])\n",
    "dfUGTransformers['Type'] = dfUGTransformers['Type'].apply(lambda x: phasingDict[x])\n",
    "\n",
    "#******************************************************\n",
    "# Rename col names\n",
    "dfOHTransformers = dfOHTransformers.rename(columns={'OPERATINGVOLTAGE': 'primary_voltage',\n",
    "                                                    'Type': 'phasing'})\n",
    "dfUGTransformers = dfUGTransformers.rename(columns={'OPERATINGVOLTAGE': 'primary_voltage',\n",
    "                                                    'Type': 'phasing'})\n",
    "#******************************************************\n",
    "# Lower case column names\n",
    "# dfSwitches.columns = map(str.lower, dfSwitches.columns)\n",
    "dfOHTransformers.columns = map(str.lower, dfOHTransformers.columns)\n",
    "dfUGTransformers.columns = map(str.lower, dfUGTransformers.columns)\n",
    "\n",
    "#******************************************************\n",
    "# REARRANGE COLUMNS\n",
    "#******************************************************\n",
    "# *All tables need 'asset_id' - rename index\n",
    "# OH_TX_COLS = ['asset_id','asset_class_code','id','circuit','install_year','asset_subclass_code','hi',\n",
    "#               'phasing','primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "#               'device_commercial','device_industrial','upstream_device','prid','in_valley','pcb','banking']\n",
    "dfOHTransformers = dfOHTransformers[['asset_class_code','id','circuit','install_year','asset_subclass_code','hi','phasing','primary_voltage','kva','tx_residential','tx_commercial','tx_industrial','device_residential','device_commercial','device_industrial','upstream_device','prid','in_valley','pcb','banking','sec_voltage']]\n",
    "#'faultindicator','type','units','tx_type_counts','sec_voltage','fused'\n",
    "\n",
    "# UG_TX_COLS = ['asset_id','asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit',\n",
    "#               'primary_voltage','kva','in_valley','tx_residential','tx_commercial','tx_industrial','device_residential',\n",
    "#               'device_commercial','device_industrial','upstream_device','pcb','pedestal','switchable','switch_type','id']\n",
    "dfUGTransformers = dfUGTransformers[['asset_subclass_code','asset_class_code','install_year','hi','phasing','prid','circuit','primary_voltage','kva','in_valley','tx_residential','tx_commercial','tx_industrial','device_residential','device_commercial','device_industrial','upstream_device','pcb','pedestal','switchable','switch_type','id','sec_voltage']]\n",
    "# print(dfOHTransformers.columns)\n",
    "# print(dfUGTransformers.columns)\n",
    "\n",
    "#******************************************************\n",
    "# OUTPUT DATAFRAMES TO EXCEL FILES\n",
    "#******************************************************\n",
    "# Output table/file names\n",
    "# OH_SWITCHES_TABLE ='IN_OH_SW.xlsx'\n",
    "# UG_SWITCHES_TABLE ='IN_UG_SW.xls'\n",
    "# OH_TX_TABLE = 'IN_OH_TX.xlsx'\n",
    "# UG_TX_TABLE = 'IN_UG_TX.xlsx'\n",
    "# POLES_TABLE = 'IN_POLES.xlsx'\n",
    "# UG_PRI_CABLE_TABLE = 'IN_CABLES.xlsx'\n",
    "# NTWK_TX_TABLE = 'IN_NTWK_TX.xlsx'\n",
    "\n",
    "# UG SWITCH\n",
    "# MasterFile = pd.ExcelWriter(UG_SWITCHES_TABLE)\n",
    "# dfSwitches.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "# OH TX\n",
    "MasterFile = pd.ExcelWriter(OH_TX_TABLE)\n",
    "dfOHTransformers.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "# UG TX\n",
    "MasterFile = pd.ExcelWriter(UG_TX_TABLE)\n",
    "dfUGTransformers.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('OH and UG Tx analyses completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poles analysis completed\n"
     ]
    }
   ],
   "source": [
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# Save future wait times while running\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# keep only distribution poles\n",
    "dfPoles = dfPoles[dfPoles.SUBTYPECD == 1] #1 - Dist(47%), 5-TrafficLights(2%), 7-streetlight(51%)\n",
    "\n",
    "dropPolesCols = ['SYMBOLROTATION','GPSDATE','SUBTYPECD','LABELTEXT','STRUCTURENUMBER','FEATURE_STATUS',\n",
    "                 'STREETLIGHT_FACILITY','REPLACED_DATE_MM_DD_YYYY','CONDITION','CONDITION_STATUS','CONDITION_DATE']\n",
    "dfPoles = drop_columns(dfPoles,dropPolesCols)\n",
    "\n",
    "# Add additional columns and fill with NaNs\n",
    "#dfPoles[''] = new_columns(dfPoles, numPolesRows,'')\n",
    "numPolesRows = len(dfPoles['DEVICENUMBER'])\n",
    "dfPoles[ASSET_CLASS] = new_columns(dfPoles, numPolesRows,ASSET_CLASS)\n",
    "dfPoles[ASSET_SUBCLASS] = new_columns(dfPoles, numPolesRows,ASSET_SUBCLASS)\n",
    "dfPoles['HI'] = new_columns(dfPoles, numPolesRows,'HI')\n",
    "dfPoles['PHASING'] = new_columns(dfPoles, numPolesRows,'PHASING')\n",
    "dfPoles['PRID'] = new_columns(dfPoles, numPolesRows,'PRID')\n",
    "dfPoles['TX'] = new_columns(dfPoles, numPolesRows,'TX')\n",
    "dfPoles['TX_TYPE'] = new_columns(dfPoles, numPolesRows,'TX_TYPE')\n",
    "dfPoles['CIRCUIT1'] = new_columns(dfPoles, numPolesRows,'CIRCUIT1')\n",
    "dfPoles['CIRCUIT2'] = new_columns(dfPoles, numPolesRows,'CIRCUIT2')\n",
    "dfPoles['CIRCUIT3'] = new_columns(dfPoles, numPolesRows,'CIRCUIT3')\n",
    "dfPoles['CIRCUIT4'] = new_columns(dfPoles, numPolesRows,'CIRCUIT4')\n",
    "dfPoles['CIRCUIT5'] = new_columns(dfPoles, numPolesRows,'CIRCUIT5')\n",
    "dfPoles['CIRCUIT6'] = new_columns(dfPoles, numPolesRows,'CIRCUIT6')\n",
    "dfPoles['CIRCUIT7'] = new_columns(dfPoles, numPolesRows,'CIRCUIT7')\n",
    "dfPoles['CIRCUIT8'] = new_columns(dfPoles, numPolesRows,'CIRCUIT8')\n",
    "dfPoles['IN_VALLEY'] = new_columns(dfPoles, numPolesRows,'IN_VALLEY')\n",
    "dfPoles['TX_RESIDENTIAL'] = new_columns(dfPoles, numPolesRows,'TX_RESIDENTIAL')\n",
    "dfPoles['TX_COMMERCIAL'] = new_columns(dfPoles, numPolesRows,'TX_COMMERCIAL')\n",
    "dfPoles['TX_INDUSTRIAL'] = new_columns(dfPoles, numPolesRows,'TX_INDUSTRIAL')\n",
    "#dfPoles['HEIGHT'] = new_columns(dfPoles, numPolesRows,'HEIGHT')\n",
    "dfPoles['NUM_CIRCUITS'] = new_columns(dfPoles, numPolesRows,'NUM_CIRCUITS')\n",
    "dfPoles['DEVICE'] = new_columns(dfPoles, numPolesRows,'DEVICE')\n",
    "dfPoles['TX_KVA'] = new_columns(dfPoles, numPolesRows,'TX_KVA')\n",
    "dfPoles['TX_PHASING'] = new_columns(dfPoles, numPolesRows,'TX_PHASING')\n",
    "\n",
    "# Fill with values\n",
    "dfPoles[ASSET_CLASS] = POLES_ASSET_CLASS\n",
    "dfPoles[ASSET_SUBCLASS] = 'WOOD'\n",
    "\n",
    "# Poles_class_height table\n",
    "fileNamePolesClassHeight = 'DomainCodes_PolesClassHeight.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNamePolesClassHeight) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfPolesClassHeight = pd.read_excel(xls, 'Sheet1') # 280 rows\n",
    "#print(dfPoles.shape) \n",
    "# Merge tables\n",
    "dfPoles = dfPoles.merge(dfPolesClassHeight, how='left', on='COMPATIBLEUNITID')\n",
    "\n",
    "# Rename Pole columns\n",
    "dfPoles = dfPoles.rename(columns={'DEVICENUMBER':'ID',\n",
    "                                  'TYPE':'POLE_CLASS',\n",
    "                                  'INSTALLATIONDATE':'INSTALL_YEAR'})\n",
    "# Separate year\n",
    "dfPoles['INSTALL_YEAR'] = dfPoles['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "\n",
    "dropPolesCols2 = ['COMPATIBLEUNITID']\n",
    "dfPoles = drop_columns(dfPoles, dropPolesCols2)\n",
    "# POLES_COLS = ['asset_id','asset_class_code','asset_subclass_code','install_year','hi character','phasing character',\n",
    "#               'prid character','pole_class','tx','tx_type','circuit1','circuit2','circuit3','circuit4','in_valley',\n",
    "#               'tx_residential','tx_commercial','tx_industrial','height','num_circuits','device','tx_kva','id','prid2',\n",
    "#               'prid3','prid4','tx_pcb']\n",
    "# ['phasing', 'prid', 'tx', 'tx_type', 'circuit1', 'circuit2', 'circuit3',\n",
    "#        'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'in_valley',\n",
    "#        'tx_residential', 'tx_commercial', 'tx_industrial', 'num_circuits',\n",
    "#        'device', 'tx_kva', 'tx_phasing']\n",
    "\n",
    "# Lower case column names\n",
    "dfPoles.columns = map(str.lower, dfPoles.columns)\n",
    "\n",
    "#NEED to Rearrange columns - will do when pole attachment info available\n",
    "# POLES_TABLE = 'IN_POLES.xlsx'\n",
    "MasterFile = pd.ExcelWriter(POLES_TABLE)\n",
    "dfPoles.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "#print(dfPoles.columns)\n",
    "print('Poles analysis completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cables analysis completed\n"
     ]
    }
   ],
   "source": [
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# Save future wait times while running\n",
    "dfTransformers = dfTransformersV2\n",
    "dfSwitches = dfSwitchesV2\n",
    "dfPoles = dfPolesV2\n",
    "dfCables = dfCablesV2\n",
    "dfFuses = dfFusesV2\n",
    "dfUGStructures = dfUGStructuresV2\n",
    "#**********************************************************************************\n",
    "#DELETE THIS WHEN COMBINING ALL ASSETS\n",
    "#**********************************************************************************\n",
    "# Cables\n",
    "dropCablesCols = ['ENABLED',  'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID',\n",
    "                  'LENGTHSOURCE',  'LENGTHUOMCODE', 'LABELTEXT', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', \n",
    "                  'ISFEEDERTRUNK', 'NEUTRALUSECD', 'FEATURE_STATUS', 'CONDUCTOR_REJUVENATION']\n",
    "# drop columns not related to Tx\n",
    "dfCables = drop_columns(dfCables,dropCablesCols)\n",
    "\n",
    "# Add additional columns and fill with NaNs\n",
    "numCablesRows = len(dfCables['INSTALLATIONDATE'])\n",
    "\n",
    "#dfCables\n",
    "dfCables[ASSET_CLASS] = new_columns(dfCables, numCablesRows, ASSET_CLASS)\n",
    "dfCables[ASSET_SUBCLASS] = new_columns(dfCables, numCablesRows, ASSET_SUBCLASS)\n",
    "dfCables['HI'] = new_columns(dfCables,numCablesRows,'HI')\n",
    "dfCables['PRID'] = new_columns(dfCables, numCablesRows,'PRID')\n",
    "dfCables['ARRANGEMENT'] = new_columns(dfCables, numCablesRows,'ARRANGEMENT')\n",
    "dfCables['INSTALLATION'] = new_columns(dfCables, numCablesRows,'INSTALLATION')\n",
    "dfCables['CONFIG'] = new_columns(dfCables, numCablesRows,'CONFIG')\n",
    "dfCables['NUM_SPLICES'] = new_columns(dfCables, numCablesRows,'NUM_SPLICES')\n",
    "dfCables['PRID_RESIDENTIAL'] = new_columns(dfCables, numCablesRows,'PRID_RESIDENTIAL')\n",
    "dfCables['PRID_COMMERCIAL'] = new_columns(dfCables, numCablesRows,'PRID_COMMERCIAL')\n",
    "dfCables['PRID_INDUSTRIAL'] = new_columns(dfCables, numCablesRows,'PRID_INDUSTRIAL')\n",
    "dfCables['WC_CATASTROPHIC_RES'] = new_columns(dfCables, numCablesRows,'WC_CATASTROPHIC_RES')\n",
    "dfCables['WC_CATASTROPHIC_COMM'] = new_columns(dfCables, numCablesRows,'WC_CATASTROPHIC_COMM')\n",
    "dfCables['WC_CATASTROPHIC_IND'] = new_columns(dfCables, numCablesRows,'WC_CATASTROPHIC_IND')\n",
    "dfCables['WC_REPLACEMENT'] = new_columns(dfCables, numCablesRows,'WC_REPLACEMENT')\n",
    "#dfCables['CABLE_PHASE'] = new_columns(dfCables, numCablesRows,'CABLE_PHASE')\n",
    "\n",
    "# Rename Cable columns\n",
    "dfCables = dfCables.rename(columns={'SHAPE_Length':'ID',\n",
    "                                    'SUBTYPECD':'PHASING',\n",
    "                                    'INSTALLATIONDATE':'INSTALL_YEAR',\n",
    "                                    'FEEDERID':'CIRCUIT',\n",
    "                                    'MEASUREDLENGTH':'LENGTH',\n",
    "                                    'WIRECOUNT': 'NUM_CABLES',\n",
    "                                    'PHASEDESIGNATION':'CABLE_PHASE'})\n",
    "# Separate year\n",
    "dfCables['INSTALL_YEAR'] = dfCables['INSTALL_YEAR'].apply(lambda x: x.year)\n",
    "#print(dfCables.head(3))\n",
    "\n",
    "# Replace Asset class and 'SUBTYPECD' with actual tx types\n",
    "dictCablesPhasing = {'1':'1','2':'1','3':'1','4':'2','5':'3','6':'Abandon'}\n",
    "dictCablesPhase = {'0.0':'', '1.0':'B','2.0':'Y','3.0':'YB','4.0':'R','6.0':'RB','7.0':'RYB','':''}\n",
    "\n",
    "dfCables['PHASING'] = dfCables['PHASING'].astype(str)\n",
    "dfCables['CABLE_PHASE'] = dfCables['CABLE_PHASE'].astype(str)\n",
    "\n",
    "#Try using .loc[row_indexer,col_indexer] = value instead\n",
    "dfCables.loc[:,'PHASING'] = dfCables['PHASING'].apply(lambda x: dictCablesPhasing[x])\n",
    "dfCables.loc[:,'CABLE_PHASE'] = dfCables['CABLE_PHASE'].apply(lambda x: dictCablesPhase[x])\n",
    "\n",
    "# Fill in Asset and asset subclass columns\n",
    "dfCables[ASSET_CLASS] = UG_PRI_CABLE_ASSET_CLASS\n",
    "\n",
    "# Cables Domain code tables\n",
    "fileNameDomainCodes_Cables = 'DomainCodes_Cables.xlsx'\n",
    "# Read Other Device Numbers into dataframes\n",
    "with pd.ExcelFile(fileNameDomainCodes_Cables) as xls:\n",
    "    #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "    dfCablesDomainCodes = pd.read_excel(xls, 'Sheet1')\n",
    "\n",
    "dfCables=dfCables.merge(dfCablesDomainCodes, how='left', on='COMPATIBLEUNITID')\n",
    "#print(dfUGTransformers.head(2))\n",
    "dropCablesCols2 = ['COMPATIBLEUNITID','Description','Percent']\n",
    "dfCables = drop_columns(dfCables,dropCablesCols2)\n",
    "\n",
    "# Lower case column names\n",
    "dfCables.columns = map(str.lower, dfCables.columns)\n",
    "\n",
    "# UG_PRI_CABLE_COLS = ['asset_id','id','install_year','hi','asset_subclass_code','asset_class_code','phasing','prid',\n",
    "#                      'circuit','arrangement','installation','material','cable_size','config','length','num_splices',\n",
    "#                      'num_cables','prid_residential','prid_commercial','prid_industrial','nominal_voltage',\n",
    "#                      'wc_prid_catastrophic_res','wc_prid_catastrophic_comm','wc_prid_catastrophic_ind','cable_phase',\n",
    "#                      'wc_replacement','wc_switching_res','wc_switching_comm','wc_switching_ind','wc_switching_duration']\n",
    "\n",
    "# print(dfCables.columns)\n",
    "# ['install_year', 'circuit', 'length', 'num_cables', 'phasing',\n",
    "#        'cable_phase', 'id', 'asset_class_code', 'asset_subclass_code', 'hi',\n",
    "#        'prid', 'arrangement', 'installation', 'config', 'num_splices',\n",
    "#        'prid_residential', 'prid_commercial', 'prid_industrial',\n",
    "#        'wc_catastrophic_res', 'wc_catastrophic_comm', 'wc_catastrophic_ind',\n",
    "#        'wc_replacement', 'cable_size', 'material', 'cnshld',\n",
    "#        'nominal_voltage'],\n",
    "\n",
    "# UG_PRI_CABLE_TABLE = 'IN_CABLES.xlsx'\n",
    "# UG_PRI_CABLE_ASSET_CLASS = 'UG_CABLE'\n",
    "MasterFile = pd.ExcelWriter(UG_PRI_CABLE_TABLE)\n",
    "dfCables.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Cables analysis completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k =   1 ,a score of:  96.9570654439\n",
      "With k =   2 ,a score of:  96.2901208837\n",
      "With k =   3 ,a score of:  96.8736973739\n",
      "With k =   5 ,a score of:  96.5402250938\n",
      "With k =   10 ,a score of:  95.4981242184\n",
      "With k =   20 ,a score of:  93.0387661526\n",
      "96.8736973739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:420: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POLE_ID            0\n",
      "x                  0\n",
      "y                  0\n",
      "xy                 0\n",
      "OH_FEEDERID        0\n",
      "OH_FEEDERID2    2571\n",
      "xyEnd           2571\n",
      "dtype: int64\n",
      "Pole attachments analysis completed\n"
     ]
    }
   ],
   "source": [
    "#dfPolesTxSwitchCablesOHCondLatLongEnd = dfPolesTxSwitchCablesLatLong.merge(dfOHCondLatLong,left_on='xy', right_on='xyEnd')\n",
    "#**********************************************************************\n",
    "# OUTPUT FILES\n",
    "#**********************************************************************\n",
    "# # Transformer-Switch-Cables-OHCond-Poles match output\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCableOHCond_start.xlsx')\n",
    "# dfPolesTxSwitchCablesOHCondLatLongStart.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "# # MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCableOHCond_mid.xlsx')\n",
    "# # dfPolesTxSwitchCablesOHCondLatLongMid.to_excel(MasterFile, 'Sheet1')\n",
    "# # MasterFile.save()\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCableOHCond_end.xlsx')\n",
    "# dfPolesTxSwitchCablesOHCondLatLongEnd.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "# print('Pole attachments analysis completed')\n",
    "\n",
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfOHCondLatLong = dfOHCondLatLongV1\n",
    "dfCablesLatLong = dfCablesLatLongV1\n",
    "dfTxLatLong = dfTxLatLongV1\n",
    "\n",
    "dfPoles.columns = map(str.lower, dfPoles.columns)\n",
    "\n",
    "polesLatLongDropCols = ['FID', 'OBJECTID', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF', 'COMMENTS','CREATIONUS', \n",
    "                        'DATECREATE', 'LASTUSER', 'DATEMODIFI', 'WORKREQUES','DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                        'WORKFLOWST', 'WORKFUNCTI','SYMBOLROTA', 'GPSDATE', 'GISONUMBER', 'GISOTYPENB', 'SUBTYPECD',\n",
    "                        'LABELTEXT', 'OWNERSHIP', 'COMPATIBLE', 'STRUCTUREN', 'FEATURE_ST','STREETLIGH', 'REPLACED_D', \n",
    "                        'CONDITION', 'CONDITION_','CONDITION1']\n",
    "\n",
    "# 'DEVICENUMB', 'x', 'y'\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, polesLatLongDropCols)\n",
    "\n",
    "#Change datatype to str for concatenation\n",
    "dfPolesLatLong['x'] = dfPolesLatLong['x'].astype(str)\n",
    "dfPolesLatLong['y'] = dfPolesLatLong['y'].astype(str)\n",
    "dfPolesLatLong['xy'] = dfPolesLatLong['x']+'-'+dfPolesLatLong['y']\n",
    "#print(dfPolesLatLong.columns) \n",
    "# ['DEVICENUMB', 'x', 'y', 'xy']\n",
    "dfPolesLatLong = dfPolesLatLong.rename(columns={'DEVICENUMB': 'POLE_ID'})\n",
    "dropMoreLatLongCols =['x','y']\n",
    "#dropMoreWireLatLongCols =['x','y','xMid','yMid','xEnd', 'yEnd']\n",
    "dropMoreWireLatLongCols =['xStart','yStart','xMid','yMid','xEnd', 'yEnd']\n",
    "\n",
    "#dfPolesLatLong = drop_columns(dfPolesLatLong, dropMoreLatLongCols)\n",
    "\n",
    "#**********************************************************************\n",
    "# Primary OH\n",
    "#**********************************************************************\n",
    "priOHCondLatLongDropCols = ['FID', 'OBJECTID', 'ENABLED', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF','COMMENTS', 'CREATIONUS', \n",
    "                            'DATECREATE', 'LASTUSER', 'DATEMODIFI','WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                            'WORKFLOWST','WORKFUNCTI', 'FEEDERINFO', 'ELECTRICTR','LOCATIONID', 'LENGTHSOUR', 'MEASUREDLE', \n",
    "                            'LENGTHUOMC', 'WIRECOUNT','GISONUMBER', 'GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE',\n",
    "                            'OWNERSHIP', 'PHASEDESIG', 'OPERATINGV', 'NOMINALVOL', 'ISFEEDERTR','NEUTRALUSE', 'PHASECONFI', \n",
    "                            'CLEARANCE', 'FEATURE_ST', 'TL_DESIGNA','SHAPE_LEN', 'FeederID_1', 'EnergizedP', 'SourceCoun', \n",
    "                            'Loop']\n",
    "\n",
    "#'INSTALLATI','FEEDERID', 'FEEDERID2','xStart','xMid', 'xEnd', 'yStart', 'yMid', 'yEnd'\n",
    "dfOHCondLatLong = drop_columns(dfOHCondLatLong, priOHCondLatLongDropCols)\n",
    "# dfOHCondLatLong = dfOHCondLatLong.rename(columns={'xStart': 'x',\n",
    "#                                                   'yStart': 'y',\n",
    "#                                                   'FEEDERID': 'OH_FEEDERID',\n",
    "#                                                   'FEEDERID2': 'OH_FEEDERID2',})\n",
    "dfOHCondLatLong = dfOHCondLatLong.rename(columns={'FEEDERID': 'OH_FEEDERID',\n",
    "                                                  'FEEDERID2': 'OH_FEEDERID2',})\n",
    "#'xMid', 'yMid','xEnd','yEnd','FEEDERID','INSTALLATI',\n",
    "#Change datatype to str for concatenation\n",
    "dfOHCondLatLong['xStart'] = dfOHCondLatLong['xStart'].astype(str)\n",
    "dfOHCondLatLong['yStart'] = dfOHCondLatLong['yStart'].astype(str)\n",
    "dfOHCondLatLong['xy'] = dfOHCondLatLong['xStart']+'-'+dfOHCondLatLong['yStart']\n",
    "dfOHCondLatLong['xEnd'] = dfOHCondLatLong['xEnd'].astype(str)\n",
    "dfOHCondLatLong['yEnd'] = dfOHCondLatLong['yEnd'].astype(str)\n",
    "dfOHCondLatLong['xyEnd'] = dfOHCondLatLong['xEnd']+'-'+dfOHCondLatLong['yEnd']\n",
    "\n",
    "dfOHCondLatLong = drop_columns(dfOHCondLatLong, dropMoreWireLatLongCols)\n",
    "# Transformer-Switch-Cables-Poles: \n",
    "# 7156 matches (81.1%) out of 8826 [1670 unmatched ~ 18.9%]\n",
    "dfPolesOHCondLatLongStart = dfPolesLatLong.merge(dfOHCondLatLong, how='left', on='xy')\n",
    "#print(dfPolesTxSwitchCablesLatLong.columns)\n",
    "# 6813 matches (77.2%) out of 8826 [2013 unmatched ~ 22.8%]\n",
    "dfPolesOHCondLatLongEnd = dfPolesLatLong.merge(dfOHCondLatLong, how='left', left_on='xy', right_on='xyEnd')\n",
    "\n",
    "#print(dfPolesOHCondLatLongStart.isnull().sum())\n",
    "df_empty = dfPolesOHCondLatLongStart[dfPolesOHCondLatLongStart.OH_FEEDERID.isnull()]\n",
    "df_filled = dfPolesOHCondLatLongStart[dfPolesOHCondLatLongStart.OH_FEEDERID.notnull()]\n",
    "\n",
    "# df_empty.drop('OH_FEEDERID', axis=1, inplace=True)\n",
    "# df_empty['OH_FEEDERID'] = 0\n",
    "# print(df_filled.columns)\n",
    "# print(df_empty.columns)\n",
    "# print(df_empty.isnull().sum())\n",
    "# print(df_empty.shape)\n",
    "# print(df_empty.head(5))\n",
    "# print(df_filled.isnull().sum())\n",
    "# print(df_filled.shape)\n",
    "\n",
    "# Split the df_filled to train and test data\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine,test_size=0.30, random_state=123)\n",
    "\n",
    "#https://www.dataquest.io/blog/k-nearest-neighbors/\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "import math\n",
    "\n",
    "# Randomly shuffle the index of df_filled.\n",
    "random_indices = permutation(df_filled.index)\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(df_filled)/3)\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "df_filled_test = df_filled.loc[random_indices[1:test_cutoff]]\n",
    "# Generate the train set with the rest of the data.\n",
    "df_filled_train = df_filled.loc[random_indices[test_cutoff:]]\n",
    "\n",
    "for k in [1, 2, 3, 5, 10, 20]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(df_filled_train[['x', 'y']], df_filled_train['OH_FEEDERID'])\n",
    "\n",
    "    predictions = knn.predict(df_filled_test[['x','y']])\n",
    "    prediction_results = df_filled_test['OH_FEEDERID'] == predictions\n",
    "    print('With k =  ',k,',a score of: ', prediction_results.mean()*100)\n",
    "\n",
    "# Let's initialize a classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# knn.fit takes two parameters # First, the content we want to train on. For us it's height and weight.\n",
    "# Secondly, how we're classifying each element of the training data. We're classifying by position!\n",
    "# knn.fit(nba_training[[\"Ht (In.)\", \"WT\"]], nba_training[\"POS\"])\n",
    "knn.fit(df_filled_train[['x', 'y']], df_filled_train['OH_FEEDERID'])\n",
    "predictions = knn.predict(df_filled_test[['x','y']])\n",
    "fill_feeders = knn.predict(df_empty[['x','y']])\n",
    "prediction_results = df_filled_test['OH_FEEDERID'] == predictions\n",
    "print(prediction_results.mean()*100)\n",
    "df_empty.loc[:,'OH_FEEDERID'] = fill_feeders\n",
    "# print(df_empty.isnull().sum())\n",
    "# print(df_empty.shape)\n",
    "# print(df_empty.head(5))\n",
    "# Get the actual values for the test set.\n",
    "#actual = df_filled_test['OH_FEEDERID']\n",
    "# Compute the mean squared error of our predictions.\n",
    "# mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "\n",
    "df_all = pd.concat([df_filled,df_empty])\n",
    "print(df_all.isnull().sum())\n",
    "MasterFile = pd.ExcelWriter('V4_ML_PolesOHCond_start.xlsx')\n",
    "df_all.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole attachments analysis completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Feeders:  36\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# fileName - iterate through entire folder :)\n",
    "#fileName = '3S3-1_Crestwood_Feeder_Details.xlsx'\n",
    "\n",
    "#input directory\n",
    "inputDirectory = 'Metsco_Feeder_Reports'\n",
    "\n",
    "# define filepath and sort the file list\n",
    "filesList = glob(os.path.join(inputDirectory, '*.xlsx'))\n",
    "numFiles = len(filesList)\n",
    "print('Number of Feeders: ', numFiles)\n",
    "sortedFileList = sorted(filesList)\n",
    "\n",
    "# variables\n",
    "dictFeeders = {}\n",
    "allNodes_list = pd.DataFrame()\n",
    "\n",
    "# read text files in tweet_input directory\n",
    "for f in sortedFileList:\n",
    "\n",
    "    fileName = os.path.basename(f).split('_')\n",
    "    FeederKey = fileName[0]\n",
    "    #print(FeederKey)\n",
    "    \n",
    "    if ('$' not in FeederKey):\n",
    "        # Read CYME Feeder xlsx file into dataframes\n",
    "        with pd.ExcelFile(f) as xlsx:\n",
    "            #dfTopology = pd.read_excel(xlsx, 'Topology', index_col=None, na_values=['NA']) # IGNORE for now\n",
    "            dfTopology = pd.read_excel(xlsx, 'Topology') # 280 rows\n",
    "            dfSpotLoads = pd.read_excel(xlsx, 'Spot Loads') # Tot:239 - R/Y/B: 116/108/103 values; based on phases\n",
    "            dfLoads = pd.read_excel(xlsx, 'Loads') # 239 rows; 'Spot Number\\n' col contains unique tx ids\n",
    "            dfCables = pd.read_excel(xlsx, 'Cables')\n",
    "            dfSwitches = pd.read_excel(xlsx, 'Switches') # 41 items\n",
    "            dfNodes = pd.read_excel(xlsx, 'Nodes') # 249 items\n",
    "            dfOHlines = pd.read_excel(xlsx, 'OverheadLinesByPhase') #Neutral - 94, Section Id - 381\n",
    "            dfFuses = pd.read_excel(xlsx, 'Fuses') # 44 items\n",
    "\n",
    "            # # Strip '\\n' from column headers\n",
    "            dfTopology.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSpotLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfCables.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfSwitches.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfNodes.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfOHlines.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            dfFuses.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "            #print(dfNodes.columns)\n",
    "            allNodes_list = allNodes_list.append(dfNodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['POLE_ID', 'xy', 'CIRCUITIDs'], dtype='object')\n",
      "Index(['xy', 'OH_FEEDERID'], dtype='object')\n",
      "6S2-3\n",
      "Pole attachments completed\n",
      "Pole attachments completed\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfOHCondLatLong = dfOHCondLatLongV1\n",
    "dfCablesLatLong = dfCablesLatLongV1\n",
    "dfTxLatLong = dfTxLatLongV1\n",
    "\n",
    "dfPoles.columns = map(str.lower, dfPoles.columns)\n",
    "\n",
    "polesLatLongDropCols = ['FID', 'OBJECTID', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF', 'COMMENTS','CREATIONUS', \n",
    "                        'DATECREATE', 'LASTUSER', 'DATEMODIFI', 'WORKREQUES','DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                        'WORKFLOWST', 'WORKFUNCTI','SYMBOLROTA', 'GPSDATE', 'GISONUMBER', 'GISOTYPENB', 'SUBTYPECD',\n",
    "                        'LABELTEXT', 'OWNERSHIP', 'COMPATIBLE', 'STRUCTUREN', 'FEATURE_ST','STREETLIGH', 'REPLACED_D', \n",
    "                        'CONDITION', 'CONDITION_','CONDITION1']\n",
    "\n",
    "# 'DEVICENUMB', 'x', 'y'\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, polesLatLongDropCols)\n",
    "\n",
    "#Change datatype to str for concatenation\n",
    "dfPolesLatLong['x'] = dfPolesLatLong['x'].astype(str)\n",
    "dfPolesLatLong['y'] = dfPolesLatLong['y'].astype(str)\n",
    "dfPolesLatLong['xy'] = dfPolesLatLong['x']+'-'+dfPolesLatLong['y']\n",
    "\n",
    "# ['DEVICENUMB', 'x', 'y', 'xy']\n",
    "dfPolesLatLong = dfPolesLatLong.rename(columns={'DEVICENUMB': 'POLE_ID'})\n",
    "dropMoreLatLongCols =['x','y']\n",
    "#dropMoreWireLatLongCols =['x','y','xMid','yMid','xEnd', 'yEnd']\n",
    "dropMoreWireLatLongCols =['xStart','yStart','xMid','yMid','xEnd', 'yEnd']\n",
    "\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, dropMoreLatLongCols)\n",
    "\n",
    "dfPolesLatLong['CIRCUITIDs'] = new_columns(dfPolesLatLong, numPolesRows,'CIRCUITIDs')\n",
    "\n",
    "print(dfPolesLatLong.columns) \n",
    "#**********************************************************************\n",
    "# Primary OH\n",
    "#**********************************************************************\n",
    "priOHCondLatLongDropCols = ['FID', 'OBJECTID', 'ENABLED', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF','COMMENTS', 'CREATIONUS', \n",
    "                            'DATECREATE', 'LASTUSER', 'DATEMODIFI','WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                            'WORKFLOWST','WORKFUNCTI', 'FEEDERINFO', 'ELECTRICTR','LOCATIONID', 'LENGTHSOUR', 'MEASUREDLE', \n",
    "                            'LENGTHUOMC', 'WIRECOUNT','GISONUMBER', 'GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE',\n",
    "                            'OWNERSHIP', 'PHASEDESIG', 'OPERATINGV', 'NOMINALVOL', 'ISFEEDERTR','NEUTRALUSE', 'PHASECONFI', \n",
    "                            'CLEARANCE', 'FEATURE_ST', 'TL_DESIGNA','SHAPE_LEN', 'FeederID_1', 'EnergizedP', 'SourceCoun', \n",
    "                            'Loop']\n",
    "\n",
    "#'INSTALLATI','FEEDERID', 'FEEDERID2','xStart','xMid', 'xEnd', 'yStart', 'yMid', 'yEnd'\n",
    "dfOHCondLatLong = drop_columns(dfOHCondLatLong, priOHCondLatLongDropCols)\n",
    "# dfOHCondLatLong = dfOHCondLatLong.rename(columns={'xStart': 'x',\n",
    "#                                                   'yStart': 'y',\n",
    "#                                                   'FEEDERID': 'OH_FEEDERID',\n",
    "#                                                   'FEEDERID2': 'OH_FEEDERID2',})\n",
    "dfOHCondLatLong = dfOHCondLatLong.rename(columns={'FEEDERID': 'OH_FEEDERID',\n",
    "                                                  'FEEDERID2': 'OH_FEEDERID2',})\n",
    "#'xMid', 'yMid','xEnd','yEnd','FEEDERID','INSTALLATI',\n",
    "#Change datatype to str for concatenation\n",
    "dfOHCondLatLong['xStart'] = dfOHCondLatLong['xStart'].astype(str)\n",
    "dfOHCondLatLong['yStart'] = dfOHCondLatLong['yStart'].astype(str)\n",
    "dfOHCondLatLong['xy'] = dfOHCondLatLong['xStart']+'-'+dfOHCondLatLong['yStart']\n",
    "dfOHCondLatLong['xEnd'] = dfOHCondLatLong['xEnd'].astype(str)\n",
    "dfOHCondLatLong['yEnd'] = dfOHCondLatLong['yEnd'].astype(str)\n",
    "dfOHCondLatLong['xyEnd'] = dfOHCondLatLong['xEnd']+'-'+dfOHCondLatLong['yEnd']\n",
    "\n",
    "# new drop\n",
    "drop_CondCols = ['xStart', 'yStart','xMid', 'yMid','xEnd','yEnd', 'xyEnd','OH_FEEDERID2']\n",
    "dfOHCondLatLong = drop_columns(dfOHCondLatLong, drop_CondCols)\n",
    "dfOHCondLatLong = dfOHCondLatLong[['xy','OH_FEEDERID']]\n",
    "print(dfOHCondLatLong.columns)\n",
    "#dfOHCondLatLong = drop_columns(dfOHCondLatLong, dropMoreWireLatLongCols)\n",
    "# Transformer-Switch-Cables-Poles: \n",
    "# 7156 matches (81.1%) out of 8826 [1670 unmatched ~ 18.9%]\n",
    "#dfPolesOHCondLatLongStart = dfPolesLatLong.merge(dfOHCondLatLong, how='left', on='xy')\n",
    "#print(dfPolesTxSwitchCablesLatLong.columns)\n",
    "# 6813 matches (77.2%) out of 8826 [2013 unmatched ~ 22.8%]\n",
    "\n",
    "#dfPolesOHCondLatLongEnd = dfPolesLatLong.merge(dfOHCondLatLong, how='left', left_on='xy', right_on='xyEnd')\n",
    "#dictOHCondLatLong = pd.DataFrame.to_dict(dfOHCondLatLong)\n",
    "#dictOHCondLatLong = dfOHCondLatLong.set_index('xy').T.to_dict(dfOHCondLatLong)\n",
    "#df.set_index('id')['value'].to_dict()\n",
    "dictOHCondLatLong = dfOHCondLatLong.set_index('xy')['OH_FEEDERID'].to_dict()\n",
    "\n",
    "#df.set_index('ID't).T.to_dict('list')\n",
    "print(dictOHCondLatLong['23492.882-5543246.193']) #6S2-3\n",
    "#print(dictOHCondLatLong.keys())\n",
    "#print(dfPolesLatLong.isnull().sum())\n",
    "dfPolesLatLong['CIRCUITIDs'] = dfPolesLatLong['xy'].apply(lambda x: dictOHCondLatLong[x] if x in dictOHCondLatLong.keys() else np.nan)\n",
    "#print(dfPolesLatLong.isnull().sum())\n",
    "\n",
    "MasterFile = pd.ExcelWriter('V4_PolesOHCond_start_dictionary.xlsx')\n",
    "dfPolesLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole attachments completed')\n",
    "\n",
    "length_dict = {key: len(value) for key, value in dictOHCondLatLong.items()}\n",
    "length_series = pd.Series(length_dict)\n",
    "length_df = pd.Series.to_frame(length_series)\n",
    "MasterFile = pd.ExcelWriter('V4_PolesOHCond_start_dictLength.xlsx')\n",
    "length_df.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole attachments completed')\n",
    "\n",
    "list_keys_1 = ['14749.889-5552131.258','14873.328-5552132.821','14917.084625-5549564.644','14917.308-5549523.135',\n",
    "               '14998.016-5552134.385','15126.766-5552135.949','15259.892-5552137.825','15392.705-5552139.701',\n",
    "               '15523.331-5552141.266','15651.146-5552142.518','15783.022-5552144.083','15938.89-5552145.087',\n",
    "               '17531.555-5543479.302','17532.084-5543327.087','17532.273-5543173.845','17532.481-5543097.508',\n",
    "               '17532.481-5543403.221']\n",
    "for k in list_keys_1:\n",
    "    print(dictOHCondLatLong[k]) #6S2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole attachments analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Poles and Tx match - 1553 matches out of 1642 [89 no matches ~ 5%]\n",
    "# Poles and Switch match - 98 matches\n",
    "\n",
    "# Lat long df\n",
    "dfPolesLatLong = dfPolesLatLongV1\n",
    "dfSwitchesLatLong = dfSwitchesLatLongV1\n",
    "dfOHCondLatLong = dfOHCondLatLongV1\n",
    "dfCablesLatLong = dfCablesLatLongV1\n",
    "dfTxLatLong = dfTxLatLongV1\n",
    "\n",
    "dfPoles.columns = map(str.lower, dfPoles.columns)\n",
    "\n",
    "polesLatLongDropCols = ['FID', 'OBJECTID', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF', 'COMMENTS','CREATIONUS', \n",
    "                        'DATECREATE', 'LASTUSER', 'DATEMODIFI', 'WORKREQUES','DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                        'WORKFLOWST', 'WORKFUNCTI','SYMBOLROTA', 'GPSDATE', 'GISONUMBER', 'GISOTYPENB', 'SUBTYPECD',\n",
    "                        'LABELTEXT', 'OWNERSHIP', 'COMPATIBLE', 'STRUCTUREN', 'FEATURE_ST','STREETLIGH', 'REPLACED_D', \n",
    "                        'CONDITION', 'CONDITION_','CONDITION1']\n",
    "\n",
    "# 'DEVICENUMB', 'x', 'y'\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, polesLatLongDropCols)\n",
    "\n",
    "#Change datatype to str for concatenation\n",
    "dfPolesLatLong['x'] = dfPolesLatLong['x'].astype(str)\n",
    "dfPolesLatLong['y'] = dfPolesLatLong['y'].astype(str)\n",
    "dfPolesLatLong['xy'] = dfPolesLatLong['x']+'-'+dfPolesLatLong['y']\n",
    "#print(dfPolesLatLong.columns) \n",
    "# ['DEVICENUMB', 'x', 'y', 'xy']\n",
    "dfPolesLatLong = dfPolesLatLong.rename(columns={'DEVICENUMB': 'POLE_ID'})\n",
    "dropMoreLatLongCols =['x','y']\n",
    "dropMoreWireLatLongCols =['x','y','xMid','yMid','xEnd', 'yEnd']\n",
    "dfPolesLatLong = drop_columns(dfPolesLatLong, dropMoreLatLongCols)\n",
    "\n",
    "# UG SWITCH\n",
    "switchLatLongDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI', 'INSTALLATI','FIELDVERIF', 'COMMENTS', \n",
    "                         'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', \n",
    "                         'WMSID','WORKFLOWST', 'WORKFUNCTI',  'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'GPSDATE', \n",
    "                         'GISONUMBER', 'GISOTYPENB','LABELTEXT', 'OWNERSHIP', 'PHASEDESIG','OPERATINGV', 'NOMINALVOL', \n",
    "                         'MAXOPERATI', 'MAXCONTINU', 'PRESENTPOS', 'PRESENTP_1', 'PRESENTP_2', 'NORMALPOSI', 'NORMALPO_1',\n",
    "                         'NORMALPO_2','SCADACONTR', 'SCADAMONIT', 'PREFERREDC', 'TIESWITCHI', 'GANGOPERAT','MANUALLYOP',\n",
    "                         'FEATURE_ST', 'HYPERLINK', 'HYPERLINK_','SYMBOLROTA', 'INSULATOR_', 'FeederID_1', 'EnergizedP', \n",
    "                         'SourceCoun','Loop', 'Tie','COMPATIBLE']\n",
    "\n",
    "dfSwitchesLatLong = drop_columns(dfSwitchesLatLong, switchLatLongDropCols)\n",
    "dfSwitchesLatLong = dfSwitchesLatLong.rename(columns={'DEVICENUMB': 'SW_ID',\n",
    "                                                      'FEEDERID': 'SW_FEEDERID',\n",
    "                                                      'FEEDERID2': 'SW_FEEDERID2'})\n",
    "#Change datatype to str for concatenation\n",
    "dfSwitchesLatLong['x'] = dfSwitchesLatLong['x'].astype(str)\n",
    "dfSwitchesLatLong['y'] = dfSwitchesLatLong['y'].astype(str)\n",
    "dfSwitchesLatLong['xy'] = dfSwitchesLatLong['x']+'-'+dfSwitchesLatLong['y']\n",
    "# print(dfSwitchesLatLong.columns)\n",
    "#['FEEDERID', 'FEEDERID2', 'SUBTYPECD','DEVICENUMB', 'x','y', 'xy']\n",
    "#print(dfSwitchesLatLong.head(2))\n",
    "dfSwitchesLatLong = drop_columns(dfSwitchesLatLong, dropMoreLatLongCols)\n",
    "\n",
    "# Poles and Switch match - 98 matches\n",
    "dfPolesSwitchLatLong = dfPolesLatLong.merge(dfSwitchesLatLong, how='left', on='xy')\n",
    "#dfPolesSwitchLatLong = dfPolesLatLong.merge(dfSwitchesLatLong, on='xy')\n",
    "\n",
    "#**********************************************************************\n",
    "# Tx\n",
    "#**********************************************************************\n",
    "txLatLongDropCols = ['FID', 'OBJECTID', 'ANCILLARYR', 'ENABLED', 'WORKORDERI', 'INSTALLATI','FIELDVERIF', 'COMMENTS', \n",
    "                     'CREATIONUS', 'DATECREATE', 'LASTUSER','DATEMODIFI', 'WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID',\n",
    "                     'WORKFLOWST', 'WORKFUNCTI', 'FEEDERINFO','ELECTRICTR', 'LOCATIONID', 'SYMBOLROTA', 'GPSDATE', \n",
    "                     'GISONUMBER','GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE', 'OWNERSHIP','PHASEDESIG', \n",
    "                     'OPERATINGV', 'NOMINALVOL', 'GROUNDREAC', 'GROUNDRESI','MAGNETIZIN', 'MAGNETIZ_1', 'HIGHSIDEGR', \n",
    "                     'HIGHSIDE_1', 'HIGHSIDEPR','LOCATIONTY', 'FAULTINDIC', 'COOLINGTYP', 'FEATURE_ST','KVA', 'UNITS', \n",
    "                     'DEMAND_KVA', 'DEMAND_DAT', 'STREET_LIG', 'HIGHSIDECO','LOWSIDECON', 'LOWSIDEGRO', 'LOWSIDEVOL', \n",
    "                     'LATITUDE', 'LONGITUDE','RATEDKVA', 'FeederID_1', 'EnergizedP', 'SourceCoun', 'Loop','FEEDERID2']\n",
    "\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, txLatLongDropCols)\n",
    "\n",
    "# dfTxLatLong = dfTxLatLong.rename(columns={'DEVICENUMB': 'TX_ID',\n",
    "#                                           'FEEDERID': 'TX_FEEDERID'})\n",
    "\n",
    "dfTxLatLong = dfTxLatLong.merge(dfOHTransformers, how='left', left_on='DEVICENUMB', right_on='id')\n",
    "#print(dfTxLatLong.columns)\n",
    "\n",
    "\n",
    "txLatLongDropCols2 = ['DEVICENUMB', 'asset_class_code','asset_subclass_code', 'hi', 'primary_voltage','device_residential', \n",
    "                      'device_commercial','device_industrial','upstream_device', 'prid', 'in_valley', 'pcb','banking', \n",
    "                      'sec_voltage']\n",
    "#'FEEDERID','id', 'circuit','install_year','kva','x', 'y','phasing','tx_residential', 'tx_commercial','tx_industrial', \n",
    "\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, txLatLongDropCols2)\n",
    "\n",
    "# ['phasing', 'prid', 'tx', 'tx_type', 'circuit1', 'circuit2', 'circuit3',\n",
    "#        'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'in_valley',\n",
    "#        'tx_residential', 'tx_commercial', 'tx_industrial', 'num_circuits',\n",
    "#        'device', 'tx_kva', 'tx_phasing']\n",
    "\n",
    "#Change datatype to str for concatenation\n",
    "dfTxLatLong['x'] = dfTxLatLong['x'].astype(str)\n",
    "dfTxLatLong['y'] = dfTxLatLong['y'].astype(str)\n",
    "dfTxLatLong['xy'] = dfTxLatLong['x']+'-'+dfTxLatLong['y']\n",
    "\n",
    "# print(dfSwitchesLatLong.columns)\n",
    "#['FEEDERID','DEVICENUMB', 'x','y', 'xy']\n",
    "dfTxLatLong = drop_columns(dfTxLatLong, dropMoreLatLongCols)\n",
    "\n",
    "# Poles and Tx match - 1553 matches out of 1642 [89 no matches ~ 5%]\n",
    "dfPolesTxLatLong = dfPolesLatLong.merge(dfTxLatLong, how='left', on='xy')\n",
    "dfPolesTxSwitchLatLong = dfPolesTxLatLong.merge(dfSwitchesLatLong, how='left', on='xy')\n",
    "# dfPolesTxLatLong = dfPolesLatLong.merge(dfTxLatLong, on='xy')\n",
    "# dfPolesTxSwitchLatLong = dfPolesTxLatLong.merge(dfSwitchesLatLong, on='xy')\n",
    "#print(type(dfPolesTxLatLong))\n",
    "\n",
    "#**********************************************************************\n",
    "# UG Cables\n",
    "#**********************************************************************\n",
    "cablesLatLongDropCols = ['FID', 'OBJECTID', 'ENABLED', 'WORKORDERI',  'FIELDVERIF','COMMENTS', 'CREATIONUS', 'DATECREATE', \n",
    "                         'LASTUSER', 'DATEMODIFI','WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID', 'WORKFLOWST','WORKFUNCTI',\n",
    "                         'FEEDERID2', 'FEEDERINFO', 'ELECTRICTR','LOCATIONID', 'LENGTHSOUR', 'MEASUREDLE', 'LENGTHUOMC', \n",
    "                         'WIRECOUNT','GISONUMBER', 'GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE','OWNERSHIP', \n",
    "                         'PHASEDESIG', 'OPERATINGV', 'NOMINALVOL', 'ISFEEDERTR','NEUTRALUSE', 'FEATURE_ST', 'CONDUCTOR_', \n",
    "                         'SHAPE_LEN', 'FeederID_1','EnergizedP', 'SourceCoun', 'Loop']\n",
    "\n",
    "dfCablesLatLong = drop_columns(dfCablesLatLong, cablesLatLongDropCols)\n",
    "dfCablesLatLong = dfCablesLatLong.rename(columns={'xStart': 'x',\n",
    "                                                  'yStart': 'y',\n",
    "                                                  'FEEDERID': 'Cable_FEEDERID',\n",
    "                                                  'INSTALLATI': 'Cable_Year',})\n",
    "#'xMid', 'yMid','xEnd','yEnd','FEEDERID','INSTALLATI',\n",
    "#Change datatype to str for concatenation\n",
    "dfCablesLatLong['x'] = dfCablesLatLong['x'].astype(str)\n",
    "dfCablesLatLong['y'] = dfCablesLatLong['y'].astype(str)\n",
    "dfCablesLatLong['xy'] = dfCablesLatLong['x']+'-'+dfCablesLatLong['y']\n",
    "\n",
    "dfCablesLatLong = drop_columns(dfCablesLatLong, dropMoreWireLatLongCols)\n",
    "# Transformer-Switch-Cables-Poles: only 11 matches :(\n",
    "dfPolesTxSwitchCablesLatLong = dfPolesTxSwitchLatLong.merge(dfCablesLatLong, how='left', on='xy')\n",
    "#dfPolesTxSwitchCablesLatLong = dfPolesTxSwitchLatLong.merge(dfCablesLatLong, on='xy')\n",
    "\n",
    "#**********************************************************************\n",
    "# Primary OH\n",
    "#**********************************************************************\n",
    "priOHCondLatLongDropCols = ['FID', 'OBJECTID', 'ENABLED', 'WORKORDERI', 'INSTALLATI', 'FIELDVERIF','COMMENTS', 'CREATIONUS', \n",
    "                            'DATECREATE', 'LASTUSER', 'DATEMODIFI','WORKREQUES', 'DESIGNID', 'WORKLOCATI', 'WMSID', \n",
    "                            'WORKFLOWST','WORKFUNCTI', 'FEEDERINFO', 'ELECTRICTR','LOCATIONID', 'LENGTHSOUR', 'MEASUREDLE', \n",
    "                            'LENGTHUOMC', 'WIRECOUNT','GISONUMBER', 'GISOTYPENB', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLE',\n",
    "                            'OWNERSHIP', 'PHASEDESIG', 'OPERATINGV', 'NOMINALVOL', 'ISFEEDERTR','NEUTRALUSE', 'PHASECONFI', \n",
    "                            'CLEARANCE', 'FEATURE_ST', 'TL_DESIGNA','SHAPE_LEN', 'FeederID_1', 'EnergizedP', 'SourceCoun', \n",
    "                            'Loop']\n",
    "\n",
    "#'INSTALLATI','FEEDERID', 'FEEDERID2','xStart','xMid', 'xEnd', 'yStart', 'yMid', 'yEnd'\n",
    "dfOHCondLatLong = drop_columns(dfOHCondLatLong, priOHCondLatLongDropCols)\n",
    "dfOHCondLatLong = dfOHCondLatLong.rename(columns={'xStart': 'x',\n",
    "                                                  'yStart': 'y',\n",
    "                                                  'FEEDERID': 'OH_FEEDERID',\n",
    "                                                  'FEEDERID2': 'OH_FEEDERID2',})\n",
    "#'xMid', 'yMid','xEnd','yEnd','FEEDERID','INSTALLATI',\n",
    "#Change datatype to str for concatenation\n",
    "dfOHCondLatLong['x'] = dfOHCondLatLong['x'].astype(str)\n",
    "dfOHCondLatLong['y'] = dfOHCondLatLong['y'].astype(str)\n",
    "dfOHCondLatLong['xy'] = dfOHCondLatLong['x']+'-'+dfOHCondLatLong['y']\n",
    "# dfOHCondLatLong['xMid'] = dfOHCondLatLong['xMid'].astype(str)\n",
    "# dfOHCondLatLong['yMid'] = dfOHCondLatLong['yMid'].astype(str)\n",
    "# dfOHCondLatLong['xyMid'] = dfOHCondLatLong['xMid']+'-'+dfOHCondLatLong['yMid']\n",
    "dfOHCondLatLong['xEnd'] = dfOHCondLatLong['xEnd'].astype(str)\n",
    "dfOHCondLatLong['yEnd'] = dfOHCondLatLong['yEnd'].astype(str)\n",
    "dfOHCondLatLong['xyEnd'] = dfOHCondLatLong['xEnd']+'-'+dfOHCondLatLong['yEnd']\n",
    "\n",
    "dfOHCondLatLong = drop_columns(dfOHCondLatLong, dropMoreWireLatLongCols)\n",
    "\n",
    "# Groupby 'xy'\n",
    "dfOHCondLatLongXY = dfOHCondLatLong.groupby('xy')\n",
    "#print(dfOHCondLatLongXY.head(3))\n",
    "\n",
    "# Groupby 'xyEnd'\n",
    "\n",
    "\n",
    "# Transformer-Switch-Cables-Poles: \n",
    "# 7156 matches (81.1%) out of 8826 [1670 unmatched ~ 18.9%]\n",
    "dfPolesTxSwitchCablesOHCondLatLongStart = dfPolesTxSwitchCablesLatLong.merge(dfOHCondLatLong, how='left', on='xy')\n",
    "#print(dfPolesTxSwitchCablesLatLong.columns)\n",
    "#dfPolesTxSwitchCablesOHCondLatLongStart = dfPolesTxSwitchCablesLatLong.merge(dfOHCondLatLong, on='xy')\n",
    "\n",
    "#print(dfPolesTxSwitchCablesOHCondLatLongStart.columns)\n",
    "\n",
    "# 0 matches out of 8826 \n",
    "# dfPolesTxSwitchCablesOHCondLatLongMid = dfPolesTxSwitchCablesLatLong.merge(dfOHCondLatLong,                                                                        how='left', left_on='xy', right_on='xyMid')\n",
    "# 6813 matches (77.2%) out of 8826 [2013 unmatched ~ 22.8%]\n",
    "dfPolesTxSwitchCablesOHCondLatLongEnd = dfPolesTxSwitchCablesLatLong.merge(dfOHCondLatLong,\n",
    "                                                                           how='left', left_on='xy', right_on='xyEnd')\n",
    "\n",
    "#dfPolesTxSwitchCablesOHCondLatLongEnd = dfPolesTxSwitchCablesLatLong.merge(dfOHCondLatLong,left_on='xy', right_on='xyEnd')\n",
    "#**********************************************************************\n",
    "# OUTPUT FILES\n",
    "#**********************************************************************\n",
    "# Transformer-Poles match output\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesTx.xlsx')\n",
    "# dfPolesTxLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "# Pole-Switch Output\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesSwitches.xlsx')\n",
    "# dfPolesSwitchLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "# Transformer-Switch-Poles match output\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesTxSwitch.xlsx')\n",
    "# dfPolesTxSwitchLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "# Transformer-Switch-Cables-Poles match output\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCable.xlsx')\n",
    "# dfPolesTxSwitchCablesLatLong.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "\n",
    "# Transformer-Switch-Cables-OHCond-Poles match output\n",
    "MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCableOHCond_start.xlsx')\n",
    "dfPolesTxSwitchCablesOHCondLatLongStart.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "# MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCableOHCond_mid.xlsx')\n",
    "# dfPolesTxSwitchCablesOHCondLatLongMid.to_excel(MasterFile, 'Sheet1')\n",
    "# MasterFile.save()\n",
    "MasterFile = pd.ExcelWriter('V4_PolesTxSwitchCableOHCond_end.xlsx')\n",
    "dfPolesTxSwitchCablesOHCondLatLongEnd.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole attachments analysis completed')\n",
    "\n",
    "\n",
    "# ['phasing', 'prid', 'tx', 'tx_type', 'circuit1', 'circuit2', 'circuit3',\n",
    "#        'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'in_valley',\n",
    "#        'tx_residential', 'tx_commercial', 'tx_industrial', 'num_circuits',\n",
    "#        'device', 'tx_kva', 'tx_phasing']\n",
    "\n",
    "\n",
    "#print(FeederKey,':',cableLength,'kms')\n",
    "#dictFeeders.update({FeederKey:[cableLength, txCounts, switchCounts,fuseCounts]})\n",
    "    \n",
    "# 1. Pole circuit ids\n",
    "# Combine lat long of V2_LatLongPoles, V2_LatLongSwitches\n",
    "# Assign circuit id to poles\n",
    "# fill in circuit column in poles - how to match multiple circuit ids?\n",
    "# *V2_LatLongPriOHCond values [start, mid, end]\n",
    "\n",
    "# 2. cable installation age\n",
    "# \n",
    "# 3. PRID :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLE_ID              0\n",
      "xy                   0\n",
      "FEEDERID          2367\n",
      "id                2367\n",
      "circuit           2367\n",
      "install_year      2368\n",
      "phasing           2367\n",
      "kva               2367\n",
      "tx_residential    2571\n",
      "tx_commercial     2571\n",
      "tx_industrial     2571\n",
      "SW_FEEDERID       2562\n",
      "SW_FEEDERID2      2562\n",
      "SUBTYPECD         2562\n",
      "SW_ID             2562\n",
      "Cable_Year        2570\n",
      "Cable_FEEDERID    2568\n",
      "OH_FEEDERID       2571\n",
      "OH_FEEDERID2      2571\n",
      "xyEnd             2571\n",
      "dtype: int64\n",
      "(2571, 20)\n",
      "POLE_ID              0\n",
      "xy                   0\n",
      "FEEDERID          5795\n",
      "id                5796\n",
      "circuit           5796\n",
      "install_year      5798\n",
      "phasing           5796\n",
      "kva               5796\n",
      "tx_residential    7201\n",
      "tx_commercial     7201\n",
      "tx_industrial     7201\n",
      "SW_FEEDERID       7108\n",
      "SW_FEEDERID2      7108\n",
      "SUBTYPECD         7108\n",
      "SW_ID             7108\n",
      "Cable_Year        7198\n",
      "Cable_FEEDERID    7189\n",
      "OH_FEEDERID          0\n",
      "OH_FEEDERID2         0\n",
      "xyEnd                0\n",
      "dtype: int64\n",
      "(7201, 20)\n"
     ]
    }
   ],
   "source": [
    "#print(dfPolesOHCondLatLongStart.isnull().sum())\n",
    "df_empty = dfPolesTxSwitchCablesOHCondLatLongStart[dfPolesTxSwitchCablesOHCondLatLongStart.OH_FEEDERID.isnull()]\n",
    "df_filled = dfPolesTxSwitchCablesOHCondLatLongStart[dfPolesTxSwitchCablesOHCondLatLongStart.OH_FEEDERID.notnull()]\n",
    "\n",
    "# df_empty.drop('OH_FEEDERID', axis=1, inplace=True)\n",
    "# df_empty['OH_FEEDERID'] = 0\n",
    "# print(df_filled.columns)\n",
    "# print(df_empty.columns)\n",
    "print(df_empty.isnull().sum())\n",
    "print(df_empty.shape)\n",
    "#print(df_empty.head(5))\n",
    "print(df_filled.isnull().sum())\n",
    "print(df_filled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the df_filled to train and test data\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine,test_size=0.30, random_state=123)\n",
    "\n",
    "#https://www.dataquest.io/blog/k-nearest-neighbors/\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "import math\n",
    "\n",
    "# Randomly shuffle the index of df_filled.\n",
    "random_indices = permutation(df_filled.index)\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(df_filled)/3)\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "df_filled_test = df_filled.loc[random_indices[1:test_cutoff]]\n",
    "# Generate the train set with the rest of the data.\n",
    "df_filled_train = df_filled.loc[random_indices[test_cutoff:]]\n",
    "\n",
    "for k in [1, 2, 3, 5, 10, 20]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(df_filled_train[['x', 'y']], df_filled_train['OH_FEEDERID'])\n",
    "\n",
    "    predictions = knn.predict(df_filled_test[['x','y']])\n",
    "    prediction_results = df_filled_test['OH_FEEDERID'] == predictions\n",
    "    print('With k =  ',k,',a score of: ', prediction_results.mean()*100)\n",
    "\n",
    "# Let's initialize a classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# knn.fit takes two parameters # First, the content we want to train on. For us it's height and weight.\n",
    "# Secondly, how we're classifying each element of the training data. We're classifying by position!\n",
    "# knn.fit(nba_training[[\"Ht (In.)\", \"WT\"]], nba_training[\"POS\"])\n",
    "knn.fit(df_filled_train[['x', 'y']], df_filled_train['OH_FEEDERID'])\n",
    "predictions = knn.predict(df_filled_test[['x','y']])\n",
    "fill_feeders = knn.predict(df_empty[['x','y']])\n",
    "prediction_results = df_filled_test['OH_FEEDERID'] == predictions\n",
    "print(prediction_results.mean()*100)\n",
    "df_empty.loc[:,'OH_FEEDERID'] = fill_feeders\n",
    "# print(df_empty.isnull().sum())\n",
    "# print(df_empty.shape)\n",
    "# print(df_empty.head(5))\n",
    "# Get the actual values for the test set.\n",
    "#actual = df_filled_test['OH_FEEDERID']\n",
    "# Compute the mean squared error of our predictions.\n",
    "# mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "\n",
    "df_all = pd.concat([df_filled,df_empty])\n",
    "print(df_all.isnull().sum())\n",
    "MasterFile = pd.ExcelWriter('V4_ML_PolesOHCond_start.xlsx')\n",
    "df_all.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "print('Pole attachments analysis completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole attachments analysis completed\n"
     ]
    }
   ],
   "source": [
    "#polesLatLong_GroupBy = dfPolesTxSwitchCablesOHCondLatLongEnd.groupby(['POLE_ID'])\n",
    "#polesLatLong_GroupBy = pd.DataFrame({'count' : dfPolesTxSwitchCablesOHCondLatLongEnd.groupby( [ \"POLE_ID\"] ).size()}).reset_index()\n",
    "\n",
    "#cities = df.groupby('ID')['City'].apply(lambda x: pd.Series([city for city in x])).unstack()\n",
    "\n",
    "polesLatLong_GroupBy = dfPolesTxSwitchCablesOHCondLatLongStart.groupby('POLE_ID')['OH_FEEDERID'].apply(lambda x: pd.Series([fdr for fdr in x])).unstack()\n",
    "MasterFile = pd.ExcelWriter('V4_PolesLatLongCounts.xlsx')\n",
    "polesLatLong_GroupBy.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()\n",
    "\n",
    "print('Pole attachments analysis completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SW_FEEDERID', 'SW_FEEDERID2', 'SUBTYPECD', 'SW_ID', 'xy'], dtype='object')\n",
      "25301.244-5541380.516\n",
      "24313.636-5546611.628\n",
      "26437.217-5540996.446\n",
      "20770.32975-5547330.23225\n",
      "20778.243-5546583.879\n",
      "24050.604375-5540162.82363\n",
      "24076.289-5546208.683\n",
      "25959.138-5542076.944\n",
      "24077.504-5546212.102\n",
      "24220.488-5545272.059\n",
      "24900.512-5543179.201\n"
     ]
    }
   ],
   "source": [
    "# dfPolesTxLatLong\n",
    "# dfPolesSwitchLatLong\n",
    "# dfPolesTxSwitchCablesOHCondLatLongStart\n",
    "# dfPolesTxSwitchCablesOHCondLatLongEnd\n",
    "print(dfSwitchesLatLong.columns)\n",
    "dictPolesLatLong = dict(zip(dfPolesLatLong['xy'], dfPolesLatLong['POLE_ID']))\n",
    "#dictPolesLatLong = dictPolesLatLong.update(dfPolesSwitchLatLong.apply(lambda x: df['xy']))\n",
    "#print(dictPolesLatLong)\n",
    "count = 0\n",
    "for index,i2,i3,i4,i5,i6 in dfSwitchesLatLong.itertuples():\n",
    "    if count <= 10:\n",
    "        print(i6)\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for index,i2,i3,i4,i5,i6 in dfSwitchesLatLong.itertuples():\n",
    "    if i6 in dictPolesLatLong['xy']:\n",
    "        dictPolesLatLong.update(i)\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "#     dictPolesLatLong.update()\n",
    "# count = 0\n",
    "# for f in dfPolesSwitchLatLong:\n",
    "#     count = count + 1\n",
    "#     if count == 10:\n",
    "#         break\n",
    "#     else:\n",
    "#         print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(polesLatLong_GroupBy.head())\n",
    "#polesLatLong_GroupBy.add_suffix('_Count').reset_index()\n",
    "MasterFile = pd.ExcelWriter('V4_PolesLatLongCounts.xlsx')\n",
    "polesLatLong_GroupBy.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fuses\n",
    "\n",
    "dropFusesCols = ['ANCILLARYROLE', 'ENABLED', 'INSTALLATIONDATE', 'FEEDERID', 'FEEDERID2', 'FEEDERINFO', 'ELECTRICTRACEWEIGHT', 'LOCATIONID', 'GPSDATE', 'SUBTYPECD', 'LABELTEXT', 'COMPATIBLEUNITID', 'PHASEDESIGNATION', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE', 'MAXCONTINUOUSCURRENT', 'MAXINTERRUPTINGCURRENT', 'MAXOPERATINGVOLTAGE', 'PRESENTPOSITION_R', 'PRESENTPOSITION_Y', 'PRESENTPOSITION_B', 'NORMALPOSITION_R', 'NORMALPOSITION_Y', 'NORMALPOSITION_B', 'DEVICENUMBER', 'FUSELINKSIZE', 'FEATURE_STATUS', 'SYMBOLROTATION', 'INSULATOR_MATERIAL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop_Switch_Columns = ['OBJECTID', 'ANCILLARYROLE', 'ENABLED', 'WORKORDERID', 'FIELDVERIFY', 'COMMENTS','CREATIONUSER', \n",
    "#                        'DATECREATED', 'LASTUSER', 'DATEMODIFIED', 'WORKREQUESTID', 'DESIGNID','WORKLOCATIONID', 'WMSID', \n",
    "#                        'WORKFLOWSTATUS', 'WORKFUNCTION', 'FEEDERINFO','ELECTRICTRACEWEIGHT', 'LOCATIONID', 'GPSDATE', \n",
    "#                        'GISONUMBER', 'GISOTYPENBR', 'LABELTEXT','OWNERSHIP', 'OPERATINGVOLTAGE', 'NOMINALVOLTAGE',\n",
    "#                        'MAXOPERATINGVOLTAGE', 'MAXCONTINUOUSCURRENT', 'PRESENTPOSITION_R', 'PRESENTPOSITION_Y', \n",
    "#                        'PRESENTPOSITION_B', 'NORMALPOSITION_R', 'NORMALPOSITION_Y', 'NORMALPOSITION_B', 'SCADACONTROLID', \n",
    "#                        'SCADAMONITORID', 'PREFERREDCIRCUITSOURCE', 'TIESWITCHINDICATOR', 'GANGOPERATED', 'MANUALLYOPERATED',\n",
    "#                         'FEATURE_STATUS', 'HYPERLINK', 'HYPERLINK_PGDB', 'SYMBOLROTATION', 'INSULATOR_MATERIAL']\n",
    "\n",
    "\n",
    "# %timeit\n",
    "# Strip '\\n' from column headers\n",
    "dfTopology.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfSpotLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfLoads.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfCables.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfSwitches.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfNodes.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfOHlines.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "dfFuses.rename(columns=lambda x: x.replace('\\n',''), inplace=True)\n",
    "\n",
    "# Rename column headers\n",
    "dfTopology.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "#dfSpotLoads.rename(columns=lambda x: 'SpotLoads_'+x, inplace=True)\n",
    "dfLoads.rename(columns=lambda x: 'Loads_'+x, inplace=True)\n",
    "dfCables.rename(columns=lambda x: 'Cables_'+x, inplace=True)\n",
    "dfSwitches.rename(columns=lambda x: 'Switches_'+x, inplace=True)\n",
    "dfNodes.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "dfOHlines.rename(columns=lambda x: 'OHlines_'+x, inplace=True)\n",
    "dfFuses.rename(columns=lambda x: 'Fuses_'+x, inplace=True)\n",
    "\n",
    "# Merge assets: switch, transformers, fuses, cables, OHlines to Node worksheet\n",
    "dfNodesMaster = pd.merge(dfNodes, dfSwitches, how='outer', left_on='Nodes_Node Id', right_on ='Switches_From Node')\n",
    "dfNodesMaster = pd.merge(dfNodesMaster, dfLoads, how='outer', left_on='Nodes_Node Id', right_on='Loads_From Node')\n",
    "dfNodesMaster = pd.merge(dfNodesMaster, dfFuses, how='outer', left_on='Nodes_Node Id', right_on='Fuses_From Node')\n",
    "#dfNodesMaster = pd.merge(dfNodesMaster, dfOHlines, how='outer', left_on='Nodes_Node Id', right_on='OHlines_From Node')\n",
    "dfNodesMaster = pd.merge(dfNodesMaster, dfCables, how='outer', left_on='Nodes_Node Id', right_on='Cables_From Node')\n",
    "# print(dfNodesMaster.head(3))\n",
    "print(len(dfNodesMaster.columns))\n",
    "\n",
    "dfNodesMaster = dfNodesMaster.rename(columns={'Loads_Total CkVA(kVA)':'Nameplate', 'Loads_Spot Number':'TransformerID'})\n",
    "dfNodesCopy = dfNodesMaster\n",
    "#print(dfNodesCopy.dtypes)\n",
    "\n",
    "#Change to str\n",
    "dfNodesCopy['Cables_From Node']= dfNodesCopy['Cables_From Node'].astype(str)\n",
    "dfNodesCopy['Cables_To Node']= dfNodesCopy['Cables_To Node'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split 'Nodes_Node Id' to 'NodeID_1' and 'NodeID_2' for 'SwitchRegion'\n",
    "dfNodesCopy['NodeID_1'], dfNodesCopy['NodeID_2'] = zip(*dfNodesCopy['Nodes_Node Id'].\n",
    "                                                       apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "\n",
    "#******************************#\n",
    "#***DIFFERET FROM V5 BEGINS****#\n",
    "#******************************#\n",
    "dfNodesCopy['Cables_FromNodeID_1'], dfNodesCopy['Cables_FromNodeID_2'] = zip(*dfNodesCopy['Cables_From Node'].\n",
    "                                                       apply(lambda x: x.split('_') if '_' in x else (x,np.nan)))\n",
    "dfNodesCopy['Cables_ToNodeID_1'], dfNodesCopy['Cables_ToNodeID_2'] = zip(*dfNodesCopy['Cables_To Node'].\n",
    "                                                        apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "                # Columns 'Cables_FromNodeID_2' and 'Cables_ToNodeID_2' dropped in Cables_drop_cols\n",
    "#******************************#\n",
    "#***DIFFERET FROM V5 ENDS******#\n",
    "#******************************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns deleted:  70\n",
      "Number of rows:  735\n",
      "Number of remaining columnns:  16\n"
     ]
    }
   ],
   "source": [
    "#Switch region col a.fill(numpy.nan), a[:] = numpy.nan\n",
    "Num_rows = len(dfNodesCopy['Nodes_Network Id'])\n",
    "dfNodesCopy['SwitchRegion'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "dfNodesCopy['CablesSwitchRegionFrom'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "dfNodesCopy['CablesSwitchRegionEnd'] = pd.DataFrame(np.empty([Num_rows,1]).cumsum(axis=1))\n",
    "# avoid chain indexing - http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
    "dfNodesCopy.loc[:,'SwitchRegion'] = np.nan\n",
    "dfNodesCopy.loc[:,'CablesSwitchRegionFrom'] = np.nan\n",
    "dfNodesCopy.loc[:,'CablesSwitchRegionEnd'] = np.nan\n",
    "\n",
    "# V6 changes\n",
    "#df['Normalized'] = np.where(df['Currency'] == '$', df['Budget'] * 0.78125, df['Budget'])\n",
    "#'Cables_FromNodeID_2' and 'Cables_ToNodeID_2'\n",
    "dfNodesCopy['CablesSwitchRegionFrom'] = dfNodesCopy['Cables_FromNodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "dfNodesCopy['CablesSwitchRegionEnd'] = dfNodesCopy['Cables_ToNodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "dfNodesCopy['SwitchRegion'] = dfNodesCopy['NodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "\n",
    "#FillNA\n",
    "dfNodesCopy['SwitchRegion'] = dfNodesCopy['SwitchRegion'].fillna(method='ffill')\n",
    "dfNodesCopy['CablesSwitchRegionFrom'] = dfNodesCopy['CablesSwitchRegionFrom'].fillna(method='ffill')\n",
    "dfNodesCopy['CablesSwitchRegionEnd'] = dfNodesCopy['CablesSwitchRegionEnd'].fillna(method='ffill')\n",
    "\n",
    "#V5\n",
    "#dfNodesCopy['SwitchRegion'] = dfNodesCopy['NodeID_1'].apply(lambda x: x if '-' in x else np.nan)\n",
    "\n",
    "#http://stackoverflow.com/questions/27905295/how-to-replace-nans-by-preceding-values-in-pandas-dataframe\n",
    "# df.fillna(method='ffill')\n",
    "# http://stackoverflow.com/questions/11497206/regular-expression-for-letters-dash-underscore-numbers-and-space\n",
    "\n",
    "# Remove columns - temporary list for now\n",
    "Nodes_drop_cols = ['Nodes_Phase','Nodes_Node Id', 'NodeID_1','NodeID_2'] #['Nodes_Network Id','Nodes_Node Id','Nodes_Phase'] \n",
    "Switches_drop_cols = ['Switches_Network Id','Switches_Equipment Id','Switches_Device Type','Switches_Status',\n",
    "                         'Switches_Phase','Switches_From Node','Switches_Voltage(kV)'] \n",
    "                        #'Switches_Section Id','Switches_State','Switches_Rating(A)'\n",
    "Tx_drop_cols = ['Loads_Network Id','Loads_Section Id','Loads_Status','Loads_From Node','Loads_Spot Type',\n",
    "                   'Loads_Dist Number','Loads_Dist Type','Loads_Total kVA(kVA)','Loads_Total kW(kW)','Loads_Total kvar',\n",
    "                   'Loads_Aver. PF(%)','Loads_Total kWh(kWh)','Loads_Total Cust','Loads_Phase Type','Loads_Config',\n",
    "                   'Loads_Locked','Loads_Load Model'] #'Loads_TransformerID','Loads_Phase','Loads_Nameplate',\n",
    "\n",
    "Fuses_drop_cols =['Fuses_Network Id', 'Fuses_Status','Fuses_State','Fuses_Phase','Fuses_Manufacturer', \n",
    "                    'Fuses_Model', 'Fuses_Voltage(kV)', 'Fuses_Voltage Class', 'Fuses_Standard', 'Fuses_Rating(A)',\n",
    "                  'Fuses_Rating','Fuses_Interrupting Rating(A)', 'Fuses_From Node', 'Fuses_To Node'] \n",
    "                    #  'Fuses_Section Id', 'Fuses_Equipment Id', Fuses_Rating' \n",
    "\n",
    "#OHlines_deleted_cols =['OHlines_Network Id','OHlines_Phase','OHlines_Cond R','OHlines_Cond Y',\n",
    "                       #'OHlines_Cond B','OHlines_Neutral 1','OHlines_Neutral 2','OHlines_Spacing']\n",
    "                        #'OHlines_Section Id','OHlines_Length(m)',\n",
    "OHlines_drop_cols=[]\n",
    "\n",
    "#V6 changes\n",
    "Cables_drop_cols =['Cables_Network Id','Cables_Equipment Id','Cables_Line Id','Cables_Status','Cables_Phase',\n",
    "                      'Cables_# parallel','Cables_Manufacturer','Cables_Standard',\n",
    "                      'Cables_Rated Voltage(kV)','Cables_Ampacity(A)','Cables_Withstand(A)','Cables_Cable Type',\n",
    "                      'Cables_Conductor Material','Cables_Sheathed','Cables_Concentric Neutrals','Cables_Line R1(ohms)',\n",
    "                      'Cables_Line X1(ohms)','Cables_Line B1(S)','Cables_Line R0(ohms)','Cables_Line X0(ohms)',\n",
    "                      'Cables_Line B0(S)','Cables_Harmonic Model', 'Cables_FromNodeID_1','Cables_ToNodeID_1',\n",
    "                      'Cables_FromNodeID_2','Cables_ToNodeID_2','Cables_From Node', 'Cables_To Node',] \n",
    "                    #'Cables_From Node','Cables_To Node','Cables_Length(m)','Cables_Size','Cables_insulation'\n",
    "\n",
    "# Poles_deleted_cols=[]\n",
    "\n",
    "combined_drop_cols = (Nodes_drop_cols + Switches_drop_cols + Tx_drop_cols + Fuses_drop_cols + \n",
    "                      OHlines_drop_cols + Cables_drop_cols)\n",
    "\n",
    "print('Number of columns deleted: ', len(combined_drop_cols))\n",
    "print('Number of rows: ', len(dfNodesCopy['Nodes_Network Id']))\n",
    "\n",
    "#Drop columns\n",
    "dfNodesCopy=dfNodesCopy.drop(combined_drop_cols, axis=1)\n",
    "\n",
    "#print('new cols: ', len(dfNodesCopy.columns))\n",
    "print('Number of remaining columnns: ', len(dfNodesCopy.columns))\n",
    "#print(dfNodesCopy.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MasterFile = pd.ExcelWriter('V7_NodeIDs.xlsx')\n",
    "dfNodesCopy.to_excel(MasterFile, 'Sheet1')\n",
    "MasterFile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SwitchGrouped = dfNodesCopy.groupby('SwitchRegion')\n",
    "#print(SwitchGrouped.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #  Ctrl + A\n",
    "# # Ctrl + / to uncomment\n",
    "\n",
    "# # ****************************\n",
    "# # A. NODES sheet\n",
    "# # ****************************\n",
    "# # 1. Split 'Node Id' to 'NodeID_1' and 'NodeID_2'\n",
    "# dfNodes['NodeID_1'], dfNodes['NodeID_2'] = zip(*dfNodes['Node Id'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfNodesCopy = pd.DataFrame(dfNodes)\n",
    "# # 3. Rename all column headers to 'Nodes_' + x\n",
    "# dfNodesCopy.rename(columns=lambda x: 'Nodes_'+x, inplace=True)\n",
    "# #print(dfNodes_Copy.count())\n",
    "\n",
    "# # ****************************\n",
    "# # B. MASTER SPREADSHEET\n",
    "# # ****************************\n",
    "# # Copy dfNodesCopy into dfMaster\n",
    "# dfMaster = pd.DataFrame(dfNodesCopy)\n",
    "# # print(dfMaster.count())\n",
    "# # Nodes_NodeID_1 and Nodes_NodeID_2 are keys\n",
    "\n",
    "# # ****************************\n",
    "# # C. Topology sheet\n",
    "# # ****************************\n",
    "# # 1. No renaming here,so freate a 'copy' dataframe\n",
    "# dfTopologyCopy = pd.DataFrame(dfTopology)\n",
    "# # 2. Rename all column headers to 'Topology_' + x\n",
    "# dfTopologyCopy.rename(columns=lambda x: 'Topology_'+x, inplace=True)\n",
    "# #print(dfTopologyCopy.count())\n",
    "\n",
    "# # 3. Combine topology sheet\n",
    "# # pd.merge(frame_1, frame_2, left_on = 'county_ID', right_on = 'countyid')\n",
    "# # dfFinal = \n",
    "# # Topology - more match with 'Topology_Coord. Y' over 'Topology_Coord. X'\n",
    "# dfMaster = pd.merge(dfMaster, dfTopologyCopy, how='outer', left_on='Nodes_NodeID_2', right_on ='Topology_Coord. Y')\n",
    "# #print(dfMaster.count())\n",
    "\n",
    "\n",
    "# # ****************************\n",
    "# # D. Fuses sheet \n",
    "# # ****************************\n",
    "# # 1. Split 'From Node' to 'FromNode_xCoord' and 'FromNode_yCoord'\n",
    "# dfFuses['FromNode_xCoord'], dfFuses['FromNode_yCoord'] = zip(*dfFuses['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Split 'To Node' to 'ToNode_FuseID' and 'ToNode_FdrID'\n",
    "# dfFuses['ToNode_FuseID'], dfFuses['ToNode_FdrID'] = zip(*dfFuses['To Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 3. Create a 'Copy' dataframe\n",
    "# dfFusesCopy = pd.DataFrame(dfFuses)\n",
    "# # 4. Rename all column headers to 'Fuses_' + x\n",
    "# dfFusesCopy.rename(columns=lambda x:'Fuses_'+x, inplace=True)\n",
    "# # 5. Combine Fuses sheet with Master\n",
    "# dfMaster = pd.merge(dfMaster, dfFusesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Fuses_FromNode_xCoord')\n",
    "# #print(dfMaster.count())\n",
    "\n",
    "# # ****************************\n",
    "# # D1. Output excel file - For VERIFICATION purposes\n",
    "# # ****************************\n",
    "# # Verify the excel file \n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# # http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# # MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# # dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# # MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ctrl + / to uncomment\n",
    "\n",
    "# # ****************************\n",
    "# # E. Switch sheet \n",
    "# # ****************************\n",
    "# # 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "# dfSwitches['FromNode_1'], dfSwitches['FromNode_2'] = zip(*dfSwitches['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfSwitchesCopy = pd.DataFrame(dfSwitches)\n",
    "# # 3. Rename all column headers to 'Switches_' + x\n",
    "# dfSwitchesCopy.rename(columns=lambda x:'Switches_'+x, inplace=True)\n",
    "# # 4. Combine Switches sheet with Master: \n",
    "# # 4.1 First with 'Switches_FromNode_1' - NodeID_1 also has '109-D'/'7-S' switch id :)\n",
    "# dfMaster = pd.merge(dfMaster, dfSwitchesCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Switches_FromNode_1')\n",
    "# # 4.2 Second with 'Section Id' of FusesCopy - maybe not necessary\n",
    "\n",
    "# # ****************************\n",
    "# # F. Transformer aka \"Loads\" in CYME\n",
    "# # ****************************\n",
    "# # \n",
    "# # 1. Split 'From Node' to 'FromNode_1' and 'FromNode_2'\n",
    "# dfLoads['FromNode_1'], dfLoads['FromNode_2'] = zip(*dfLoads['From Node'].apply(lambda x: x.split('_') if '_' in x else (x, np.nan)))\n",
    "# # 2. Create a 'Copy' dataframe\n",
    "# dfLoadsCopy = pd.DataFrame(dfLoads)\n",
    "# # 3. Rename all column headers to Loads_' + x\n",
    "# dfLoadsCopy.rename(columns=lambda x:'Loads_'+x, inplace=True)\n",
    "# # 4. Combine all Loads with 'FromNode_1'  with dfMaster\n",
    "# dfMaster = pd.merge(dfMaster, dfLoadsCopy, how='outer', left_on='Nodes_NodeID_1', right_on ='Loads_FromNode_1')\n",
    "# # 4.2 May need to combine dfLoadsCopy with dfSpotLoads if tx nameplate rating not same\n",
    "\n",
    "\n",
    "# #Plot\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# pd.options.display.mpl_style = 'default'\n",
    "# #dfSwitches.boxplot()\n",
    "# #dfFusesCopy.boxplot(column=\"Fuses_Rating(A)\")\n",
    "# #mydf['CigarNum'] = mydf['CigarNum'].convert_objects(convert_numeric=True)\n",
    "# dfFusesCopy['Fuses_FromNode_xCoord'] = dfFusesCopy['Fuses_FromNode_xCord'].convert_objects(convert_numeric=True)\n",
    "# dfFusesCopy['Fuses_FromNode_yCoord'] = dfFusesCopy['Fuses_FromNode_yCord'].convert_objects(convert_numeric=True)\n",
    "# #dfFusesCopy.plot(kind='scatter', x='Fuses_FromNode_xCoord', y='Fuses_FromNode_yCoord')\n",
    "\n",
    "\n",
    "# # ****************************\n",
    "# # D1. Output excel file\n",
    "# # ****************************\n",
    "# # Verify the excel file \n",
    "# # http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.to_excel.html\n",
    "# # http://stackoverflow.com/questions/29974672/writing-pandas-dataframe-to-excel-with-different-formats-for-different-columns\n",
    "# #MasterFile = pd.ExcelWriter('master.xlsx')\n",
    "# #dfMaster.to_excel(MasterFile, 'Sheet1')\n",
    "# #MasterFile.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************************\n",
    "# G. PRID to each region\n",
    "# ****************************\n",
    "# combine PRID to Tx?\n",
    "\n",
    "# ****************************\n",
    "# H. Cable \n",
    "# ****************************\n",
    "# combine cable and conductors\n",
    "\n",
    "# ****************************\n",
    "# I. Conductors  \n",
    "# ****************************\n",
    "# combine poles\n",
    "\n",
    "# ****************************\n",
    "# J. Poles \n",
    "# ****************************\n",
    "# Output excel file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
